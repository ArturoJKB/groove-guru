{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "156do7viZ3wZ"
      },
      "source": [
        "# **// GROOVE GURU //**\n",
        "#### *(An Audio Analysis, Music Mixing and Production Assistant Tool)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXm_rVHUbTCY"
      },
      "source": [
        "# Workflow Diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fayvVVxVd6nv"
      },
      "source": [
        "![diagram_app.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDYrWf_BbQLZ"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAkX0MXWV0h0"
      },
      "outputs": [],
      "source": [
        "!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNxMzfgH3ei"
      },
      "source": [
        "# Complete APP Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgJRA0VB9zjG"
      },
      "source": [
        "## Audio_Features_Analisys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rX3ok7-fTnMC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Audio Analysis Module\n",
        "====================\n",
        "Extracts comprehensive audio features for mixing recommendation system.\n",
        "Compatible with the mixing recommendation mapper.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa as lb\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, Any, Tuple, Optional\n",
        "import warnings\n",
        "\n",
        "# Suppress librosa warnings for cleaner output\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "def analyze_audio_features(audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Comprehensive audio analysis function that extracts all features needed\n",
        "    for mixing recommendations.\n",
        "\n",
        "    Args:\n",
        "        audio_data: Audio signal as numpy array\n",
        "        sample_rate: Sample rate of the audio\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all extracted audio features\n",
        "    \"\"\"\n",
        "    # Ensure mono audio for most analyses\n",
        "    if audio_data.ndim > 1:\n",
        "        audio_mono = np.mean(audio_data, axis=0)  # Convert to mono\n",
        "        audio_stereo = audio_data\n",
        "    else:\n",
        "        audio_mono = audio_data\n",
        "        audio_stereo = None\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    features = {}\n",
        "\n",
        "    # === CORE MUSICAL FEATURES ===\n",
        "    try:\n",
        "        # Key and tempo analysis\n",
        "        key_info = _analyze_key_and_tonality(audio_mono, sample_rate)\n",
        "        tempo_info = _analyze_tempo_and_rhythm(audio_mono, sample_rate)\n",
        "\n",
        "        features.update(key_info)\n",
        "        features.update(tempo_info)\n",
        "\n",
        "        # === SPECTRAL AND TIMBRAL FEATURES ===\n",
        "        spectral_features = _analyze_spectral_features(audio_mono, sample_rate)\n",
        "        features.update(spectral_features)\n",
        "\n",
        "        # === DYNAMIC AND LOUDNESS FEATURES ===\n",
        "        dynamic_features = _analyze_dynamic_features(audio_mono, sample_rate)\n",
        "        features.update(dynamic_features)\n",
        "\n",
        "        # === HARMONIC AND PERCUSSIVE FEATURES ===\n",
        "        harmonic_features = _analyze_harmonic_features(audio_mono, sample_rate)\n",
        "        features.update(harmonic_features)\n",
        "\n",
        "        # === SPATIAL FEATURES (if stereo) ===\n",
        "        if audio_stereo is not None:\n",
        "            spatial_features = _analyze_spatial_features(audio_stereo, sample_rate)\n",
        "            features.update(spatial_features)\n",
        "        else:\n",
        "            # Default stereo width for mono files\n",
        "            features['stereo_width'] = 0.0\n",
        "\n",
        "        # === DERIVED FEATURES FOR MIXING ===\n",
        "        derived_features = _calculate_derived_features(features, audio_mono, sample_rate)\n",
        "        features.update(derived_features)\n",
        "\n",
        "        # Add basic metadata\n",
        "        features['duration'] = len(audio_mono) / sample_rate\n",
        "        features['sample_rate'] = sample_rate\n",
        "        features['is_stereo'] = audio_stereo is not None\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback with basic features if analysis fails\n",
        "        print(f\"Warning: Audio analysis failed with error: {e}\")\n",
        "        features = _get_fallback_features(audio_mono, sample_rate)\n",
        "\n",
        "    return features\n",
        "\n",
        "def _analyze_key_and_tonality(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze musical key and tonal features.\"\"\"\n",
        "    # Extract chroma features\n",
        "    chroma = lb.feature.chroma_cqt(y=audio, sr=sr)\n",
        "\n",
        "    # Apply recency weighting (more weight to recent notes)\n",
        "    weights = np.linspace(0.5, 1.5, chroma.shape[1])\n",
        "    chroma_weighted = chroma * weights\n",
        "    chroma_norm = chroma_weighted / (chroma_weighted.sum(axis=0, keepdims=True) + 1e-8)\n",
        "\n",
        "    # Krumhansl-Schmuckler key profiles\n",
        "    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
        "    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # Test all 24 possible keys (12 major + 12 minor)\n",
        "    for i in range(12):\n",
        "        rotated_major = np.roll(major_profile, i)\n",
        "        rotated_minor = np.roll(minor_profile, i)\n",
        "\n",
        "        # Calculate correlation scores\n",
        "        score_major = np.sum(chroma_norm.mean(axis=1) * rotated_major)\n",
        "        score_minor = np.sum(chroma_norm.mean(axis=1) * rotated_minor)\n",
        "\n",
        "        scores.append((score_major, 'Major', i))\n",
        "        scores.append((score_minor, 'Minor', i))\n",
        "\n",
        "    # Find best match\n",
        "    best_score, mode, tonic = max(scores, key=lambda x: x[0])\n",
        "\n",
        "    # Key names\n",
        "    key_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
        "\n",
        "    # Hierarchical analysis (tonic triad strength)\n",
        "    triad = [tonic, (tonic + 4) % 12, (tonic + 7) % 12]  # Major triad intervals\n",
        "    triad_strength = np.sum(chroma_norm[triad, :].mean(axis=1))\n",
        "\n",
        "    # Tonal stability analysis\n",
        "    tonic_series = np.argmax(chroma, axis=0)\n",
        "    tonic_stability = np.sum(np.diff(tonic_series) == 0) / (len(tonic_series) - 1 + 1e-8)\n",
        "\n",
        "    return {\n",
        "        'key': f\"{key_names[tonic]} {mode}\",\n",
        "        'key_confidence': best_score,\n",
        "        'tonic_stability': tonic_stability,\n",
        "        'triad_strength': triad_strength\n",
        "    }\n",
        "\n",
        "def _analyze_tempo_and_rhythm(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze tempo and rhythmic characteristics.\"\"\"\n",
        "    # Onset detection and tempo estimation\n",
        "    onset_env = lb.onset.onset_strength(y=audio, sr=sr)\n",
        "    tempo_global, beats = lb.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
        "\n",
        "    # Analyze tempo stability using windowed analysis\n",
        "    hop_length = 512\n",
        "    frame_length = 2048\n",
        "    tempo_segments = []\n",
        "\n",
        "    # Windowed tempo analysis\n",
        "    for start in range(0, len(onset_env) - frame_length, hop_length):\n",
        "        segment = onset_env[start:start + frame_length]\n",
        "        if len(segment) >= frame_length:\n",
        "            tempo_segment, _ = lb.beat.beat_track(onset_envelope=segment, sr=sr)\n",
        "            tempo_segments.append(tempo_segment)\n",
        "\n",
        "    if tempo_segments:\n",
        "        tempo_median = np.median(tempo_segments)\n",
        "        tempo_std = np.std(tempo_segments)\n",
        "        tempo_stability = 1 - (tempo_std / (tempo_median + 1e-8))\n",
        "    else:\n",
        "        tempo_median = tempo_global\n",
        "        tempo_stability = 1.0\n",
        "\n",
        "    # Onset analysis\n",
        "    onsets = lb.onset.onset_detect(y=audio, sr=sr, units='time')\n",
        "    onset_rate = len(onsets) / (len(audio) / sr) if len(audio) > 0 else 0\n",
        "\n",
        "    # Rhythmic regularity\n",
        "    if len(onsets) > 2:\n",
        "        onset_intervals = np.diff(onsets)\n",
        "        rhythmic_regularity = 1 - (np.std(onset_intervals) / (np.mean(onset_intervals) + 1e-8))\n",
        "        rhythmic_regularity = np.clip(rhythmic_regularity, 0, 1)\n",
        "    else:\n",
        "        rhythmic_regularity = 0.5\n",
        "\n",
        "    return {\n",
        "        'tempo': float(tempo_median),\n",
        "        'tempo_confidence': float(tempo_stability),\n",
        "        'onset_rate': float(onset_rate),\n",
        "        'rhythmic_regularity': float(rhythmic_regularity)\n",
        "    }\n",
        "\n",
        "def _analyze_spectral_features(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Extract spectral and frequency-domain features.\"\"\"\n",
        "    # Basic spectral features\n",
        "    spectral_centroid = lb.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = lb.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    spectral_contrast = lb.feature.spectral_contrast(y=audio, sr=sr)\n",
        "    zero_crossing_rate = lb.feature.zero_crossing_rate(audio)[0]\n",
        "\n",
        "    # MFCC features for timbral analysis\n",
        "    mfccs = lb.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    mfcc_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "    # Frequency band energy analysis (compatible with mixing mapper)\n",
        "    graves = np.mean(mfcc_mean[0:3])    # Low frequencies (bass)\n",
        "    medios = np.mean(mfcc_mean[3:7])    # Mid frequencies\n",
        "    agudos = np.mean(mfcc_mean[8:12])   # High frequencies (treble)\n",
        "\n",
        "    # Timbral complexity\n",
        "    complejidad_timbral = np.std(mfcc_mean[1:]) * 10  # Scale for compatibility\n",
        "\n",
        "    return {\n",
        "        'spectral_centroid': float(np.mean(spectral_centroid)),\n",
        "        'spectral_rolloff': float(np.mean(spectral_rolloff)),\n",
        "        'spectral_contrast_mean': float(np.mean(spectral_contrast)),\n",
        "        'zero_crossing_rate': float(np.mean(zero_crossing_rate)),\n",
        "        'mfcc_features': mfcc_mean.tolist(),\n",
        "        'graves': float(graves),\n",
        "        'medios': float(medios),\n",
        "        'agudos': float(agudos),\n",
        "        'graves_medios_agudos': [float(graves), float(medios), float(agudos)],\n",
        "        'complejidad_timbral': float(complejidad_timbral)\n",
        "    }\n",
        "\n",
        "def _analyze_dynamic_features(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze dynamic range and loudness characteristics.\"\"\"\n",
        "    # RMS energy and loudness\n",
        "    rms = lb.feature.rms(y=audio)[0]\n",
        "    loudness_mean = np.mean(rms)\n",
        "    loudness_db = 20 * np.log10(loudness_mean + 1e-8)\n",
        "\n",
        "    # Crest factor (peak-to-average ratio)\n",
        "    peak_level = np.max(np.abs(audio))\n",
        "    crest_factor = peak_level / (loudness_mean + 1e-8)\n",
        "\n",
        "    # Dynamic range analysis\n",
        "    percentile_95 = np.percentile(np.abs(audio), 95)\n",
        "    percentile_10 = np.percentile(np.abs(audio), 10)\n",
        "    dynamic_range = 20 * np.log10((percentile_95 + 1e-8) / (percentile_10 + 1e-8))\n",
        "\n",
        "    return {\n",
        "        'loudness_db': float(loudness_db),\n",
        "        'rms_energy': float(loudness_mean),\n",
        "        'crest_factor': float(crest_factor),\n",
        "        'peak_level': float(peak_level),\n",
        "        'dynamic_range': float(dynamic_range)\n",
        "    }\n",
        "\n",
        "def _analyze_harmonic_features(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze harmonic and percussive content.\"\"\"\n",
        "    # Harmonic-percussive separation\n",
        "    y_harmonic, y_percussive = lb.effects.hpss(audio)\n",
        "\n",
        "    # Calculate harmonic ratio (approximation of instrumentalness)\n",
        "    harmonic_energy = np.mean(np.abs(y_harmonic))\n",
        "    total_energy = np.mean(np.abs(audio))\n",
        "    harmonic_ratio = harmonic_energy / (total_energy + 1e-8)\n",
        "\n",
        "    # Percussive ratio\n",
        "    percussive_energy = np.mean(np.abs(y_percussive))\n",
        "    percussive_ratio = percussive_energy / (total_energy + 1e-8)\n",
        "\n",
        "    # Tonnetz features for harmonic complexity\n",
        "    try:\n",
        "        tonnetz = lb.feature.tonnetz(y=audio, sr=sr)\n",
        "        harmonic_complexity = np.std(tonnetz)\n",
        "    except:\n",
        "        harmonic_complexity = 0.5\n",
        "\n",
        "    return {\n",
        "        'instrumentalness': float(harmonic_ratio),\n",
        "        'harmonic_ratio': float(harmonic_ratio),\n",
        "        'percussive_ratio': float(percussive_ratio),\n",
        "        'harmonic_complexity': float(harmonic_complexity)\n",
        "    }\n",
        "\n",
        "def _analyze_spatial_features(audio_stereo: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze stereo spatial characteristics.\"\"\"\n",
        "    if audio_stereo.shape[0] >= 2:\n",
        "        left_channel = audio_stereo[0]\n",
        "        right_channel = audio_stereo[1]\n",
        "\n",
        "        # Stereo correlation\n",
        "        correlation = np.corrcoef(left_channel, right_channel)[0, 1]\n",
        "        stereo_width = 1 - abs(correlation)  # Higher values = wider stereo image\n",
        "        stereo_width = np.clip(stereo_width, 0, 1)\n",
        "\n",
        "        # Phase correlation (mono compatibility)\n",
        "        phase_correlation = correlation\n",
        "\n",
        "    else:\n",
        "        stereo_width = 0.0\n",
        "        phase_correlation = 1.0\n",
        "\n",
        "    return {\n",
        "        'stereo_width': float(stereo_width),\n",
        "        'phase_correlation': float(phase_correlation)\n",
        "    }\n",
        "\n",
        "def _calculate_derived_features(features: Dict[str, Any], audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Calculate additional derived features for mixing recommendations.\"\"\"\n",
        "    # Arrangement density approximation\n",
        "    spectral_flux = np.mean(np.diff(np.abs(lb.stft(audio)), axis=1) ** 2)\n",
        "    arrangement_density = np.clip(spectral_flux / 1000, 0, 1)  # Normalized approximation\n",
        "\n",
        "    # Punch factor (low-frequency contrast)\n",
        "    if 'spectral_contrast_mean' in features:\n",
        "        punch_factor = features['spectral_contrast_mean']\n",
        "    else:\n",
        "        punch_factor = 0.5\n",
        "\n",
        "    # Sub-bass energy\n",
        "    if 'graves' in features:\n",
        "        sub_bass_energy = features['graves']\n",
        "    else:\n",
        "        sub_bass_energy = 0.0\n",
        "\n",
        "    # Loopability score (auto-correlation based)\n",
        "    try:\n",
        "        autocorr = np.correlate(audio, audio, mode='full')\n",
        "        mid = len(autocorr) // 2\n",
        "        if mid + 3*sr < len(autocorr):\n",
        "            loopability_score = np.max(autocorr[mid + sr//2 : mid + 3*sr]) / (np.max(autocorr) + 1e-8)\n",
        "        else:\n",
        "            loopability_score = 0.5\n",
        "    except:\n",
        "        loopability_score = 0.5\n",
        "\n",
        "    return {\n",
        "        'arrangement_density': float(arrangement_density),\n",
        "        'punch_factor': float(punch_factor),\n",
        "        'sub_bass_energy': float(sub_bass_energy),\n",
        "        'loopability_score': float(loopability_score)\n",
        "    }\n",
        "\n",
        "def _get_fallback_features(audio: np.ndarray, sr: int) -> Dict[str, Any]:\n",
        "    \"\"\"Provide fallback features if analysis fails.\"\"\"\n",
        "    return {\n",
        "        # Core features with safe defaults\n",
        "        'key': 'C Major',\n",
        "        'tempo': 120.0,\n",
        "        'spectral_centroid': 2000.0,\n",
        "        'loudness_db': -20.0,\n",
        "        'onset_rate': 3.0,\n",
        "        'rhythmic_regularity': 0.6,\n",
        "        'complejidad_timbral': 8.0,\n",
        "        'graves': -10.0,\n",
        "        'medios': 0.0,\n",
        "        'agudos': -5.0,\n",
        "        'graves_medios_agudos': [-10.0, 0.0, -5.0],\n",
        "        'stereo_width': 0.5,\n",
        "        'crest_factor': 6.0,\n",
        "        'instrumentalness': 0.5,\n",
        "        'arrangement_density': 0.5,\n",
        "        'harmonic_complexity': 0.5,\n",
        "        'duration': len(audio) / sr,\n",
        "        'sample_rate': sr,\n",
        "        'is_stereo': False\n",
        "    }\n",
        "\n",
        "def extract_features_for_mixing(audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main entry point for feature extraction optimized for mixing recommendations.\n",
        "    This function ensures compatibility with the mixing recommendation system.\n",
        "\n",
        "    Args:\n",
        "        audio_data: Audio signal as numpy array\n",
        "        sample_rate: Sample rate of the audio\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with features formatted for mixing recommendations\n",
        "    \"\"\"\n",
        "    # Get full feature analysis\n",
        "    features = analyze_audio_features(audio_data, sample_rate)\n",
        "\n",
        "    # Ensure all required features for mixing recommendations are present\n",
        "    required_features = [\n",
        "        'tempo', 'loudness_db', 'spectral_centroid', 'instrumentalness',\n",
        "        'onset_rate', 'rhythmic_regularity', 'complejidad_timbral',\n",
        "        'graves_medios_agudos', 'stereo_width', 'crest_factor', 'arrangement_density'\n",
        "    ]\n",
        "\n",
        "    # Fill missing features with defaults\n",
        "    for feature in required_features:\n",
        "        if feature not in features:\n",
        "            if feature == 'graves_medios_agudos':\n",
        "                features[feature] = [features.get('graves', -10),\n",
        "                                   features.get('medios', 0),\n",
        "                                   features.get('agudos', -5)]\n",
        "            elif feature == 'tempo':\n",
        "                features[feature] = 120.0\n",
        "            elif feature == 'loudness_db':\n",
        "                features[feature] = -20.0\n",
        "            elif feature == 'spectral_centroid':\n",
        "                features[feature] = 2000.0\n",
        "            else:\n",
        "                features[feature] = 0.5  # Default normalized value\n",
        "\n",
        "    return features\n",
        "\n",
        "def get_audio_summary(features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generate a user-friendly summary of the audio characteristics.\n",
        "\n",
        "    Args:\n",
        "        features: Dictionary of extracted audio features\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with interpretable audio characteristics\n",
        "    \"\"\"\n",
        "    summary = {\n",
        "        'musical_key': features.get('key', 'Unknown'),\n",
        "        'tempo_bpm': round(features.get('tempo', 120), 1),\n",
        "        'duration_seconds': round(features.get('duration', 0), 2),\n",
        "        'overall_loudness_db': round(features.get('loudness_db', -20), 1),\n",
        "        'brightness': 'Bright' if features.get('spectral_centroid', 2000) > 3000 else 'Warm',\n",
        "        'rhythmic_activity': 'High' if features.get('onset_rate', 3) > 5 else 'Moderate' if features.get('onset_rate', 3) > 2 else 'Low',\n",
        "        'stereo_image': 'Wide' if features.get('stereo_width', 0.5) > 0.7 else 'Narrow' if features.get('stereo_width', 0.5) < 0.3 else 'Moderate',\n",
        "        'dynamic_range': 'High' if features.get('crest_factor', 6) > 10 else 'Compressed' if features.get('crest_factor', 6) < 4 else 'Moderate',\n",
        "        'timbral_complexity': 'Complex' if features.get('complejidad_timbral', 8) > 12 else 'Simple' if features.get('complejidad_timbral', 8) < 6 else 'Moderate',\n",
        "        'instrumental_content': 'Highly Instrumental' if features.get('instrumentalness', 0.5) > 0.8 else 'Mixed' if features.get('instrumentalness', 0.5) > 0.3 else 'Vocal-Heavy'\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "    def get_all_feature_names() -> list:\n",
        "        \"\"\"\n",
        "        Returns a list of all feature names extracted by the audio analysis module.\n",
        "        \"\"\"\n",
        "        return [\n",
        "            'key',\n",
        "            'key_confidence',\n",
        "            'tonic_stability',\n",
        "            'triad_strength',\n",
        "            'tempo',\n",
        "            'tempo_confidence',\n",
        "            'onset_rate',\n",
        "            'rhythmic_regularity',\n",
        "            'spectral_centroid',\n",
        "            'spectral_rolloff',\n",
        "            'spectral_contrast_mean',\n",
        "            'zero_crossing_rate',\n",
        "            'mfcc_features',\n",
        "            'graves',\n",
        "            'medios',\n",
        "            'agudos',\n",
        "            'graves_medios_agudos',\n",
        "            'complejidad_timbral',\n",
        "            'loudness_db',\n",
        "            'rms_energy',\n",
        "            'crest_factor',\n",
        "            'peak_level',\n",
        "            'dynamic_range',\n",
        "            'instrumentalness',\n",
        "            'harmonic_ratio',\n",
        "            'percussive_ratio',\n",
        "            'harmonic_complexity',\n",
        "            'stereo_width',\n",
        "            'phase_correlation',\n",
        "            'arrangement_density',\n",
        "            'punch_factor',\n",
        "            'sub_bass_energy',\n",
        "            'loopability_score',\n",
        "            'duration',\n",
        "            'sample_rate',\n",
        "            'is_stereo'\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIFrM7h-OVU"
      },
      "source": [
        "## Semantic_Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE3vysyNUgqn"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Any, List, Tuple, Callable\n",
        "import numpy as np\n",
        "from functools import lru_cache\n",
        "\n",
        "# ====== CONFIGURATION AND NORMALIZATION RANGES ======\n",
        "\n",
        "# Define feature normalization ranges for consistent semantic mapping\n",
        "SEMANTIC_FEATURE_RANGES = {\n",
        "    # Tonal Features\n",
        "    'key_confidence': {'min': 0, 'max': 1, 'optimal': 0.8},\n",
        "    'tonic_stability': {'min': 0, 'max': 1, 'optimal': 0.7},\n",
        "    'triad_strength': {'min': 0, 'max': 1, 'optimal': 0.6},\n",
        "\n",
        "    # Rhythmic Features\n",
        "    'tempo': {'min': 60, 'max': 200, 'optimal_low': 80, 'optimal_high': 140},\n",
        "    'tempo_confidence': {'min': 0, 'max': 1, 'optimal': 0.8},\n",
        "    'onset_rate': {'min': 0, 'max': 10, 'optimal_low': 2, 'optimal_high': 6},\n",
        "    'rhythmic_regularity': {'min': 0, 'max': 1, 'optimal': 0.7},\n",
        "\n",
        "    # Spectral Features\n",
        "    'spectral_centroid': {'min': 500, 'max': 8000, 'bright_threshold': 3500, 'dark_threshold': 1500},\n",
        "    'spectral_rolloff': {'min': 2000, 'max': 16000, 'bright_threshold': 8000},\n",
        "    'spectral_contrast_mean': {'min': 0, 'max': 30, 'high_threshold': 20},\n",
        "    'zero_crossing_rate': {'min': 0, 'max': 1, 'percussive_threshold': 0.15},\n",
        "    'graves': {'min': -40, 'max': 20, 'strong_threshold': -5, 'weak_threshold': -25},\n",
        "    'medios': {'min': -30, 'max': 25, 'strong_threshold': 5, 'weak_threshold': -15},\n",
        "    'agudos': {'min': -35, 'max': 15, 'strong_threshold': 0, 'weak_threshold': -20},\n",
        "    'complejidad_timbral': {'min': 0, 'max': 25, 'complex_threshold': 15, 'simple_threshold': 5},\n",
        "\n",
        "    # Dynamic Features\n",
        "    'loudness_db': {'min': -60, 'max': 0, 'loud_threshold': -10, 'quiet_threshold': -35},\n",
        "    'rms_energy': {'min': 0, 'max': 1, 'high_threshold': 0.3, 'low_threshold': 0.05},\n",
        "    'crest_factor': {'min': 1, 'max': 25, 'dynamic_threshold': 10, 'compressed_threshold': 4},\n",
        "    'dynamic_range': {'min': 0, 'max': 60, 'wide_threshold': 30, 'narrow_threshold': 10},\n",
        "\n",
        "    # Structural Features\n",
        "    'instrumentalness': {'min': 0, 'max': 1, 'instrumental_threshold': 0.7},\n",
        "    'harmonic_ratio': {'min': 0, 'max': 1, 'harmonic_threshold': 0.6},\n",
        "    'percussive_ratio': {'min': 0, 'max': 1, 'percussive_threshold': 0.4},\n",
        "    'harmonic_complexity': {'min': 0, 'max': 15, 'complex_threshold': 8},\n",
        "    'arrangement_density': {'min': 0, 'max': 1, 'dense_threshold': 0.7, 'sparse_threshold': 0.3},\n",
        "    'punch_factor': {'min': 0, 'max': 1, 'punchy_threshold': 0.6},\n",
        "\n",
        "    # Spatial Features\n",
        "    'stereo_width': {'min': 0, 'max': 1, 'wide_threshold': 0.7, 'narrow_threshold': 0.3},\n",
        "    'phase_correlation': {'min': -1, 'max': 1, 'good_threshold': 0.6}\n",
        "}\n",
        "\n",
        "'''\n",
        "# Define key mappings for semantic interpretation\n",
        "KEY_SEMANTIC_MAP = {\n",
        "    'C': {'mood': 'stable', 'energy': 'neutral', 'character': 'foundational'},\n",
        "    'C#': {'mood': 'mysterious', 'energy': 'medium', 'character': 'edgy'},\n",
        "    'D': {'mood': 'bright', 'energy': 'high', 'character': 'triumphant'},\n",
        "    'D#': {'mood': 'dramatic', 'energy': 'intense', 'character': 'bold'},\n",
        "    'E': {'mood': 'confident', 'energy': 'high', 'character': 'assertive'},\n",
        "    'F': {'mood': 'warm', 'energy': 'medium', 'character': 'pastoral'},\n",
        "    'F#': {'mood': 'dreamy', 'energy': 'medium', 'character': 'ethereal'},\n",
        "    'G': {'mood': 'uplifting', 'energy': 'high', 'character': 'joyful'},\n",
        "    'G#': {'mood': 'tense', 'energy': 'high', 'character': 'aggressive'},\n",
        "    'A': {'mood': 'balanced', 'energy': 'medium-high', 'character': 'natural'},\n",
        "    'A#': {'mood': 'dark', 'energy': 'intense', 'character': 'ominous'},\n",
        "    'B': {'mood': 'restless', 'energy': 'high', 'character': 'driving'}\n",
        "}\n",
        "'''\n",
        "# Enhanced key semantic mapping with popular music terminology\n",
        "KEY_SEMANTIC_MAP = {\n",
        "    'C': {\n",
        "        'mood': ['stable', 'grounded', 'foundational'],\n",
        "        'energy': ['neutral', 'balanced', 'steady'],\n",
        "        'character': ['classic', 'pure', 'natural'],\n",
        "        'mixing_quality': ['clear', 'fundamental', 'reference']\n",
        "    },\n",
        "    'C#': {\n",
        "        'mood': ['mysterious', 'edgy', 'tense'],\n",
        "        'energy': ['medium', 'restless', 'charged'],\n",
        "        'character': ['modern', 'urban', 'sophisticated'],\n",
        "        'mixing_quality': ['sharp', 'cutting', 'distinctive']\n",
        "    },\n",
        "    'D': {\n",
        "        'mood': ['bright', 'optimistic', 'celebratory'],\n",
        "        'energy': ['high', 'uplifting', 'energetic'],\n",
        "        'character': ['triumphant', 'joyful', 'bold'],\n",
        "        'mixing_quality': ['brilliant', 'open', 'airy']\n",
        "    },\n",
        "    'D#': {\n",
        "        'mood': ['dramatic', 'intense', 'passionate'],\n",
        "        'energy': ['powerful', 'driving', 'forceful'],\n",
        "        'character': ['bold', 'theatrical', 'commanding'],\n",
        "        'mixing_quality': ['punchy', 'aggressive', 'impactful']\n",
        "    },\n",
        "    'E': {\n",
        "        'mood': ['confident', 'assertive', 'strong'],\n",
        "        'energy': ['high', 'dynamic', 'vibrant'],\n",
        "        'character': ['heroic', 'determined', 'resilient'],\n",
        "        'mixing_quality': ['strong', 'present', 'forward']\n",
        "    },\n",
        "    'F': {\n",
        "        'mood': ['warm', 'gentle', 'peaceful'],\n",
        "        'energy': ['medium', 'relaxed', 'flowing'],\n",
        "        'character': ['pastoral', 'intimate', 'comfortable'],\n",
        "        'mixing_quality': ['warm', 'rounded', 'smooth']\n",
        "    },\n",
        "    'F#': {\n",
        "        'mood': ['dreamy', 'ethereal', 'floating'],\n",
        "        'energy': ['medium', 'ambient', 'spacious'],\n",
        "        'character': ['mystical', 'otherworldly', 'atmospheric'],\n",
        "        'mixing_quality': ['spacious', 'dreamy', 'reverberant']\n",
        "    },\n",
        "    'G': {\n",
        "        'mood': ['uplifting', 'joyful', 'positive'],\n",
        "        'energy': ['high', 'bright', 'cheerful'],\n",
        "        'character': ['happy', 'carefree', 'playful'],\n",
        "        'mixing_quality': ['bright', 'sparkling', 'lively']\n",
        "    },\n",
        "    'G#': {\n",
        "        'mood': ['tense', 'aggressive', 'dark'],\n",
        "        'energy': ['intense', 'heavy', 'powerful'],\n",
        "        'character': ['menacing', 'gothic', 'fierce'],\n",
        "        'mixing_quality': ['heavy', 'dense', 'compressed']\n",
        "    },\n",
        "    'A': {\n",
        "        'mood': ['balanced', 'natural', 'honest'],\n",
        "        'energy': ['medium-high', 'stable', 'grounded'],\n",
        "        'character': ['authentic', 'genuine', 'timeless'],\n",
        "        'mixing_quality': ['natural', 'balanced', 'true']\n",
        "    },\n",
        "    'A#': {\n",
        "        'mood': ['dark', 'brooding', 'mysterious'],\n",
        "        'energy': ['intense', 'deep', 'heavy'],\n",
        "        'character': ['ominous', 'serious', 'contemplative'],\n",
        "        'mixing_quality': ['deep', 'rich', 'full']\n",
        "    },\n",
        "    'B': {\n",
        "        'mood': ['restless', 'urgent', 'driving'],\n",
        "        'energy': ['high', 'propulsive', 'unstable'],\n",
        "        'character': ['anxious', 'pushing', 'relentless'],\n",
        "        'mixing_quality': ['tight', 'focused', 'precise']\n",
        "    }\n",
        "}\n",
        "\n",
        "# ====== MODULAR RULE-BASED STRUCTURES ======\n",
        "'''\n",
        "# Genre inference rules as modular structures\n",
        "GENRE_INFERENCE_RULES = [\n",
        "    {\n",
        "        'genre': 'heavy_metal',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('spectral_centroid', 2500) > 2500 and\n",
        "            f.get('graves', -15) > -10 and\n",
        "            f.get('complejidad_timbral', 8) > 12 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.4 and\n",
        "            f.get('tempo', 120) > 140\n",
        "        ),\n",
        "        'confidence_factors': ['spectral_centroid', 'graves', 'complejidad_timbral', 'percussive_ratio', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'rock',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('spectral_centroid', 2500) > 2500 and\n",
        "            f.get('graves', -15) > -10 and\n",
        "            f.get('complejidad_timbral', 8) > 12 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.4 and\n",
        "            f.get('tempo', 120) <= 140\n",
        "        ),\n",
        "        'confidence_factors': ['spectral_centroid', 'graves', 'complejidad_timbral', 'percussive_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'electronic_dance',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.5 and\n",
        "            f.get('onset_rate', 3) > 4 and\n",
        "            f.get('instrumentalness', 0.5) > 0.7 and\n",
        "            f.get('tempo', 120) > 120\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'onset_rate', 'instrumentalness', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'electronic_ambient',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.5 and\n",
        "            f.get('onset_rate', 3) > 4 and\n",
        "            f.get('instrumentalness', 0.5) > 0.7 and\n",
        "            f.get('tempo', 120) <= 120\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'onset_rate', 'instrumentalness']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'acoustic_folk',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.6 and\n",
        "            f.get('complejidad_timbral', 8) < 8 and\n",
        "            f.get('spectral_centroid', 2500) < 3000\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'jazz_complex',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('complejidad_timbral', 8) > 10 and\n",
        "            f.get('onset_rate', 3) < 6 and\n",
        "            f.get('spectral_centroid', 2500) > 2000 and\n",
        "            f.get('spectral_centroid', 2500) < 4000\n",
        "        ),\n",
        "        'confidence_factors': ['complejidad_timbral', 'onset_rate', 'spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'classical_orchestral',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.8 and\n",
        "            f.get('complejidad_timbral', 8) > 8 and\n",
        "            f.get('tempo', 120) < 150 and\n",
        "            f.get('percussive_ratio', 0.3) < 0.3\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'tempo', 'percussive_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'hip_hop',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.6 and\n",
        "            f.get('graves', -15) > -8 and\n",
        "            f.get('onset_rate', 3) > 3 and\n",
        "            f.get('tempo', 120) > 80 and\n",
        "            f.get('tempo', 120) < 140\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'graves', 'onset_rate', 'tempo']\n",
        "    }\n",
        "]\n",
        "'''\n",
        "# Updated genre inference rules focused on popular genres\n",
        "GENRE_INFERENCE_RULES = [\n",
        "    {\n",
        "        'genre': 'pop',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) < 0.6 and\n",
        "            f.get('tempo', 120) > 100 and\n",
        "            f.get('tempo', 120) < 140 and\n",
        "            f.get('complejidad_timbral', 8) < 12 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.3\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'tempo', 'complejidad_timbral', 'percussive_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'rock',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('spectral_centroid', 2500) > 2200 and\n",
        "            f.get('graves', -15) > -12 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.35 and\n",
        "            f.get('tempo', 120) > 100 and\n",
        "            f.get('complejidad_timbral', 8) > 8\n",
        "        ),\n",
        "        'confidence_factors': ['spectral_centroid', 'graves', 'percussive_ratio', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'heavy_metal',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('spectral_centroid', 2500) > 3000 and\n",
        "            f.get('graves', -15) > -8 and\n",
        "            f.get('complejidad_timbral', 8) > 14 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.4 and\n",
        "            f.get('tempo', 120) > 130\n",
        "        ),\n",
        "        'confidence_factors': ['spectral_centroid', 'graves', 'complejidad_timbral', 'percussive_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'hip_hop',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.5 and\n",
        "            f.get('graves', -15) > -6 and\n",
        "            f.get('onset_rate', 3) > 2.5 and\n",
        "            f.get('tempo', 120) > 70 and\n",
        "            f.get('tempo', 120) < 150 and\n",
        "            f.get('instrumentalness', 0.5) > 0.2\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'graves', 'onset_rate', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'electronic_dance',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.4 and\n",
        "            f.get('onset_rate', 3) > 3.5 and\n",
        "            f.get('instrumentalness', 0.5) > 0.6 and\n",
        "            f.get('tempo', 120) > 120 and\n",
        "            f.get('complejidad_timbral', 8) > 9\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'onset_rate', 'instrumentalness', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'indie_folk',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.4 and\n",
        "            f.get('instrumentalness', 0.5) < 0.8 and\n",
        "            f.get('complejidad_timbral', 8) < 10 and\n",
        "            f.get('spectral_centroid', 2500) < 3200 and\n",
        "            f.get('tempo', 120) < 130 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.4\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid', 'harmonic_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'r_and_b',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('graves', -15) > -10 and\n",
        "            f.get('instrumentalness', 0.5) < 0.7 and\n",
        "            f.get('tempo', 120) > 80 and\n",
        "            f.get('tempo', 120) < 130 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.4 and\n",
        "            f.get('complejidad_timbral', 8) > 6\n",
        "        ),\n",
        "        'confidence_factors': ['graves', 'instrumentalness', 'tempo', 'harmonic_ratio']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'country',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.3 and\n",
        "            f.get('instrumentalness', 0.5) < 0.7 and\n",
        "            f.get('complejidad_timbral', 8) < 9 and\n",
        "            f.get('spectral_centroid', 2500) > 2000 and\n",
        "            f.get('spectral_centroid', 2500) < 3500 and\n",
        "            f.get('tempo', 120) > 90 and\n",
        "            f.get('tempo', 120) < 160\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'alternative_rock',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('spectral_centroid', 2500) > 2400 and\n",
        "            f.get('complejidad_timbral', 8) > 9 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.3 and\n",
        "            f.get('tempo', 120) > 90 and\n",
        "            f.get('tempo', 120) < 150 and\n",
        "            f.get('instrumentalness', 0.5) > 0.3\n",
        "        ),\n",
        "        'confidence_factors': ['spectral_centroid', 'complejidad_timbral', 'percussive_ratio', 'tempo']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'reggaeton',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.5 and\n",
        "            f.get('graves', -15) > -8 and\n",
        "            f.get('tempo', 120) > 85 and\n",
        "            f.get('tempo', 120) < 105 and\n",
        "            f.get('onset_rate', 3) > 3 and\n",
        "            f.get('instrumentalness', 0.5) > 0.4\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'graves', 'tempo', 'onset_rate']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'jazz_fusion',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('complejidad_timbral', 8) > 11 and\n",
        "            f.get('onset_rate', 3) > 2 and\n",
        "            f.get('onset_rate', 3) < 6 and\n",
        "            f.get('spectral_centroid', 2500) > 2200 and\n",
        "            f.get('instrumentalness', 0.5) > 0.6 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.5\n",
        "        ),\n",
        "        'confidence_factors': ['complejidad_timbral', 'onset_rate', 'spectral_centroid', 'instrumentalness']\n",
        "    },\n",
        "    {\n",
        "        'genre': 'classical_orchestral',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.85 and\n",
        "            f.get('complejidad_timbral', 8) > 12 and\n",
        "            f.get('tempo', 120) < 160 and\n",
        "            f.get('percussive_ratio', 0.3) < 0.25 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.7 and\n",
        "            f.get('onset_rate', 3) < 4\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'percussive_ratio', 'harmonic_ratio']\n",
        "    }\n",
        "]\n",
        "\n",
        "# Mood inference rules as modular structures\n",
        "MOOD_INFERENCE_RULES = [\n",
        "    {\n",
        "        'mood': 'energetic',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('tempo', 120) > 140 and\n",
        "            f.get('loudness_db', -20) > -15\n",
        "        ),\n",
        "        'confidence_factors': ['tempo', 'loudness_db']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'intense',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('tempo', 120) > 140 and\n",
        "            f.get('loudness_db', -20) > -15\n",
        "        ),\n",
        "        'confidence_factors': ['tempo', 'loudness_db']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'calm',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('tempo', 120) < 90 and\n",
        "            f.get('dynamic_range', 20) < 15\n",
        "        ),\n",
        "        'confidence_factors': ['tempo', 'dynamic_range']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'subdued',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('tempo', 120) < 90 and\n",
        "            f.get('dynamic_range', 20) < 15\n",
        "        ),\n",
        "        'confidence_factors': ['tempo', 'dynamic_range']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'bright',\n",
        "        'conditions': lambda f: f.get('spectral_centroid', 2500) > 4000,\n",
        "        'confidence_factors': ['spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'warm',\n",
        "        'conditions': lambda f: f.get('spectral_centroid', 2500) < 1500,\n",
        "        'confidence_factors': ['spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'mellow',\n",
        "        'conditions': lambda f: f.get('spectral_centroid', 2500) < 1500,\n",
        "        'confidence_factors': ['spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'unstable',\n",
        "        'conditions': lambda f: f.get('tonic_stability', 0.7) < 0.5,\n",
        "        'confidence_factors': ['tonic_stability']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'stable',\n",
        "        'conditions': lambda f: f.get('tonic_stability', 0.7) > 0.8,\n",
        "        'confidence_factors': ['tonic_stability']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'powerful',\n",
        "        'conditions': lambda f: f.get('graves', -15) > 0,\n",
        "        'confidence_factors': ['graves']\n",
        "    },\n",
        "    {\n",
        "        'mood': 'light',\n",
        "        'conditions': lambda f: f.get('graves', -15) < -25,\n",
        "        'confidence_factors': ['graves']\n",
        "    }\n",
        "]\n",
        "\n",
        "# Instrumentation classification rules\n",
        "'''\n",
        "INSTRUMENTATION_RULES = [\n",
        "    {\n",
        "        'type': 'band_based',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.3 and\n",
        "            f.get('instrumentalness', 0.5) < 0.8 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.3 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.4\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'percussive_ratio', 'harmonic_ratio']\n",
        "    },\n",
        "    {\n",
        "        'type': 'orchestral',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.8 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.7 and\n",
        "            f.get('percussive_ratio', 0.3) < 0.3 and\n",
        "            f.get('complejidad_timbral', 8) > 10\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'harmonic_ratio', 'percussive_ratio', 'complejidad_timbral']\n",
        "    },\n",
        "    {\n",
        "        'type': 'synth_heavy',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.7 and\n",
        "            f.get('complejidad_timbral', 8) > 12 and\n",
        "            f.get('spectral_centroid', 2500) > 3000\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid']\n",
        "    },\n",
        "    {\n",
        "        'type': 'hybrid',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.5 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.4 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.4 and\n",
        "            f.get('complejidad_timbral', 8) > 8\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'harmonic_ratio', 'percussive_ratio', 'complejidad_timbral']\n",
        "    }\n",
        "]\n",
        "'''\n",
        "# Updated instrumentation classification for popular genres\n",
        "INSTRUMENTATION_RULES = [\n",
        "    {\n",
        "        'type': 'pop_rock_band',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.2 and\n",
        "            f.get('instrumentalness', 0.5) < 0.7 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.3 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.4 and\n",
        "            f.get('complejidad_timbral', 8) < 12\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'percussive_ratio', 'harmonic_ratio']\n",
        "    },\n",
        "    {\n",
        "        'type': 'electronic_production',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.6 and\n",
        "            f.get('complejidad_timbral', 8) > 10 and\n",
        "            f.get('spectral_centroid', 2500) > 2800 and\n",
        "            f.get('percussive_ratio', 0.3) > 0.4\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid', 'percussive_ratio']\n",
        "    },\n",
        "    {\n",
        "        'type': 'acoustic_ensemble',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.5 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.6 and\n",
        "            f.get('percussive_ratio', 0.3) < 0.4 and\n",
        "            f.get('complejidad_timbral', 8) < 10 and\n",
        "            f.get('spectral_centroid', 2500) < 3500\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'harmonic_ratio', 'percussive_ratio', 'complejidad_timbral']\n",
        "    },\n",
        "    {\n",
        "        'type': 'hip_hop_production',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('percussive_ratio', 0.3) > 0.5 and\n",
        "            f.get('graves', -15) > -8 and\n",
        "            f.get('instrumentalness', 0.5) > 0.3 and\n",
        "            f.get('complejidad_timbral', 8) > 6\n",
        "        ),\n",
        "        'confidence_factors': ['percussive_ratio', 'graves', 'instrumentalness']\n",
        "    },\n",
        "    {\n",
        "        'type': 'orchestral_classical',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.8 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.7 and\n",
        "            f.get('percussive_ratio', 0.3) < 0.2 and\n",
        "            f.get('complejidad_timbral', 8) > 12 and\n",
        "            f.get('onset_rate', 3) < 4\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'harmonic_ratio', 'percussive_ratio', 'complejidad_timbral']\n",
        "    },\n",
        "    {\n",
        "        'type': 'indie_alternative',\n",
        "        'conditions': lambda f: (\n",
        "            f.get('instrumentalness', 0.5) > 0.4 and\n",
        "            f.get('instrumentalness', 0.5) < 0.8 and\n",
        "            f.get('complejidad_timbral', 8) > 8 and\n",
        "            f.get('spectral_centroid', 2500) > 2200 and\n",
        "            f.get('harmonic_ratio', 0.5) > 0.3\n",
        "        ),\n",
        "        'confidence_factors': ['instrumentalness', 'complejidad_timbral', 'spectral_centroid']\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# ====== CONFIDENCE CALCULATION UTILITIES ======\n",
        "\n",
        "def calculate_rule_confidence(features: Dict[str, Any], confidence_factors: List[str]) -> float:\n",
        "    \"\"\"Calculate confidence score based on how well features match their optimal ranges.\"\"\"\n",
        "    if not confidence_factors:\n",
        "        return 0.5\n",
        "\n",
        "    confidences = []\n",
        "\n",
        "    for factor in confidence_factors:\n",
        "        if factor not in features:\n",
        "            continue\n",
        "\n",
        "        value = features[factor]\n",
        "        if factor not in SEMANTIC_FEATURE_RANGES:\n",
        "            confidences.append(0.5)\n",
        "            continue\n",
        "\n",
        "        range_info = SEMANTIC_FEATURE_RANGES[factor]\n",
        "\n",
        "        # Calculate distance from optimal value or range\n",
        "        if 'optimal' in range_info:\n",
        "            optimal = range_info['optimal']\n",
        "            max_distance = max(abs(range_info['max'] - optimal), abs(range_info['min'] - optimal))\n",
        "            distance = abs(value - optimal)\n",
        "            confidence = max(0, 1 - (distance / max_distance))\n",
        "        elif 'optimal_low' in range_info and 'optimal_high' in range_info:\n",
        "            opt_low, opt_high = range_info['optimal_low'], range_info['optimal_high']\n",
        "            if opt_low <= value <= opt_high:\n",
        "                confidence = 1.0\n",
        "            else:\n",
        "                distance = min(abs(value - opt_low), abs(value - opt_high))\n",
        "                max_distance = max(abs(range_info['max'] - opt_high), abs(range_info['min'] - opt_low))\n",
        "                confidence = max(0, 1 - (distance / max_distance))\n",
        "        else:\n",
        "            # Use normalized position as confidence proxy\n",
        "            normalized = (value - range_info['min']) / (range_info['max'] - range_info['min'])\n",
        "            confidence = 1 - abs(0.5 - np.clip(normalized, 0, 1))\n",
        "\n",
        "        confidences.append(confidence)\n",
        "\n",
        "    return np.mean(confidences) if confidences else 0.5\n",
        "\n",
        "def apply_inference_rules(features: Dict[str, Any], rules: List[Dict]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Apply modular inference rules and return results with confidence scores.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for rule in rules:\n",
        "        if rule['conditions'](features):\n",
        "            confidence = calculate_rule_confidence(features, rule['confidence_factors'])\n",
        "\n",
        "            result_key = 'genre' if 'genre' in rule else ('mood' if 'mood' in rule else 'type')\n",
        "            result = {\n",
        "                result_key: rule[result_key],\n",
        "                'confidence': confidence,\n",
        "                'matched_factors': rule['confidence_factors']\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ====== CACHING UTILITIES ======\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def compute_mfcc_characteristics(mfcc_tuple: Tuple) -> Dict[str, Any]:\n",
        "    \"\"\"Cached computation of MFCC characteristics.\"\"\"\n",
        "    if not mfcc_tuple:\n",
        "        return {'variance': 0, 'timbral_character': 'neutral', 'complexity': 'moderate'}\n",
        "\n",
        "    mfcc_array = np.array(mfcc_tuple)\n",
        "    variance = float(np.var(mfcc_array))\n",
        "\n",
        "    if variance > 100:\n",
        "        return {'variance': variance, 'timbral_character': 'highly_varied', 'complexity': 'complex'}\n",
        "    elif variance < 20:\n",
        "        return {'variance': variance, 'timbral_character': 'consistent', 'complexity': 'simple'}\n",
        "    else:\n",
        "        return {'variance': variance, 'timbral_character': 'moderately_varied', 'complexity': 'moderate'}\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def compute_energy_metrics(tempo: float, loudness_db: float, onset_rate: float,\n",
        "                          rms_energy: float, percussive_ratio: float) -> Dict[str, float]:\n",
        "    \"\"\"Cached computation of energy-related metrics.\"\"\"\n",
        "    tempo_score = normalize_with_context(tempo, 'tempo')['normalized']\n",
        "    loudness_score = normalize_with_context(loudness_db, 'loudness_db')['normalized']\n",
        "    onset_score = normalize_with_context(onset_rate, 'onset_rate')['normalized']\n",
        "    rms_score = normalize_with_context(rms_energy, 'rms_energy')['normalized']\n",
        "    percussive_score = normalize_with_context(percussive_ratio, 'percussive_ratio')['normalized']\n",
        "\n",
        "    # Weighted average (tempo and loudness are most important for energy)\n",
        "    energy_score = (tempo_score * 0.3 + loudness_score * 0.3 +\n",
        "                   onset_score * 0.2 + rms_score * 0.1 + percussive_score * 0.1)\n",
        "\n",
        "    return {\n",
        "        'energy_score': energy_score,\n",
        "        'tempo_score': tempo_score,\n",
        "        'loudness_score': loudness_score,\n",
        "        'onset_score': onset_score,\n",
        "        'rms_score': rms_score,\n",
        "        'percussive_score': percussive_score\n",
        "    }\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def compute_complexity_metrics(timbral: float, harmonic: float,\n",
        "                              arrangement: float, contrast: float) -> Dict[str, float]:\n",
        "    \"\"\"Cached computation of complexity-related metrics.\"\"\"\n",
        "    timbral_norm = normalize_with_context(timbral, 'complejidad_timbral')['normalized']\n",
        "    harmonic_norm = normalize_with_context(harmonic, 'harmonic_complexity')['normalized']\n",
        "    arrangement_norm = normalize_with_context(arrangement, 'arrangement_density')['normalized']\n",
        "    contrast_norm = normalize_with_context(contrast, 'spectral_contrast_mean')['normalized']\n",
        "\n",
        "    complexity_score = (timbral_norm * 0.4 + harmonic_norm * 0.3 +\n",
        "                       arrangement_norm * 0.2 + contrast_norm * 0.1)\n",
        "\n",
        "    return {\n",
        "        'complexity_score': complexity_score,\n",
        "        'timbral_norm': timbral_norm,\n",
        "        'harmonic_norm': harmonic_norm,\n",
        "        'arrangement_norm': arrangement_norm,\n",
        "        'contrast_norm': contrast_norm\n",
        "    }\n",
        "\n",
        "# ====== NORMALIZATION AND INTERPRETATION FUNCTIONS ======\n",
        "\n",
        "def normalize_with_context(value: float, feature_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Normalize feature value and provide semantic context.\n",
        "    Returns normalized value plus semantic interpretation.\n",
        "    \"\"\"\n",
        "    if feature_name not in SEMANTIC_FEATURE_RANGES:\n",
        "        return {\n",
        "            'normalized': np.clip(float(value), 0, 1),\n",
        "            'intensity': 'moderate',\n",
        "            'semantic_level': 'neutral'\n",
        "        }\n",
        "\n",
        "    range_info = SEMANTIC_FEATURE_RANGES[feature_name]\n",
        "\n",
        "    # Basic normalization\n",
        "    normalized = (value - range_info['min']) / (range_info['max'] - range_info['min'])\n",
        "    normalized = np.clip(normalized, 0, 1)\n",
        "\n",
        "    # Intensity mapping\n",
        "    if normalized < 0.2:\n",
        "        intensity = 'very_low'\n",
        "    elif normalized < 0.4:\n",
        "        intensity = 'low'\n",
        "    elif normalized < 0.6:\n",
        "        intensity = 'moderate'\n",
        "    elif normalized < 0.8:\n",
        "        intensity = 'high'\n",
        "    else:\n",
        "        intensity = 'very_high'\n",
        "\n",
        "    # Feature-specific semantic interpretation\n",
        "    semantic_level = get_feature_semantic_level(value, feature_name, range_info)\n",
        "\n",
        "    return {\n",
        "        'raw_value': value,\n",
        "        'normalized': normalized,\n",
        "        'intensity': intensity,\n",
        "        'semantic_level': semantic_level\n",
        "    }\n",
        "\n",
        "'''\n",
        "def get_feature_semantic_level(value: float, feature_name: str, range_info: Dict) -> str:\n",
        "    \"\"\"Get semantic interpretation for specific feature types.\"\"\"\n",
        "\n",
        "    # Spectral brightness interpretation\n",
        "    if feature_name == 'spectral_centroid':\n",
        "        if value > range_info.get('bright_threshold', 3500):\n",
        "            return 'bright'\n",
        "        elif value < range_info.get('dark_threshold', 1500):\n",
        "            return 'dark'\n",
        "        else:\n",
        "            return 'balanced'\n",
        "\n",
        "    # Tempo energy interpretation\n",
        "    elif feature_name == 'tempo':\n",
        "        if value < 80:\n",
        "            return 'slow'\n",
        "        elif value < 110:\n",
        "            return 'moderate'\n",
        "        elif value < 140:\n",
        "            return 'energetic'\n",
        "        else:\n",
        "            return 'fast'\n",
        "\n",
        "    # Frequency band strength interpretation\n",
        "    elif feature_name in ['graves', 'medios', 'agudos']:\n",
        "        strong_thresh = range_info.get('strong_threshold', 0)\n",
        "        weak_thresh = range_info.get('weak_threshold', -20)\n",
        "\n",
        "        if value > strong_thresh:\n",
        "            return 'strong'\n",
        "        elif value < weak_thresh:\n",
        "            return 'weak'\n",
        "        else:\n",
        "            return 'moderate'\n",
        "\n",
        "    # Dynamic range interpretation\n",
        "    elif feature_name == 'crest_factor':\n",
        "        if value > range_info.get('dynamic_threshold', 10):\n",
        "            return 'very_dynamic'\n",
        "        elif value < range_info.get('compressed_threshold', 4):\n",
        "            return 'compressed'\n",
        "        else:\n",
        "            return 'moderate_dynamics'\n",
        "\n",
        "    # Binary threshold features\n",
        "    elif feature_name in ['instrumentalness', 'harmonic_ratio', 'percussive_ratio']:\n",
        "        threshold = range_info.get(f\"{feature_name.split('_')[0]}_threshold\", 0.5)\n",
        "        return 'high' if value > threshold else 'low'\n",
        "\n",
        "    # Default intensity-based mapping\n",
        "    else:\n",
        "        if value > range_info.get('high_threshold', range_info['max'] * 0.7):\n",
        "            return 'high'\n",
        "        elif value < range_info.get('low_threshold', range_info['max'] * 0.3):\n",
        "            return 'low'\n",
        "        else:\n",
        "            return 'moderate'\n",
        "\n",
        "'''\n",
        "\n",
        "def get_feature_semantic_level(value: float, feature_name: str, range_info: Dict) -> str:\n",
        "    \"\"\"Get semantic interpretation for specific feature types with broader vocabulary.\"\"\"\n",
        "\n",
        "    # Spectral brightness interpretation - expanded vocabulary\n",
        "    if feature_name == 'spectral_centroid':\n",
        "        if value > range_info.get('very_bright_threshold', 4500):\n",
        "            return 'crystalline'\n",
        "        elif value > range_info.get('bright_threshold', 3500):\n",
        "            return 'bright'\n",
        "        elif value > range_info.get('warm_threshold', 2500):\n",
        "            return 'warm'\n",
        "        elif value > range_info.get('neutral_threshold', 1800):\n",
        "            return 'balanced'\n",
        "        elif value > range_info.get('mellow_threshold', 1200):\n",
        "            return 'mellow'\n",
        "        else:\n",
        "            return 'dark'\n",
        "\n",
        "    # Tempo energy interpretation - more nuanced\n",
        "    elif feature_name == 'tempo':\n",
        "        if value < 60:\n",
        "            return 'ballad'\n",
        "        elif value < 90:\n",
        "            return 'slow'\n",
        "        elif value < 110:\n",
        "            return 'moderate'\n",
        "        elif value < 130:\n",
        "            return 'energetic'\n",
        "        elif value < 160:\n",
        "            return 'driving'\n",
        "        else:\n",
        "            return 'intense'\n",
        "\n",
        "    # Frequency band strength interpretation - more descriptive\n",
        "    elif feature_name in ['graves', 'medios', 'agudos']:\n",
        "        very_strong_thresh = range_info.get('very_strong_threshold', 5)\n",
        "        strong_thresh = range_info.get('strong_threshold', 0)\n",
        "        moderate_thresh = range_info.get('moderate_threshold', -10)\n",
        "        weak_thresh = range_info.get('weak_threshold', -20)\n",
        "\n",
        "        if value > very_strong_thresh:\n",
        "            return 'punchy' if feature_name == 'graves' else ('crisp' if feature_name == 'agudos' else 'full')\n",
        "        elif value > strong_thresh:\n",
        "            return 'strong'\n",
        "        elif value > moderate_thresh:\n",
        "            return 'moderate'\n",
        "        elif value > weak_thresh:\n",
        "            return 'subtle'\n",
        "        else:\n",
        "            return 'weak'\n",
        "\n",
        "    # Dynamic range interpretation - mixing-focused terms\n",
        "    elif feature_name == 'crest_factor':\n",
        "        if value > range_info.get('very_dynamic_threshold', 15):\n",
        "            return 'wide_dynamic'\n",
        "        elif value > range_info.get('dynamic_threshold', 10):\n",
        "            return 'dynamic'\n",
        "        elif value > range_info.get('moderate_threshold', 6):\n",
        "            return 'controlled'\n",
        "        elif value > range_info.get('compressed_threshold', 3):\n",
        "            return 'compressed'\n",
        "        else:\n",
        "            return 'heavily_limited'\n",
        "\n",
        "    # Binary threshold features - more descriptive\n",
        "    elif feature_name in ['instrumentalness', 'harmonic_ratio', 'percussive_ratio']:\n",
        "        threshold_high = range_info.get(f\"{feature_name.split('_')[0]}_high_threshold\", 0.7)\n",
        "        threshold_low = range_info.get(f\"{feature_name.split('_')[0]}_low_threshold\", 0.3)\n",
        "\n",
        "        if value > threshold_high:\n",
        "            return 'dominant'\n",
        "        elif value > threshold_low:\n",
        "            return 'balanced'\n",
        "        else:\n",
        "            return 'minimal'\n",
        "\n",
        "    # Default intensity-based mapping - expanded vocabulary\n",
        "    else:\n",
        "        max_val = range_info.get('max', 1.0)\n",
        "        if value > range_info.get('very_high_threshold', max_val * 0.85):\n",
        "            return 'intense'\n",
        "        elif value > range_info.get('high_threshold', max_val * 0.65):\n",
        "            return 'strong'\n",
        "        elif value > range_info.get('medium_high_threshold', max_val * 0.45):\n",
        "            return 'moderate'\n",
        "        elif value > range_info.get('low_threshold', max_val * 0.25):\n",
        "            return 'subtle'\n",
        "        else:\n",
        "            return 'minimal'\n",
        "\n",
        "# ====== ENHANCED INFERENCE FUNCTIONS ======\n",
        "\n",
        "def infer_genre_characteristics_with_confidence(features: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Infer genre characteristics using modular rule-based approach with confidence scores.\"\"\"\n",
        "    genre_results = apply_inference_rules(features, GENRE_INFERENCE_RULES)\n",
        "\n",
        "    if not genre_results:\n",
        "        return [{'genre': 'general_music', 'confidence': 0.3, 'matched_factors': []}]\n",
        "\n",
        "    # Sort by confidence and return top results\n",
        "    genre_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "    return genre_results\n",
        "\n",
        "def infer_mood_characteristics_with_confidence(features: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Infer mood characteristics using modular rule-based approach with confidence scores.\"\"\"\n",
        "    mood_results = apply_inference_rules(features, MOOD_INFERENCE_RULES)\n",
        "\n",
        "    # Add key-based mood influence\n",
        "    key = features.get('key', 'C')\n",
        "    key_mood = KEY_SEMANTIC_MAP.get(key, {}).get('mood', 'neutral')\n",
        "    if key_mood != 'neutral':\n",
        "        key_confidence = features.get('key_confidence', 0.5)\n",
        "        mood_results.append({\n",
        "            'mood': key_mood,\n",
        "            'confidence': key_confidence,\n",
        "            'matched_factors': ['key', 'key_confidence']\n",
        "        })\n",
        "\n",
        "    if not mood_results:\n",
        "        return [{'mood': 'neutral', 'confidence': 0.3, 'matched_factors': []}]\n",
        "\n",
        "    # Sort by confidence and return top results\n",
        "    mood_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "    return mood_results\n",
        "\n",
        "def infer_instrumentation_tags_with_confidence(features: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Infer instrumentation tags using modular rule-based approach with confidence scores.\"\"\"\n",
        "    instrumentation_results = apply_inference_rules(features, INSTRUMENTATION_RULES)\n",
        "\n",
        "    if not instrumentation_results:\n",
        "        return [{'type': 'hybrid', 'confidence': 0.3, 'matched_factors': []}]\n",
        "\n",
        "    # Sort by confidence and return top results\n",
        "    instrumentation_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "    return instrumentation_results\n",
        "\n",
        "def infer_energy_level_with_confidence(features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Infer overall energy level from multiple features with confidence score.\"\"\"\n",
        "\n",
        "    tempo = features.get('tempo', 120)\n",
        "    loudness_db = features.get('loudness_db', -20)\n",
        "    onset_rate = features.get('onset_rate', 3)\n",
        "    rms_energy = features.get('rms_energy', 0.1)\n",
        "    percussive_ratio = features.get('percussive_ratio', 0.3)\n",
        "\n",
        "    # Use cached computation\n",
        "    energy_metrics = compute_energy_metrics(tempo, loudness_db, onset_rate, rms_energy, percussive_ratio)\n",
        "    energy_score = energy_metrics['energy_score']\n",
        "\n",
        "    # Determine energy level\n",
        "    if energy_score < 0.2:\n",
        "        level = 'very_low'\n",
        "    elif energy_score < 0.4:\n",
        "        level = 'low'\n",
        "    elif energy_score < 0.6:\n",
        "        level = 'moderate'\n",
        "    elif energy_score < 0.8:\n",
        "        level = 'high'\n",
        "    else:\n",
        "        level = 'very_high'\n",
        "\n",
        "    # Calculate confidence based on how definitively the score falls into a category\n",
        "    category_boundaries = [0.2, 0.4, 0.6, 0.8]\n",
        "    min_distance_to_boundary = min([abs(energy_score - boundary) for boundary in category_boundaries])\n",
        "    confidence = min(1.0, 0.5 + min_distance_to_boundary * 2)\n",
        "\n",
        "    return {\n",
        "        'level': level,\n",
        "        'confidence': confidence,\n",
        "        'energy_score': energy_score\n",
        "    }\n",
        "\n",
        "def infer_complexity_level_with_confidence(features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Infer musical complexity from harmonic and structural features with confidence score.\"\"\"\n",
        "\n",
        "    complejidad_timbral = features.get('complejidad_timbral', 8)\n",
        "    harmonic_complexity = features.get('harmonic_complexity', 5)\n",
        "    arrangement_density = features.get('arrangement_density', 0.5)\n",
        "    spectral_contrast = features.get('spectral_contrast_mean', 15)\n",
        "\n",
        "    # Use cached computation\n",
        "    complexity_metrics = compute_complexity_metrics(\n",
        "        complejidad_timbral, harmonic_complexity, arrangement_density, spectral_contrast\n",
        "    )\n",
        "    complexity_score = complexity_metrics['complexity_score']\n",
        "\n",
        "    # Determine complexity level\n",
        "    if complexity_score < 0.25:\n",
        "        level = 'simple'\n",
        "    elif complexity_score < 0.5:\n",
        "        level = 'moderate'\n",
        "    elif complexity_score < 0.75:\n",
        "        level = 'complex'\n",
        "    else:\n",
        "        level = 'very_complex'\n",
        "\n",
        "    # Calculate confidence based on how definitively the score falls into a category\n",
        "    category_boundaries = [0.25, 0.5, 0.75]\n",
        "    min_distance_to_boundary = min([abs(complexity_score - boundary) for boundary in category_boundaries])\n",
        "    confidence = min(1.0, 0.5 + min_distance_to_boundary * 2)\n",
        "\n",
        "    return {\n",
        "        'level': level,\n",
        "        'confidence': confidence,\n",
        "        'complexity_score': complexity_score\n",
        "    }\n",
        "\n",
        "# ====== SUPPORTING ANALYSIS FUNCTIONS ======\n",
        "\n",
        "def analyze_mfcc_features(mfcc_array) -> Dict[str, str]:\n",
        "    \"\"\"Analyze MFCC coefficients for timbral characteristics using cached computation.\"\"\"\n",
        "    if not isinstance(mfcc_array, (list, np.ndarray)) or len(mfcc_array) == 0:\n",
        "        return {'timbral_character': 'neutral', 'complexity': 'moderate'}\n",
        "\n",
        "    mfcc_tuple = tuple(mfcc_array) if isinstance(mfcc_array, (list, np.ndarray)) else ()\n",
        "    return compute_mfcc_characteristics(mfcc_tuple)\n",
        "\n",
        "\n",
        "def analyze_frequency_distribution(graves: float, medios: float, agudos: float) -> Dict[str, str]:\n",
        "    \"\"\"Analyze frequency distribution characteristics.\"\"\"\n",
        "\n",
        "    # Determine dominant frequency range\n",
        "    max_val = max(graves, medios, agudos)\n",
        "\n",
        "    if max_val == graves and graves > -5:\n",
        "        dominance = 'bass_heavy'\n",
        "        balance = 'bass_focused'\n",
        "    elif max_val == agudos and agudos > 0:\n",
        "        dominance = 'treble_heavy'\n",
        "        balance = 'bright_focused'\n",
        "    elif max_val == medios and medios > 5:\n",
        "        dominance = 'midrange_heavy'\n",
        "        balance = 'mid_focused'\n",
        "    else:\n",
        "        dominance = 'balanced'\n",
        "        balance = 'well_balanced'\n",
        "\n",
        "    # Analyze overall frequency profile\n",
        "    total_strength = graves + medios + agudos\n",
        "    if total_strength > 10:\n",
        "        profile = 'full_spectrum'\n",
        "    elif total_strength < -30:\n",
        "        profile = 'filtered'\n",
        "    else:\n",
        "        profile = 'standard'\n",
        "\n",
        "    return {\n",
        "        'dominance': dominance,\n",
        "        'balance': balance,\n",
        "        'profile': profile\n",
        "    }\n",
        "\n",
        "def analyze_spatial_characteristics(stereo_width: float, phase_correlation: float) -> Dict[str, str]:\n",
        "    \"\"\"Analyze spatial and stereo characteristics.\"\"\"\n",
        "\n",
        "    ranges = SEMANTIC_FEATURE_RANGES\n",
        "\n",
        "    # Stereo width analysis\n",
        "    if stereo_width > ranges['stereo_width']['wide_threshold']:\n",
        "        width_char = 'wide'\n",
        "    elif stereo_width < ranges['stereo_width']['narrow_threshold']:\n",
        "        width_char = 'narrow'\n",
        "    else:\n",
        "        width_char = 'moderate'\n",
        "\n",
        "    # Phase correlation analysis\n",
        "    if phase_correlation > ranges['phase_correlation']['good_threshold']:\n",
        "        phase_char = 'good_correlation'\n",
        "    elif phase_correlation < 0:\n",
        "        phase_char = 'phase_issues'\n",
        "    else:\n",
        "        phase_char = 'moderate_correlation'\n",
        "\n",
        "    # Overall spatial impression\n",
        "    if width_char == 'wide' and phase_char == 'good_correlation':\n",
        "        impression = 'spacious'\n",
        "    elif width_char == 'narrow':\n",
        "        impression = 'centered'\n",
        "    elif phase_char == 'phase_issues':\n",
        "        impression = 'problematic'\n",
        "    else:\n",
        "        impression = 'standard'\n",
        "\n",
        "    return {\n",
        "        'width_character': width_char,\n",
        "        'phase_character': phase_char,\n",
        "        'spatial_impression': impression\n",
        "    }\n",
        "\n",
        "def analyze_dynamic_characteristics(loudness_db: float, rms_energy: float,\n",
        "                                 crest_factor: float, dynamic_range: float) -> Dict[str, str]:\n",
        "    \"\"\"Analyze dynamic characteristics of the audio.\"\"\"\n",
        "\n",
        "    ranges = SEMANTIC_FEATURE_RANGES\n",
        "\n",
        "    # Loudness analysis\n",
        "    if loudness_db > ranges['loudness_db']['loud_threshold']:\n",
        "        loudness_char = 'loud'\n",
        "    elif loudness_db < ranges['loudness_db']['quiet_threshold']:\n",
        "        loudness_char = 'quiet'\n",
        "    else:\n",
        "        loudness_char = 'moderate'\n",
        "\n",
        "    # Dynamic range analysis\n",
        "    if dynamic_range > ranges['dynamic_range']['wide_threshold']:\n",
        "        dynamics_char = 'wide_dynamics'\n",
        "    elif dynamic_range < ranges['dynamic_range']['narrow_threshold']:\n",
        "        dynamics_char = 'compressed'\n",
        "    else:\n",
        "        dynamics_char = 'moderate_dynamics'\n",
        "\n",
        "    # Crest factor analysis\n",
        "    if crest_factor > ranges['crest_factor']['dynamic_threshold']:\n",
        "        crest_char = 'very_dynamic'\n",
        "    elif crest_factor < ranges['crest_factor']['compressed_threshold']:\n",
        "        crest_char = 'heavily_compressed'\n",
        "    else:\n",
        "        crest_char = 'moderate_compression'\n",
        "\n",
        "    # Overall dynamic impression\n",
        "    if dynamics_char == 'wide_dynamics' and crest_char == 'very_dynamic':\n",
        "        impression = 'highly_dynamic'\n",
        "    elif dynamics_char == 'compressed' and crest_char == 'heavily_compressed':\n",
        "        impression = 'heavily_processed'\n",
        "    else:\n",
        "        impression = 'standard_dynamics'\n",
        "\n",
        "    return {\n",
        "        'loudness_character': loudness_char,\n",
        "        'dynamics_character': dynamics_char,\n",
        "        'crest_character': crest_char,\n",
        "        'dynamic_impression': impression\n",
        "    }\n",
        "\n",
        "def analyze_feature_relationships(features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze relationships between different audio features.\"\"\"\n",
        "\n",
        "    relationships = {}\n",
        "\n",
        "    # Tempo vs Energy relationship\n",
        "    tempo = features.get('tempo', 120)\n",
        "    loudness = features.get('loudness_db', -20)\n",
        "    energy_coherence = 'aligned' if (tempo > 140 and loudness > -20) or (tempo < 100 and loudness < -30) else 'misaligned'\n",
        "    relationships['tempo_energy_coherence'] = energy_coherence\n",
        "\n",
        "    # Spectral vs Timbral relationship\n",
        "    spectral_centroid = features.get('spectral_centroid', 2500)\n",
        "    complejidad_timbral = features.get('complejidad_timbral', 8)\n",
        "    spectral_timbral_coherence = 'aligned' if (spectral_centroid > 4000 and complejidad_timbral > 12) or (spectral_centroid < 2000 and complejidad_timbral < 6) else 'contrasting'\n",
        "    relationships['spectral_timbral_coherence'] = spectral_timbral_coherence\n",
        "\n",
        "    # Harmonic vs Percussive balance\n",
        "    harmonic_ratio = features.get('harmonic_ratio', 0.5)\n",
        "    percussive_ratio = features.get('percussive_ratio', 0.3)\n",
        "    if harmonic_ratio > 0.7:\n",
        "        hp_balance = 'harmonic_dominant'\n",
        "    elif percussive_ratio > 0.6:\n",
        "        hp_balance = 'percussive_dominant'\n",
        "    else:\n",
        "        hp_balance = 'balanced'\n",
        "    relationships['harmonic_percussive_balance'] = hp_balance\n",
        "\n",
        "    # Frequency distribution coherence\n",
        "    graves = features.get('graves', -15)\n",
        "    medios = features.get('medios', -10)\n",
        "    agudos = features.get('agudos', -12)\n",
        "\n",
        "    freq_std = np.std([graves, medios, agudos])\n",
        "    if freq_std < 5:\n",
        "        freq_coherence = 'balanced'\n",
        "    elif freq_std > 15:\n",
        "        freq_coherence = 'highly_unbalanced'\n",
        "    else:\n",
        "        freq_coherence = 'moderately_unbalanced'\n",
        "    relationships['frequency_coherence'] = freq_coherence\n",
        "\n",
        "    # Spatial coherence\n",
        "    stereo_width = features.get('stereo_width', 0.5)\n",
        "    phase_correlation = features.get('phase_correlation', 0.8)\n",
        "    spatial_coherence = 'good' if stereo_width > 0.3 and phase_correlation > 0.5 else 'problematic'\n",
        "    relationships['spatial_coherence'] = spatial_coherence\n",
        "\n",
        "    return relationships\n",
        "\n",
        "def generate_contextual_analysis(features: Dict[str, Any],\n",
        "                               semantic_interpretations: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Generate high-level contextual analysis of the audio.\"\"\"\n",
        "\n",
        "    context = {}\n",
        "\n",
        "    # Production quality assessment\n",
        "    phase_correlation = features.get('phase_correlation', 0.8)\n",
        "    stereo_width = features.get('stereo_width', 0.5)\n",
        "    dynamic_range = features.get('dynamic_range', 20)\n",
        "\n",
        "    production_quality_score = (\n",
        "        (1 if phase_correlation > 0.6 else 0) +\n",
        "        (1 if stereo_width > 0.3 else 0) +\n",
        "        (1 if dynamic_range > 15 else 0)\n",
        "    ) / 3\n",
        "\n",
        "    if production_quality_score > 0.8:\n",
        "        context['production_quality'] = 'professional'\n",
        "    elif production_quality_score > 0.5:\n",
        "        context['production_quality'] = 'good'\n",
        "    else:\n",
        "        context['production_quality'] = 'amateur'\n",
        "\n",
        "    # Musical complexity assessment\n",
        "    complexity_features = [\n",
        "        features.get('complejidad_timbral', 8),\n",
        "        features.get('harmonic_complexity', 5),\n",
        "        features.get('arrangement_density', 0.5) * 20,  # Scale to similar range\n",
        "        features.get('spectral_contrast_mean', 15)\n",
        "    ]\n",
        "\n",
        "    complexity_score = np.mean([normalize_with_context(f, list(SEMANTIC_FEATURE_RANGES.keys())[i % len(SEMANTIC_FEATURE_RANGES)])['normalized']\n",
        "                               for i, f in enumerate(complexity_features)])\n",
        "\n",
        "    if complexity_score > 0.7:\n",
        "        context['musical_complexity'] = 'high'\n",
        "    elif complexity_score > 0.4:\n",
        "        context['musical_complexity'] = 'moderate'\n",
        "    else:\n",
        "        context['musical_complexity'] = 'simple'\n",
        "\n",
        "    # Listening context suggestion\n",
        "    energy_level = semantic_interpretations.get('energy_characteristics', {}).get('level', 'moderate')\n",
        "    tempo = features.get('tempo', 120)\n",
        "\n",
        "    if energy_level in ['high', 'very_high'] and tempo > 130:\n",
        "        context['listening_context'] = 'active_listening'\n",
        "    elif energy_level in ['low', 'very_low'] and tempo < 90:\n",
        "        context['listening_context'] = 'background_ambient'\n",
        "    else:\n",
        "        context['listening_context'] = 'general_listening'\n",
        "\n",
        "    # Emotional impact assessment\n",
        "    spectral_centroid = features.get('spectral_centroid', 2500)\n",
        "    loudness_db = features.get('loudness_db', -20)\n",
        "\n",
        "    if spectral_centroid > 4000 and loudness_db > -15:\n",
        "        context['emotional_impact'] = 'energizing'\n",
        "    elif spectral_centroid < 1800 and loudness_db < -25:\n",
        "        context['emotional_impact'] = 'calming'\n",
        "    elif features.get('complejidad_timbral', 8) > 12:\n",
        "        context['emotional_impact'] = 'engaging'\n",
        "    else:\n",
        "        context['emotional_impact'] = 'neutral'\n",
        "\n",
        "    return context\n",
        "\n",
        "# ====== MAIN PROCESSING FUNCTION ======\n",
        "\n",
        "def process_audio_features(features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main function to process audio features and generate comprehensive semantic analysis.\n",
        "\n",
        "    Args:\n",
        "        features: Dictionary containing audio features\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with normalized features, semantic interpretations, and inferred characteristics\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Normalize all features with context\n",
        "    normalized_features = {}\n",
        "    semantic_interpretations = {}\n",
        "\n",
        "    for feature_name, value in features.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            norm_result = normalize_with_context(float(value), feature_name)\n",
        "            normalized_features[feature_name] = norm_result\n",
        "            semantic_interpretations[feature_name] = {\n",
        "                'intensity': norm_result['intensity'],\n",
        "                'semantic_level': norm_result['semantic_level']\n",
        "            }\n",
        "\n",
        "    # 2. Analyze MFCC characteristics\n",
        "    mfcc_analysis = analyze_mfcc_features(features.get('mfcc', []))\n",
        "    semantic_interpretations['mfcc_characteristics'] = mfcc_analysis\n",
        "\n",
        "    # 3. Analyze frequency distribution\n",
        "    freq_analysis = analyze_frequency_distribution(\n",
        "        features.get('graves', -15),\n",
        "        features.get('medios', -10),\n",
        "        features.get('agudos', -12)\n",
        "    )\n",
        "    semantic_interpretations['frequency_characteristics'] = freq_analysis\n",
        "\n",
        "    # 4. Analyze spatial characteristics\n",
        "    spatial_analysis = analyze_spatial_characteristics(\n",
        "        features.get('stereo_width', 0.5),\n",
        "        features.get('phase_correlation', 0.8)\n",
        "    )\n",
        "    semantic_interpretations['spatial_characteristics'] = spatial_analysis\n",
        "\n",
        "    # 5. Analyze dynamic characteristics\n",
        "    dynamic_analysis = analyze_dynamic_characteristics(\n",
        "        features.get('loudness_db', -20),\n",
        "        features.get('rms_energy', 0.1),\n",
        "        features.get('crest_factor', 8),\n",
        "        features.get('dynamic_range', 20)\n",
        "    )\n",
        "    semantic_interpretations['dynamic_characteristics'] = dynamic_analysis\n",
        "\n",
        "    # 6. Analyze energy characteristics\n",
        "    energy_analysis = infer_energy_level_with_confidence(features)\n",
        "    semantic_interpretations['energy_characteristics'] = energy_analysis\n",
        "\n",
        "    # 7. Analyze complexity characteristics\n",
        "    complexity_analysis = infer_complexity_level_with_confidence(features)\n",
        "    semantic_interpretations['complexity_characteristics'] = complexity_analysis\n",
        "\n",
        "    # 8. Analyze feature relationships\n",
        "    feature_relationships = analyze_feature_relationships(features)\n",
        "\n",
        "    # 9. Generate contextual analysis\n",
        "    contextual_analysis = generate_contextual_analysis(features, semantic_interpretations)\n",
        "\n",
        "    # 10. Infer high-level characteristics with confidence\n",
        "    pre_inferred_characteristics = {\n",
        "        'genre_characteristics': infer_genre_characteristics_with_confidence(features),\n",
        "        'mood_characteristics': infer_mood_characteristics_with_confidence(features),\n",
        "        'instrumentation_tags': infer_instrumentation_tags_with_confidence(features)\n",
        "    }\n",
        "\n",
        "    # 11. Compile final result\n",
        "    result = {\n",
        "        'normalized_features': normalized_features,\n",
        "        'semantic_interpretations': semantic_interpretations,\n",
        "        'contextual_analysis': contextual_analysis,\n",
        "        'feature_relationships': feature_relationships,\n",
        "        'pre_inferred_characteristics': pre_inferred_characteristics\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def print_semantic_mapping(semantic_result: Dict[str, Any], features: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Return a detailed, readable summary of all features and semantic interpretations for testing.\n",
        "    \"\"\"\n",
        "    si = semantic_result['semantic_interpretations']\n",
        "    norm = semantic_result['normalized_features']\n",
        "    ctx = semantic_result['contextual_analysis']\n",
        "    pre = semantic_result['pre_inferred_characteristics']\n",
        "    rel = semantic_result['feature_relationships']\n",
        "\n",
        "    def get(name, fallback='N/A'):\n",
        "        return features.get(name, fallback)\n",
        "\n",
        "    def interpret(name):\n",
        "        interp = si.get(name, {})\n",
        "        return f\"{interp.get('semantic_level', 'N/A')} ({interp.get('intensity', 'N/A')})\"\n",
        "\n",
        "    lines = []\n",
        "\n",
        "    # ========== TONAL ==========\n",
        "    lines.append(\" Tonal Features\")\n",
        "    lines.append(f\"   Key: {get('key')}  Confidence: {get('key_confidence'):.2f}, Interpretation: {interpret('key_confidence')}\")\n",
        "    lines.append(f\"   Tonic Stability: {get('tonic_stability'):.2f}, Interpretation: {interpret('tonic_stability')}\")\n",
        "    lines.append(f\"   Triad Strength: {get('triad_strength'):.2f}, Interpretation: {interpret('triad_strength')}\")\n",
        "\n",
        "    # ========== RHYTHMIC ==========\n",
        "    lines.append(\"\\n Rhythmic Features\")\n",
        "    lines.append(f\"   Tempo: {get('tempo'):.2f} BPM  Interpretation: {interpret('tempo')}\")\n",
        "    lines.append(f\"   Tempo Confidence: {get('tempo_confidence'):.2f}, Interpretation: {interpret('tempo_confidence')}\")\n",
        "    lines.append(f\"   Onset Rate: {get('onset_rate'):.2f}, Interpretation: {interpret('onset_rate')}\")\n",
        "    lines.append(f\"   Rhythmic Regularity: {get('rhythmic_regularity'):.2f}, Interpretation: {interpret('rhythmic_regularity')}\")\n",
        "\n",
        "    # ========== SPECTRAL / TIMBRE ==========\n",
        "    lines.append(\"\\n Spectral & Timbre Features\")\n",
        "    lines.append(f\"   Spectral Centroid: {get('spectral_centroid'):.2f}, Interpretation: {interpret('spectral_centroid')}\")\n",
        "    lines.append(f\"   Spectral Rolloff: {get('spectral_rolloff'):.2f}, Interpretation: {interpret('spectral_rolloff')}\")\n",
        "    lines.append(f\"   Spectral Contrast Mean: {get('spectral_contrast_mean'):.2f}, Interpretation: {interpret('spectral_contrast_mean')}\")\n",
        "    lines.append(f\"   Zero Crossing Rate: {get('zero_crossing_rate'):.4f}, Interpretation: {interpret('zero_crossing_rate')}\")\n",
        "    lines.append(f\"   Graves: {get('graves'):.2f}, Interpretation: {interpret('graves')}\")\n",
        "    lines.append(f\"   Medios: {get('medios'):.2f}, Interpretation: {interpret('medios')}\")\n",
        "    lines.append(f\"   Agudos: {get('agudos'):.2f}, Interpretation: {interpret('agudos')}\")\n",
        "    lines.append(f\"   Timbral Complexity: {get('complejidad_timbral'):.2f}, Interpretation: {interpret('complejidad_timbral')}\")\n",
        "\n",
        "    # ========== DYNAMICS ==========\n",
        "    lines.append(\"\\n Dynamic Features\")\n",
        "    lines.append(f\"   Loudness (dB): {get('loudness_db'):.2f}, Interpretation: {interpret('loudness_db')}\")\n",
        "    lines.append(f\"   RMS Energy: {get('rms_energy'):.4f}, Interpretation: {interpret('rms_energy')}\")\n",
        "    lines.append(f\"   Crest Factor: {get('crest_factor'):.2f}, Interpretation: {interpret('crest_factor')}\")\n",
        "    lines.append(f\"   Dynamic Range: {get('dynamic_range'):.2f}, Interpretation: {interpret('dynamic_range')}\")\n",
        "    lines.append(f\"   Peak Level: {get('peak_level'):.2f}\")\n",
        "\n",
        "    # ========== HARMONIC / PERCUSSIVE ==========\n",
        "    lines.append(\"\\n Harmonic & Percussive Features\")\n",
        "    lines.append(f\"   Instrumentalness: {get('instrumentalness'):.2f}, Interpretation: {interpret('instrumentalness')}\")\n",
        "    lines.append(f\"   Harmonic Ratio: {get('harmonic_ratio'):.2f}, Interpretation: {interpret('harmonic_ratio')}\")\n",
        "    lines.append(f\"   Percussive Ratio: {get('percussive_ratio'):.2f}, Interpretation: {interpret('percussive_ratio')}\")\n",
        "    lines.append(f\"   Harmonic Complexity: {get('harmonic_complexity'):.2f}, Interpretation: {interpret('harmonic_complexity')}\")\n",
        "\n",
        "    # ========== SPATIAL ==========\n",
        "    lines.append(\"\\n Spatial Features\")\n",
        "    lines.append(f\"   Stereo Width: {get('stereo_width'):.4f}, Interpretation: {interpret('stereo_width')}\")\n",
        "    lines.append(f\"   Phase Correlation: {get('phase_correlation'):.2f}, Interpretation: {interpret('phase_correlation')}\")\n",
        "\n",
        "    # ========== DERIVED ==========\n",
        "    lines.append(\"\\n Derived / Mixed Features\")\n",
        "    lines.append(f\"   Arrangement Density: {get('arrangement_density'):.4f}, Interpretation: {interpret('arrangement_density')}\")\n",
        "    lines.append(f\"   Punch Factor: {get('punch_factor'):.2f}, Interpretation: {interpret('punch_factor')}\")\n",
        "    lines.append(f\"   Loopability Score: {get('loopability_score'):.2f}, Interpretation: {interpret('loopability_score')}\")\n",
        "    lines.append(f\"   Sub Bass Energy: {get('sub_bass_energy'):.2f}\")\n",
        "\n",
        "    # ========== META ==========\n",
        "    lines.append(\"\\n Meta / Technical\")\n",
        "    lines.append(f\"   Duration: {get('duration'):.2f} sec\")\n",
        "    lines.append(f\"   Sample Rate: {get('sample_rate')}\")\n",
        "    lines.append(f\"   Stereo: {get('is_stereo')}\")\n",
        "\n",
        "    # ========== INFERRED SEMANTICS ==========\n",
        "    genre = pre.get('genre_characteristics', [{}])[0]\n",
        "    mood = pre.get('mood_characteristics', [{}])[0]\n",
        "    inst = pre.get('instrumentation_tags', [{}])[0]\n",
        "    lines.append(\"\\n Inferred High-Level Characteristics\")\n",
        "    lines.append(f\"   Genre: {genre.get('genre', 'N/A')} (confidence: {genre.get('confidence', 0):.2f})\")\n",
        "    lines.append(f\"   Mood: {mood.get('mood', 'N/A')} (confidence: {mood.get('confidence', 0):.2f})\")\n",
        "    lines.append(f\"   Instrumentation: {inst.get('type', 'N/A')} (confidence: {inst.get('confidence', 0):.2f})\")\n",
        "\n",
        "    # ========== CONTEXTUAL / RELATIONSHIPS ==========\n",
        "    lines.append(\"\\n Contextual Analysis\")\n",
        "    for k, v in ctx.items():\n",
        "        lines.append(f\"   {k.replace('_', ' ').title()}: {v}\")\n",
        "\n",
        "    lines.append(\"\\n Feature Relationships\")\n",
        "    for k, v in rel.items():\n",
        "        lines.append(f\"   {k.replace('_', ' ').title()}: {v}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYuJdNVSUP5Z"
      },
      "source": [
        "## Mixing_Base_recomendation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUMgZA2VUOpg"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import numpy as np\n",
        "\n",
        "# ====== CONFIGURATION AND UTILITIES ======\n",
        "\n",
        "# Define feature normalization ranges for consistent mapping\n",
        "FEATURE_RANGES = {\n",
        "    'spectral_centroid': {'min': 500, 'max': 8000},\n",
        "    'loudness_db': {'min': -60, 'max': 0},\n",
        "    'tempo': {'min': 60, 'max': 180},\n",
        "    'onset_rate': {'min': 0, 'max': 10},\n",
        "    'rhythmic_regularity': {'min': 0, 'max': 1},\n",
        "    'complejidad_timbral': {'min': 0, 'max': 20},\n",
        "    'graves': {'min': -30, 'max': 10},\n",
        "    'medios': {'min': -20, 'max': 15},\n",
        "    'agudos': {'min': -25, 'max': 10},\n",
        "    'stereo_width': {'min': 0, 'max': 1},\n",
        "    'crest_factor': {'min': 1, 'max': 20}\n",
        "}\n",
        "\n",
        "def normalize_feature(value: float, feature_name: str) -> float:\n",
        "    \"\"\"Normalize feature value to 0-1 range for consistent mapping.\"\"\"\n",
        "    if feature_name not in FEATURE_RANGES:\n",
        "        return np.clip(value, 0, 1)\n",
        "\n",
        "    range_info = FEATURE_RANGES[feature_name]\n",
        "    normalized = (value - range_info['min']) / (range_info['max'] - range_info['min'])\n",
        "    return np.clip(normalized, 0, 1)\n",
        "\n",
        "def get_technical_rationale(category: str, parameters: Dict) -> str:\n",
        "    \"\"\"Provide technical explanation for parameter choices.\"\"\"\n",
        "    rationale_map = {\n",
        "        \"EQ\": \"Frequency response optimization based on spectral analysis\",\n",
        "        \"Compression\": \"Dynamic range control aligned with program material characteristics\",\n",
        "        \"Saturation\": \"Harmonic enhancement targeting timbral complexity deficiencies\",\n",
        "        \"Spatial\": \"Stereo image and dimensional processing recommendations\",\n",
        "        \"Reverb\": \"Acoustic space simulation based on tempo and arrangement density\",\n",
        "        \"Delay\": \"Rhythmic enhancement and spatial depth creation\"\n",
        "    }\n",
        "    return rationale_map.get(category, \"Audio processing optimization\")\n",
        "\n",
        "def make_recommendation(category: str, recommendation: str,\n",
        "                       confidence: float, parameters: Dict,\n",
        "                       reasoning: str, priority: int = 1) -> Dict:\n",
        "    \"\"\"Create standardized recommendation structure.\"\"\"\n",
        "    return {\n",
        "        \"category\": category,\n",
        "        \"subcategory\": recommendation,\n",
        "        \"confidence\": confidence,\n",
        "        \"priority\": priority,\n",
        "        \"parameters\": parameters,\n",
        "        \"reasoning\": reasoning,\n",
        "        \"technical_rationale\": get_technical_rationale(category, parameters)\n",
        "    }\n",
        "\n",
        "# ====== EQ RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_eq(spectral_centroid: float, graves: float,\n",
        "                medios: float, agudos: float, loudness_db: float,\n",
        "                complejidad_timbral: float = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Enhanced EQ recommendations based on spectral analysis and frequency balance.\n",
        "    Implements both corrective and creative EQ philosophies from the research.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Normalize features for consistent mapping\n",
        "    sc_norm = normalize_feature(spectral_centroid, 'spectral_centroid')\n",
        "\n",
        "    # High-frequency analysis and recommendations\n",
        "    if sc_norm < 0.3:  # Dark/dull content\n",
        "        high_freq_boost = {\n",
        "            \"air_band\": {\"freq\": 12000, \"gain\": f\"+{2 + (0.3 - sc_norm) * 4:.1f} dB\", \"q\": 0.7},\n",
        "            \"presence\": {\"freq\": 4000, \"gain\": f\"+{1 + (0.3 - sc_norm) * 2:.1f} dB\", \"q\": 1.2},\n",
        "            \"brilliance\": {\"freq\": 8000, \"gain\": f\"+{1.5 + (0.3 - sc_norm) * 2:.1f} dB\", \"q\": 0.8}\n",
        "        }\n",
        "        confidence = 0.8 + (0.3 - sc_norm) * 0.15\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"EQ\", \"High-frequency enhancement\", confidence, high_freq_boost,\n",
        "            f\"Spectral centroid at {spectral_centroid:.0f} Hz indicates lack of brightness and air\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    elif sc_norm > 0.75:  # Harsh/bright content\n",
        "        high_freq_taming = {\n",
        "            \"de_esser\": {\"freq\": 6500, \"gain\": f\"-{1 + (sc_norm - 0.75) * 3:.1f} dB\", \"q\": 2.5},\n",
        "            \"smooth_top\": {\"freq\": 10000, \"gain\": f\"-{0.5 + (sc_norm - 0.75) * 2:.1f} dB\", \"q\": 0.6},\n",
        "            \"harshness_cut\": {\"freq\": 3500, \"gain\": f\"-{0.8 + (sc_norm - 0.75) * 1.5:.1f} dB\", \"q\": 2.0}\n",
        "        }\n",
        "        confidence = 0.75 + (sc_norm - 0.75) * 0.2\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"EQ\", \"High-frequency smoothing\", confidence, high_freq_taming,\n",
        "            f\"High spectral centroid ({spectral_centroid:.0f} Hz) suggests potential harshness\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    # Low-frequency analysis\n",
        "    if graves < -18:\n",
        "        low_enhancement = {\n",
        "            \"sub_bass\": {\"freq\": 50, \"gain\": f\"+{min(3, abs(graves + 18) * 0.3):.1f} dB\", \"q\": 1.0},\n",
        "            \"bass_foundation\": {\"freq\": 120, \"gain\": f\"+{min(4, abs(graves + 18) * 0.4):.1f} dB\", \"q\": 0.8},\n",
        "            \"low_mid_support\": {\"freq\": 200, \"gain\": f\"+{min(2, abs(graves + 18) * 0.2):.1f} dB\", \"q\": 1.2}\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"EQ\", \"Low-end enhancement\", 0.7 + min(0.2, abs(graves + 18) * 0.02),\n",
        "            low_enhancement,\n",
        "            f\"Insufficient low-end energy ({graves:.1f} dB) requires foundation building\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    # Mid-range control\n",
        "    if medios > 3:\n",
        "        mid_control = {\n",
        "            \"mud_cut\": {\"freq\": 300, \"gain\": f\"-{min(3, (medios - 3) * 0.5):.1f} dB\", \"q\": 2.0},\n",
        "            \"clarity_boost\": {\"freq\": 1800, \"gain\": f\"+{min(2, (medios - 3) * 0.3):.1f} dB\", \"q\": 1.5},\n",
        "            \"definition\": {\"freq\": 2500, \"gain\": f\"+{min(1.5, (medios - 3) * 0.2):.1f} dB\", \"q\": 2.5}\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"EQ\", \"Mid-range clarity\", 0.65 + min(0.25, (medios - 3) * 0.05),\n",
        "            mid_control,\n",
        "            f\"Excessive mid-range energy ({medios:.1f} dB) may mask clarity and definition\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    # Timbral complexity considerations\n",
        "    if complejidad_timbral < 5:\n",
        "        harmonic_enhancement = {\n",
        "            \"harmonic_exciter\": {\"freq\": 2000, \"gain\": \"+1.0 dB\", \"q\": 0.5, \"type\": \"gentle_saturation\"},\n",
        "            \"color_boost\": {\"freq\": 5000, \"gain\": \"+0.8 dB\", \"q\": 1.0}\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"EQ\", \"Harmonic complexity enhancement\", 0.6,\n",
        "            harmonic_enhancement,\n",
        "            \"Low timbral complexity suggests benefit from subtle harmonic enhancement\",\n",
        "            priority=3\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== COMPRESSION RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_compression(onset_rate: float, rhythmic_regularity: float,\n",
        "                         loudness_db: float, crest_factor: float = 6) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Dynamic range control recommendations based on transient and rhythmic characteristics.\n",
        "    Maps dynamic features to compression parameters through transfer functions.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Normalize key features\n",
        "    onset_norm = normalize_feature(onset_rate, 'onset_rate')\n",
        "    rhythmic_norm = normalize_feature(rhythmic_regularity, 'rhythmic_regularity')\n",
        "\n",
        "    # Transient-based compression mapping\n",
        "    if onset_norm > 0.6:  # High transient density\n",
        "        fast_compression = {\n",
        "            \"ratio\": f\"{3 + onset_norm * 3:.1f}:1\",\n",
        "            \"attack\": f\"{max(0.5, 5 - onset_norm * 4):.1f} ms\",\n",
        "            \"release\": f\"{50 + onset_norm * 100:.0f} ms\",\n",
        "            \"threshold\": f\"{loudness_db + 6:.1f} dB\",\n",
        "            \"knee\": \"soft\" if onset_norm > 0.8 else \"medium\",\n",
        "            \"type\": \"VCA or FET\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Compression\", \"Transient-focused control\", 0.75 + onset_norm * 0.2,\n",
        "            fast_compression,\n",
        "            f\"High onset density ({onset_rate:.1f}/sec) requires fast transient control\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    elif onset_norm < 0.3:  # Low transient density\n",
        "        gentle_compression = {\n",
        "            \"ratio\": f\"{1.5 + onset_norm:.1f}:1\",\n",
        "            \"attack\": f\"{15 + (0.3 - onset_norm) * 25:.1f} ms\",\n",
        "            \"release\": f\"{200 + (0.3 - onset_norm) * 300:.0f} ms\",\n",
        "            \"threshold\": f\"{loudness_db + 10:.1f} dB\",\n",
        "            \"knee\": \"soft\",\n",
        "            \"type\": \"Optical or Tube\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Compression\", \"Gentle program control\", 0.7,\n",
        "            gentle_compression,\n",
        "            f\"Low transient activity ({onset_rate:.1f}/sec) allows for gentle, musical compression\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    # Rhythmic regularity considerations\n",
        "    if rhythmic_norm < 0.4:  # Irregular rhythm\n",
        "        musical_compression = {\n",
        "            \"ratio\": \"2.5:1\",\n",
        "            \"attack\": \"auto-adaptive\",\n",
        "            \"release\": \"program-dependent\",\n",
        "            \"threshold\": f\"{loudness_db + 8:.1f} dB\",\n",
        "            \"knee\": \"soft\",\n",
        "            \"lookahead\": \"5 ms\",\n",
        "            \"type\": \"Program-dependent\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Compression\", \"Musical program compression\", 0.8,\n",
        "            musical_compression,\n",
        "            \"Irregular rhythm requires adaptive compression to preserve musical phrasing\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    # Dynamic range specific recommendations\n",
        "    if crest_factor > 12:  # Very dynamic material\n",
        "        parallel_compression = {\n",
        "            \"parallel_ratio\": \"6:1 to 8:1\",\n",
        "            \"parallel_attack\": \"1 ms\",\n",
        "            \"parallel_release\": \"auto\",\n",
        "            \"blend\": \"15-25%\",\n",
        "            \"main_ratio\": \"2:1\",\n",
        "            \"main_threshold\": f\"{loudness_db + 12:.1f} dB\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Compression\", \"Parallel compression blend\", 0.8,\n",
        "            parallel_compression,\n",
        "            f\"High crest factor ({crest_factor:.1f}) benefits from parallel compression technique\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== SATURATION RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_saturation(spectral_centroid: float, complejidad_timbral: float,\n",
        "                        loudness_db: float, harmonic_content: float = 0.5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Harmonic enhancement recommendations based on timbral complexity and spectral characteristics.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Normalize features\n",
        "    sc_norm = normalize_feature(spectral_centroid, 'spectral_centroid')\n",
        "    timbral_norm = normalize_feature(complejidad_timbral, 'complejidad_timbral')\n",
        "\n",
        "    # Low timbral complexity enhancement\n",
        "    if timbral_norm < 0.4:\n",
        "        harmonic_enhancement = {\n",
        "            \"type\": \"Analog tube\" if sc_norm < 0.5 else \"Tape saturation\",\n",
        "            \"drive\": f\"{20 + (0.4 - timbral_norm) * 30:.1f}%\",\n",
        "            \"harmonics\": \"even-order emphasis\",\n",
        "            \"mix\": f\"{15 + (0.4 - timbral_norm) * 20:.1f}%\",\n",
        "            \"frequency_focus\": \"mid-range\" if sc_norm < 0.6 else \"high-mid\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Saturation\", \"Harmonic complexity enhancement\", 0.7 + (0.4 - timbral_norm) * 0.2,\n",
        "            harmonic_enhancement,\n",
        "            f\"Low timbral complexity ({complejidad_timbral:.1f}) benefits from harmonic saturation\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    # Bright material warming\n",
        "    if sc_norm > 0.7 and loudness_db > -20:\n",
        "        warm_saturation = {\n",
        "            \"type\": \"Console or vintage preamp\",\n",
        "            \"drive\": \"subtle (5-15%)\",\n",
        "            \"high_cut\": \"8 kHz gentle roll-off\",\n",
        "            \"mix\": \"parallel blend 10-20%\",\n",
        "            \"character\": \"warm, even harmonics\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Saturation\", \"Gentle warming\", 0.6,\n",
        "            warm_saturation,\n",
        "            \"Bright, loud material benefits from subtle warming saturation\",\n",
        "            priority=3\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== SPATIAL RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_spatial(tempo: float, instrumentalness: float,\n",
        "                     stereo_width: float, arrangement_density: float = 0.5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Stereo image and spatial processing recommendations based on musical context.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Normalize features\n",
        "    tempo_norm = normalize_feature(tempo, 'tempo')\n",
        "    width_norm = normalize_feature(stereo_width, 'stereo_width')\n",
        "\n",
        "    # Stereo width optimization\n",
        "    if width_norm < 0.3:  # Narrow stereo image\n",
        "        width_enhancement = {\n",
        "            \"stereo_widener\": {\n",
        "                \"amount\": f\"+{(0.3 - width_norm) * 40:.0f}%\",\n",
        "                \"frequency_range\": \"above 200 Hz\",\n",
        "                \"method\": \"mid-side processing\"\n",
        "            },\n",
        "            \"haas_delay\": {\n",
        "                \"delay_time\": \"10-25 ms\",\n",
        "                \"mix\": \"subtle\",\n",
        "                \"frequency_dependent\": True\n",
        "            }\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Spatial\", \"Stereo width enhancement\", 0.7,\n",
        "            width_enhancement,\n",
        "            f\"Narrow stereo image ({stereo_width:.2f}) limits spatial impact\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    elif width_norm > 0.8:  # Overly wide stereo\n",
        "        width_control = {\n",
        "            \"mono_compatibility\": {\n",
        "                \"low_freq_mono\": \"below 120 Hz\",\n",
        "                \"width_reduction\": f\"-{(width_norm - 0.8) * 25:.0f}%\",\n",
        "                \"method\": \"frequency-dependent narrowing\"\n",
        "            },\n",
        "            \"correlation_check\": \"ensure >0.7 correlation coefficient\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Spatial\", \"Stereo width control\", 0.75,\n",
        "            width_control,\n",
        "            \"Excessive stereo width may compromise mono compatibility\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    # Panning recommendations based on arrangement\n",
        "    if instrumentalness > 0.7:\n",
        "        creative_panning = {\n",
        "            \"spread_technique\": \"complementary panning\",\n",
        "            \"frequency_panning\": \"high frequencies wider\",\n",
        "            \"rhythm_elements\": \"center-focused\",\n",
        "            \"melodic_elements\": \"strategic spread\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Spatial\", \"Creative panning arrangement\", 0.65,\n",
        "            creative_panning,\n",
        "            \"Instrumental arrangement allows for creative spatial positioning\",\n",
        "            priority=3\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== REVERB RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_reverb(tempo: float, arrangement_density: float,\n",
        "                    spectral_centroid: float, rhythmic_regularity: float) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Reverb recommendations based on tempo, arrangement complexity, and spectral characteristics.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Normalize features\n",
        "    tempo_norm = normalize_feature(tempo, 'tempo')\n",
        "    sc_norm = normalize_feature(spectral_centroid, 'spectral_centroid')\n",
        "    rhythmic_norm = normalize_feature(rhythmic_regularity, 'rhythmic_regularity')\n",
        "\n",
        "    # Tempo-based reverb mapping\n",
        "    if tempo_norm < 0.4:  # Slow tempo\n",
        "        long_reverb = {\n",
        "            \"type\": \"Hall or Large Chamber\",\n",
        "            \"decay_time\": f\"{2.5 + (0.4 - tempo_norm) * 3:.1f} seconds\",\n",
        "            \"pre_delay\": f\"{60 + (0.4 - tempo_norm) * 80:.0f} ms\",\n",
        "            \"damping\": \"medium\" if sc_norm > 0.5 else \"low\",\n",
        "            \"diffusion\": \"high\",\n",
        "            \"mix\": f\"{25 + (0.4 - tempo_norm) * 15:.0f}%\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Reverb\", \"Atmospheric long reverb\", 0.8,\n",
        "            long_reverb,\n",
        "            f\"Slow tempo ({tempo:.0f} BPM) allows for longer reverb times without muddiness\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    elif tempo_norm > 0.75:  # Fast tempo\n",
        "        short_reverb = {\n",
        "            \"type\": \"Room or Plate\",\n",
        "            \"decay_time\": f\"{0.6 + (1 - tempo_norm) * 0.8:.1f} seconds\",\n",
        "            \"pre_delay\": f\"{15 + (1 - tempo_norm) * 25:.0f} ms\",\n",
        "            \"high_cut\": f\"{6000 + (1 - tempo_norm) * 2000:.0f} Hz\",\n",
        "            \"diffusion\": \"medium-high\",\n",
        "            \"mix\": f\"{15 + (1 - tempo_norm) * 10:.0f}%\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Reverb\", \"Tight rhythmic reverb\", 0.85,\n",
        "            short_reverb,\n",
        "            f\"Fast tempo ({tempo:.0f} BPM) requires short reverb to maintain rhythmic clarity\",\n",
        "            priority=1\n",
        "        ))\n",
        "\n",
        "    # Arrangement density considerations\n",
        "    if arrangement_density > 0.7:\n",
        "        selective_reverb = {\n",
        "            \"application\": \"selective frequency bands\",\n",
        "            \"high_freq_reverb\": \"minimal above 4 kHz\",\n",
        "            \"low_freq_treatment\": \"dry below 200 Hz\",\n",
        "            \"mid_range_focus\": \"primary reverb content\",\n",
        "            \"send_levels\": \"conservative (10-20%)\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Reverb\", \"Frequency-selective reverb\", 0.7,\n",
        "            selective_reverb,\n",
        "            \"Dense arrangement requires careful reverb application to avoid masking\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== DELAY RECOMMENDATIONS ======\n",
        "\n",
        "def recommend_delay(tempo: float, instrumentalness: float,\n",
        "                   rhythmic_regularity: float, arrangement_density: float = 0.5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Delay recommendations based on tempo, musical content, and rhythmic characteristics.\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Calculate rhythmically synchronized delay times\n",
        "    quarter_note_ms = (60 / tempo) * 1000\n",
        "    eighth_note_ms = quarter_note_ms / 2\n",
        "    dotted_eighth_ms = eighth_note_ms * 1.5\n",
        "\n",
        "    tempo_norm = normalize_feature(tempo, 'tempo')\n",
        "    rhythmic_norm = normalize_feature(rhythmic_regularity, 'rhythmic_regularity')\n",
        "\n",
        "    # Rhythmic delay for instrumental content\n",
        "    if instrumentalness > 0.6 and rhythmic_norm > 0.5:\n",
        "        rhythmic_delay = {\n",
        "            \"primary_delay\": f\"{quarter_note_ms:.0f} ms (1/4 note)\",\n",
        "            \"secondary_delay\": f\"{eighth_note_ms:.0f} ms (1/8 note)\",\n",
        "            \"feedback\": f\"{20 + instrumentalness * 25:.0f}%\",\n",
        "            \"high_cut\": f\"{4000 + tempo_norm * 3000:.0f} Hz\",\n",
        "            \"low_cut\": \"200 Hz\",\n",
        "            \"mix\": f\"{15 + instrumentalness * 15:.0f}%\",\n",
        "            \"stereo_spread\": \"ping-pong\" if arrangement_density < 0.6 else \"mono\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Delay\", \"Rhythmic synchronization\", 0.75,\n",
        "            rhythmic_delay,\n",
        "            f\"Instrumental content with regular rhythm benefits from tempo-sync delays\",\n",
        "            priority=2\n",
        "        ))\n",
        "\n",
        "    # Atmospheric delay for slower, less dense material\n",
        "    if tempo_norm < 0.5 and arrangement_density < 0.4:\n",
        "        atmospheric_delay = {\n",
        "            \"delay_time\": f\"{dotted_eighth_ms:.0f} ms (dotted 1/8)\",\n",
        "            \"feedback\": f\"{35 + (0.5 - tempo_norm) * 20:.0f}%\",\n",
        "            \"modulation\": \"subtle chorus/vibrato\",\n",
        "            \"diffusion\": \"medium\",\n",
        "            \"high_cut\": \"6 kHz gradual\",\n",
        "            \"mix\": f\"{25 + (0.5 - tempo_norm) * 15:.0f}%\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Delay\", \"Atmospheric depth\", 0.7,\n",
        "            atmospheric_delay,\n",
        "            \"Sparse, slow arrangement can support more prominent delay effects\",\n",
        "            priority=3\n",
        "        ))\n",
        "\n",
        "    # Creative delay for complex rhythmic patterns\n",
        "    if rhythmic_norm < 0.4:  # Irregular rhythm\n",
        "        creative_delay = {\n",
        "            \"primary_time\": f\"{quarter_note_ms * 0.75:.0f} ms\",\n",
        "            \"secondary_time\": f\"{quarter_note_ms * 1.33:.0f} ms\",\n",
        "            \"feedback\": \"20-30%\",\n",
        "            \"filtering\": \"creative frequency sculpting\",\n",
        "            \"mix\": \"15-25%\",\n",
        "            \"automation\": \"rhythmic ducking recommended\"\n",
        "        }\n",
        "\n",
        "        recommendations.append(make_recommendation(\n",
        "            \"Delay\", \"Complex rhythmic enhancement\", 0.6,\n",
        "            creative_delay,\n",
        "            \"Irregular rhythmic patterns allow for creative delay timing\",\n",
        "            priority=3\n",
        "        ))\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ====== MAIN ANALYSIS FUNCTION ======\n",
        "\n",
        "def analyze_and_recommend(audio_features: Dict[str, Any]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Main analysis function that generates comprehensive mixing recommendations\n",
        "    based on extracted audio features.\n",
        "    \"\"\"\n",
        "    # Extract features with defaults\n",
        "    tempo = audio_features.get('tempo', 120)\n",
        "    loudness_db = audio_features.get('loudness_db', -20)\n",
        "    spectral_centroid = audio_features.get('spectral_centroid', 2000)\n",
        "    instrumentalness = audio_features.get('instrumentalness', 0.5)\n",
        "    onset_rate = audio_features.get('onset_rate', 3)\n",
        "    rhythmic_regularity = audio_features.get('rhythmic_regularity', 0.7)\n",
        "    complejidad_timbral = audio_features.get('complejidad_timbral', 10)\n",
        "    graves, medios, agudos = audio_features.get('graves_medios_agudos', [-10, 0, -5])\n",
        "    stereo_width = audio_features.get('stereo_width', 0.6)\n",
        "    crest_factor = audio_features.get('crest_factor', 6)\n",
        "    arrangement_density = audio_features.get('arrangement_density', 0.5)\n",
        "\n",
        "    # Generate all recommendations\n",
        "    all_recommendations = []\n",
        "\n",
        "    all_recommendations.extend(\n",
        "        recommend_eq(spectral_centroid, graves, medios, agudos, loudness_db, complejidad_timbral)\n",
        "    )\n",
        "    all_recommendations.extend(\n",
        "        recommend_compression(onset_rate, rhythmic_regularity, loudness_db, crest_factor)\n",
        "    )\n",
        "    all_recommendations.extend(\n",
        "        recommend_saturation(spectral_centroid, complejidad_timbral, loudness_db)\n",
        "    )\n",
        "    all_recommendations.extend(\n",
        "        recommend_spatial(tempo, instrumentalness, stereo_width, arrangement_density)\n",
        "    )\n",
        "    all_recommendations.extend(\n",
        "        recommend_reverb(tempo, arrangement_density, spectral_centroid, rhythmic_regularity)\n",
        "    )\n",
        "    all_recommendations.extend(\n",
        "        recommend_delay(tempo, instrumentalness, rhythmic_regularity, arrangement_density)\n",
        "    )\n",
        "\n",
        "    # Filter and sort recommendations\n",
        "    filtered_recommendations = [r for r in all_recommendations if r[\"confidence\"] > 0.4]\n",
        "\n",
        "    # Sort by priority first, then confidence\n",
        "    sorted_recommendations = sorted(\n",
        "        filtered_recommendations,\n",
        "        key=lambda r: (r[\"priority\"], -r[\"confidence\"])\n",
        "    )\n",
        "\n",
        "    return sorted_recommendations\n",
        "\n",
        "def analyze_and_recommend_gpt(audio_features: Dict[str, Any]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Main analysis function that generates comprehensive mixing recommendations\n",
        "    based on extracted audio features, matching structure from updated audio_analysis.\n",
        "    \"\"\"\n",
        "    # Unpack and normalize audio features with safe defaults\n",
        "    tempo = float(audio_features.get('tempo', 120.0))\n",
        "    loudness_db = float(audio_features.get('loudness_db', -20.0))\n",
        "    spectral_centroid = float(audio_features.get('spectral_centroid', 2000.0))\n",
        "    instrumentalness = float(audio_features.get('instrumentalness', 0.5))\n",
        "    onset_rate = float(audio_features.get('onset_rate', 3.0))\n",
        "    rhythmic_regularity = float(audio_features.get('rhythmic_regularity', 0.6))\n",
        "    complejidad_timbral = float(audio_features.get('complejidad_timbral', 8.0))\n",
        "    stereo_width = float(audio_features.get('stereo_width', 0.5))\n",
        "    crest_factor = float(audio_features.get('crest_factor', 6.0))\n",
        "    arrangement_density = float(audio_features.get('arrangement_density', 0.5))\n",
        "\n",
        "    # Handle full frequency band structure\n",
        "    gma = audio_features.get('graves_medios_agudos', None)\n",
        "    if gma and isinstance(gma, (list, tuple)) and len(gma) == 3:\n",
        "        graves, medios, agudos = map(float, gma)\n",
        "    else:\n",
        "        graves = float(audio_features.get('graves', -10.0))\n",
        "        medios = float(audio_features.get('medios', 0.0))\n",
        "        agudos = float(audio_features.get('agudos', -5.0))\n",
        "\n",
        "    # Aggregate recommendations\n",
        "    recommendations = []\n",
        "    recommendations += recommend_eq(spectral_centroid, graves, medios, agudos, loudness_db, complejidad_timbral)\n",
        "    recommendations += recommend_compression(onset_rate, rhythmic_regularity, loudness_db, crest_factor)\n",
        "    recommendations += recommend_saturation(spectral_centroid, complejidad_timbral, loudness_db)\n",
        "    recommendations += recommend_spatial(tempo, instrumentalness, stereo_width, arrangement_density)\n",
        "    recommendations += recommend_reverb(tempo, arrangement_density, spectral_centroid, rhythmic_regularity)\n",
        "    recommendations += recommend_delay(tempo, instrumentalness, rhythmic_regularity, arrangement_density)\n",
        "\n",
        "    # Filter and sort by priority and confidence\n",
        "    filtered = [r for r in recommendations if r[\"confidence\"] > 0.4]\n",
        "    return sorted(filtered, key=lambda r: (r[\"priority\"], -r[\"confidence\"]))\n",
        "\n",
        "\n",
        "\n",
        "# ====== EXAMPLE USAGE ======\n",
        "\n",
        "def demo_recommendations():\n",
        "    \"\"\"Demonstrate the recommendation system with example audio features.\"\"\"\n",
        "\n",
        "    # Example audio features\n",
        "    example_features = {\n",
        "        'tempo': 85,\n",
        "        'loudness_db': -18,\n",
        "        'spectral_centroid': 1200,\n",
        "        'instrumentalness': 0.8,\n",
        "        'onset_rate': 2.5,\n",
        "        'rhythmic_regularity': 0.4,\n",
        "        'complejidad_timbral': 6,\n",
        "        'graves_medios_agudos': [-20, 5, -8],\n",
        "        'stereo_width': 0.4,\n",
        "        'crest_factor': 8,\n",
        "        'arrangement_density': 0.3\n",
        "    }\n",
        "\n",
        "    # Generate recommendations\n",
        "    recommendations = analyze_and_recommend(example_features)\n",
        "\n",
        "    # Display results\n",
        "    print(\"=== MIXING RECOMMENDATIONS ===\\n\")\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"{i}. {rec['category']} - {rec['subcategory']}\")\n",
        "        print(f\"   Confidence: {rec['confidence']:.2f} | Priority: {rec['priority']}\")\n",
        "        print(f\"   Reasoning: {rec['reasoning']}\")\n",
        "        print(f\"   Parameters: {rec['parameters']}\")\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq0KpH4G1l4T"
      },
      "source": [
        "## MixingLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW_EeVRiltsz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "def timed_section(name):\n",
        "    \"\"\"Decorator to time a function section - matching your existing decorator\"\"\"\n",
        "    def decorator(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.time()\n",
        "            print(f\"\\n[TIMING] Starting {name}...\")\n",
        "            result = func(*args, **kwargs)\n",
        "            duration = time.time() - start\n",
        "            print(f\"[TIMING] {name} completed in {duration:.2f} seconds\")\n",
        "            return result, duration\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "def analyze_base_recommendations(mixing_recs: List[Dict], features: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze base recommendations to extract priorities and validate against features\"\"\"\n",
        "\n",
        "    priority_1_recs = []\n",
        "    priority_2_recs = []\n",
        "    high_confidence_recs = []\n",
        "    feature_conflicts = []\n",
        "\n",
        "    for rec in mixing_recs:\n",
        "        priority = rec.get('priority', 3)\n",
        "        confidence = rec.get('confidence', 0)\n",
        "        category = rec.get('category', '')\n",
        "\n",
        "        # Categorize by priority\n",
        "        if priority == 1:\n",
        "            priority_1_recs.append(rec)\n",
        "        elif priority == 2:\n",
        "            priority_2_recs.append(rec)\n",
        "\n",
        "        # High confidence recommendations\n",
        "        if confidence > 0.8:\n",
        "            high_confidence_recs.append(rec)\n",
        "\n",
        "        # Basic feature validation\n",
        "        if category == 'EQ' and 'High-frequency enhancement' in rec.get('subcategory', ''):\n",
        "            spectral_centroid = features.get('spectral_centroid', 0)\n",
        "            if spectral_centroid > 2000:  # Already bright\n",
        "                feature_conflicts.append(f\"High-freq boost recommended but spectral centroid is {spectral_centroid:.0f}Hz\")\n",
        "\n",
        "    return {\n",
        "        'priority_1_count': len(priority_1_recs),\n",
        "        'priority_2_count': len(priority_2_recs),\n",
        "        'high_confidence_recs': high_confidence_recs,\n",
        "        'feature_conflicts': feature_conflicts,\n",
        "        'critical_categories': [rec.get('category') for rec in priority_1_recs]\n",
        "    }\n",
        "\n",
        "def create_feature_focused_prompt(features: Dict, semantic_mapping: Dict, mixing_recs: List[Dict]) -> tuple:\n",
        "    \"\"\"Create a more focused prompt that emphasizes feature-driven decisions\"\"\"\n",
        "\n",
        "    # Analyze base recommendations\n",
        "    rec_analysis = analyze_base_recommendations(mixing_recs, features)\n",
        "\n",
        "    # Extract only the most critical semantic issues\n",
        "    insights = extract_semantic_insights(semantic_mapping)\n",
        "    critical_issues = []\n",
        "\n",
        "    for feature, data in insights['critical_features'].items():\n",
        "        if data['intensity'] in ['very_high', 'very_low']:\n",
        "            critical_issues.append({\n",
        "                'feature': feature,\n",
        "                'value': data['raw_value'],\n",
        "                'issue': data['semantic_level'],\n",
        "                'severity': data['intensity']\n",
        "            })\n",
        "\n",
        "    # Key numerical thresholds\n",
        "    audio_metrics = {\n",
        "        'tempo': features.get('tempo', 0),\n",
        "        'spectral_centroid': features.get('spectral_centroid', 0),\n",
        "        'dynamic_range': features.get('dynamic_range', 0),\n",
        "        'loudness_db': features.get('loudness_db', 0),\n",
        "        'harmonic_ratio': features.get('harmonic_ratio', 0),\n",
        "        'rms_energy': features.get('rms_energy', 0)\n",
        "    }\n",
        "\n",
        "    system_prompt = \"\"\"You are a professional mixing engineer analyzing audio features.\n",
        "\n",
        "TASK: Enhance the provided base mixing recommendations by:\n",
        "1. Building upon Priority 1 recommendations first\n",
        "2. Identifying gaps the base recommendations missed\n",
        "3. Suggesting creative processing based on the audio characteristics\n",
        "4. Being specific with parameters and technical rationale\n",
        "\n",
        "RULES:\n",
        "- Base every suggestion on numerical audio features\n",
        "- Explain WHY each process is needed using specific metrics\n",
        "- Don't repeat base recommendations unless expanding them\n",
        "- Focus on the 3-4 most impactful changes\n",
        "- Use format: [Process Type - Specific Function]\n",
        "\n",
        "AUDIO FEATURE THRESHOLDS:\n",
        "- Spectral Centroid <800Hz = Dark/Muffled, >3000Hz = Bright/Harsh\n",
        "- Dynamic Range <10dB = Over-compressed, >25dB = Good dynamics\n",
        "- RMS Energy <0.05 = Quiet, >0.3 = Loud\n",
        "- Harmonic Ratio >0.8 = Very harmonic, <0.3 = Percussive/Noisy\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"AUDIO METRICS:\n",
        "{json.dumps(audio_metrics, indent=2)}\n",
        "\n",
        "CRITICAL ISSUES DETECTED:\n",
        "{json.dumps(critical_issues, indent=2)}\n",
        "\n",
        "BASE RECOMMENDATIONS SUMMARY:\n",
        "- Priority 1 items: {rec_analysis['priority_1_count']} ({', '.join(rec_analysis['critical_categories'])})\n",
        "- Priority 2 items: {rec_analysis['priority_2_count']}\n",
        "- High confidence: {len(rec_analysis['high_confidence_recs'])} recommendations\n",
        "- Potential conflicts: {rec_analysis['feature_conflicts']}\n",
        "\n",
        "DETAILED BASE RECOMMENDATIONS:\n",
        "{format_mixing_recommendations(mixing_recs)}\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. **EXPAND Priority 1 items** - provide specific parameters and additional context\n",
        "2. **IDENTIFY GAPS** - what critical issues do the base recommendations miss?\n",
        "3. **CREATIVE ADDITIONS** - suggest 2-3 creative processes that complement the base recommendations\n",
        "4. **PROCESSING ORDER** - suggest the optimal order for applying these changes, join the recomendations that are of the same field.\n",
        "For example all EQ recomendatiosn together, all the COMPRESION recomendations together, etc.\n",
        "\n",
        "Be concise but specific. Focus on actionable improvements based on the base recomendations\"\"\"\n",
        "\n",
        "    return system_prompt, user_prompt\n",
        "\n",
        "def validate_llm_response(response: str, features: Dict, mixing_recs: List[Dict]) -> str:\n",
        "    \"\"\"Add validation and formatting to LLM response\"\"\"\n",
        "\n",
        "    # Basic validation\n",
        "    if len(response.strip()) < 100:\n",
        "        return \"[WARNING] LLM response seems too short. Base recommendations may be sufficient.\"\n",
        "\n",
        "    # Check if response addresses priority 1 items\n",
        "    priority_1_categories = [rec.get('category', '') for rec in mixing_recs if rec.get('priority') == 1]\n",
        "    missing_priority_1 = []\n",
        "\n",
        "    for category in priority_1_categories:\n",
        "        if category.lower() not in response.lower():\n",
        "            missing_priority_1.append(category)\n",
        "\n",
        "    validation_note = \"\"\n",
        "    if missing_priority_1:\n",
        "        validation_note = f\"\\n[VALIDATION NOTE] Response may not address these Priority 1 items: {', '.join(missing_priority_1)}\"\n",
        "\n",
        "    return response + validation_note\n",
        "\n",
        "def analyze_and_enhance_mixing_v2(features: Dict, semantic_mapping: Dict, mixing_recs: List[Dict],\n",
        "                                 api_key: str, model: str = \"gpt-4\") -> str:\n",
        "    \"\"\"Enhanced version with better feature integration\"\"\"\n",
        "\n",
        "    try:\n",
        "        client = OpenAI(api_key=api_key)\n",
        "\n",
        "        # Create feature-focused prompts\n",
        "        system_prompt, user_prompt = create_feature_focused_prompt(features, semantic_mapping, mixing_recs)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.4,  # Slightly higher for creative insights\n",
        "            max_tokens=1200   # Slightly reduced to force conciseness\n",
        "        )\n",
        "\n",
        "        raw_response = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Validate and enhance response\n",
        "        validated_response = validate_llm_response(raw_response, features, mixing_recs)\n",
        "\n",
        "        return validated_response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"[ERROR] Enhanced LLM analysis failed: {str(e)}\\n\\nFalling back to base recommendations.\"\n",
        "\n",
        "# Updated main function\n",
        "@timed_section(\"Enhanced LLM Analysis\")\n",
        "def get_enhanced_mixing_recommendations_v2(features: Dict, semantic_mapping: Dict,\n",
        "                                         mixing_recs: List[Dict], api_key: str) -> str:\n",
        "    \"\"\"Improved version with better feature integration\"\"\"\n",
        "\n",
        "    print(\"\\n[INFO] Analyzing base recommendations and enhancing with feature-driven insights...\")\n",
        "\n",
        "    # Analyze base recommendations first\n",
        "    rec_analysis = analyze_base_recommendations(mixing_recs, features)\n",
        "    print(f\"[INFO] Found {rec_analysis['priority_1_count']} Priority 1 and {rec_analysis['priority_2_count']} Priority 2 recommendations\")\n",
        "\n",
        "    if rec_analysis['feature_conflicts']:\n",
        "        print(f\"[WARNING] Potential conflicts detected: {rec_analysis['feature_conflicts']}\")\n",
        "\n",
        "    enhanced_plan = analyze_and_enhance_mixing_v2(\n",
        "        features=features,\n",
        "        semantic_mapping=semantic_mapping,\n",
        "        mixing_recs=mixing_recs,\n",
        "        api_key=api_key\n",
        "    )\n",
        "\n",
        "    print(\"\\n[RESULT] Enhanced Mixing Strategy:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(enhanced_plan)\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return enhanced_plan\n",
        "\n",
        "# Keep your existing helper functions\n",
        "def format_value(value):\n",
        "    \"\"\"Safe formatting for all value types\"\"\"\n",
        "    if isinstance(value, (int, float)):\n",
        "        return f\"{float(value):.2f}\" if abs(value) >= 0.01 else f\"{float(value):.4f}\"\n",
        "    elif isinstance(value, (list, np.ndarray)):\n",
        "        return f\"[{', '.join(format_value(x) for x in value[:3])}{'...' if len(value) > 3 else ''}]\"\n",
        "    return str(value)\n",
        "\n",
        "def extract_semantic_insights(semantic_mapping: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"Extract key insights from semantic mapping structure\"\"\"\n",
        "    normalized_features = semantic_mapping.get('normalized_features', {})\n",
        "    contextual = semantic_mapping.get('contextual_analysis', {})\n",
        "    relationships = semantic_mapping.get('feature_relationships', {})\n",
        "    characteristics = semantic_mapping.get('pre_inferred_characteristics', {})\n",
        "\n",
        "    critical_features = {}\n",
        "    for feature, data in normalized_features.items():\n",
        "        if isinstance(data, dict) and 'semantic_level' in data:\n",
        "            intensity = data.get('intensity', 'unknown')\n",
        "            semantic_level = data.get('semantic_level', 'unknown')\n",
        "            raw_value = data.get('raw_value', 'unknown')\n",
        "\n",
        "            if intensity in ['very_high', 'very_low'] or semantic_level in ['weak', 'problematic']:\n",
        "                critical_features[feature] = {\n",
        "                    'raw_value': raw_value,\n",
        "                    'intensity': intensity,\n",
        "                    'semantic_level': semantic_level,\n",
        "                    'normalized': data.get('normalized', 0)\n",
        "                }\n",
        "\n",
        "    genre_info = characteristics.get('genre_characteristics', [])\n",
        "    mood_info = characteristics.get('mood_characteristics', [])\n",
        "\n",
        "    return {\n",
        "        'critical_features': critical_features,\n",
        "        'production_quality': contextual.get('production_quality', 'unknown'),\n",
        "        'musical_complexity': contextual.get('musical_complexity', 'unknown'),\n",
        "        'emotional_impact': contextual.get('emotional_impact', 'unknown'),\n",
        "        'frequency_coherence': relationships.get('frequency_coherence', 'unknown'),\n",
        "        'spatial_coherence': relationships.get('spatial_coherence', 'unknown'),\n",
        "        'primary_genre': genre_info[0]['genre'] if genre_info else 'unknown',\n",
        "        'genre_confidence': genre_info[0]['confidence'] if genre_info else 0,\n",
        "        'primary_mood': mood_info[0]['mood'] if mood_info else 'unknown',\n",
        "        'problematic_relationships': [k for k, v in relationships.items()\n",
        "                                    if 'problematic' in str(v) or 'misaligned' in str(v)]\n",
        "    }\n",
        "\n",
        "def format_mixing_recommendations(recommendations: List[Dict]) -> str:\n",
        "    \"\"\"Format mixing recommendations for LLM processing\"\"\"\n",
        "    if not recommendations:\n",
        "        return \"No base recommendations available\"\n",
        "\n",
        "    formatted = []\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        priority_text = f\"Priority {rec.get('priority', 'N/A')}\"\n",
        "\n",
        "        formatted.append(\n",
        "            f\"{i}. [{rec.get('category', 'Unknown')}] {rec.get('subcategory', '')}\\n\"\n",
        "            f\"   {priority_text} | Confidence: {rec.get('confidence', 0):.2f}\\n\"\n",
        "            f\"   Reasoning: {rec.get('reasoning', 'N/A')}\\n\"\n",
        "            f\"   Technical: {rec.get('technical_rationale', 'N/A')}\\n\"\n",
        "            f\"   Parameters: {json.dumps(rec.get('parameters', {}), indent=6)}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\\n\".join(formatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00fCKRSVuLwq"
      },
      "outputs": [],
      "source": [
        "#### CHATBOT IMPLEMENTATION ####\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "\n",
        "\n",
        "def initialize_mixing_chatbot_v2(api_key: str, features: Dict, semantic_mapping: Dict,\n",
        "                                enhanced_plan: str, mixing_recs: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"Initialize chatbot state with enhanced mixing context - V2\"\"\"\n",
        "\n",
        "    # Analyze base recommendations using your new logic\n",
        "    # Handle potential tuple return from timed functions\n",
        "    try:\n",
        "        rec_analysis_result = analyze_base_recommendations(mixing_recs, features)\n",
        "        if isinstance(rec_analysis_result, tuple):\n",
        "            rec_analysis = rec_analysis_result[0]  # Extract the actual result, ignore timing\n",
        "        else:\n",
        "            rec_analysis = rec_analysis_result\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] analyze_base_recommendations failed: {e}\")\n",
        "        rec_analysis = {\n",
        "            'critical_categories': [],\n",
        "            'feature_conflicts': [],\n",
        "            'priority_1_count': 0,\n",
        "            'priority_2_count': 0,\n",
        "            'high_confidence_recs': []\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        insights_result = extract_semantic_insights(semantic_mapping)\n",
        "        if isinstance(insights_result, tuple):\n",
        "            insights = insights_result[0]  # Extract the actual result, ignore timing\n",
        "        else:\n",
        "            insights = insights_result\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] extract_semantic_insights failed: {e}\")\n",
        "        insights = {\n",
        "            'critical_features': {},\n",
        "            'primary_genre': 'Unknown',\n",
        "            'genre_confidence': 0.0,\n",
        "            'production_quality': 'Unknown',\n",
        "            'musical_complexity': 'Unknown'\n",
        "        }\n",
        "\n",
        "    # Ensure rec_analysis is a dictionary\n",
        "    if not isinstance(rec_analysis, dict):\n",
        "        print(f\"[WARNING] rec_analysis is not a dict, got: {type(rec_analysis)}\")\n",
        "        rec_analysis = {\n",
        "            'critical_categories': [],\n",
        "            'feature_conflicts': [],\n",
        "            'priority_1_count': 0,\n",
        "            'priority_2_count': 0,\n",
        "            'high_confidence_recs': []\n",
        "        }\n",
        "\n",
        "    # Ensure insights is a dictionary\n",
        "    if not isinstance(insights, dict):\n",
        "        print(f\"[WARNING] insights is not a dict, got: {type(insights)}\")\n",
        "        insights = {\n",
        "            'critical_features': {},\n",
        "            'primary_genre': 'Unknown',\n",
        "            'genre_confidence': 0.0,\n",
        "            'production_quality': 'Unknown',\n",
        "            'musical_complexity': 'Unknown'\n",
        "        }\n",
        "\n",
        "    # Extract critical audio metrics for quick reference\n",
        "    audio_metrics = {\n",
        "        'tempo': features.get('tempo', 0),\n",
        "        'spectral_centroid': features.get('spectral_centroid', 0),\n",
        "        'dynamic_range': features.get('dynamic_range', 0),\n",
        "        'loudness_db': features.get('loudness_db', 0),\n",
        "        'harmonic_ratio': features.get('harmonic_ratio', 0),\n",
        "        'rms_energy': features.get('rms_energy', 0)\n",
        "    }\n",
        "\n",
        "    # Build priority-based recommendation summary\n",
        "    priority_summary = {\n",
        "        'priority_1_recs': [rec for rec in mixing_recs if rec.get('priority') == 1],\n",
        "        'priority_2_recs': [rec for rec in mixing_recs if rec.get('priority') == 2],\n",
        "        'high_confidence_recs': [rec for rec in mixing_recs if rec.get('confidence', 0) > 0.8],\n",
        "        'critical_categories': rec_analysis.get('critical_categories', []),\n",
        "        'feature_conflicts': rec_analysis.get('feature_conflicts', [])\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'client': OpenAI(api_key=api_key),\n",
        "        'features': features,\n",
        "        'semantic_mapping': semantic_mapping,\n",
        "        'enhanced_plan': enhanced_plan,\n",
        "        'mixing_recs': mixing_recs,\n",
        "        'audio_metrics': audio_metrics,\n",
        "        'insights': insights,\n",
        "        'rec_analysis': rec_analysis,\n",
        "        'priority_summary': priority_summary,\n",
        "        'conversation_history': [],\n",
        "        'session_start': time.time()\n",
        "    }\n",
        "\n",
        "\n",
        "def create_context_aware_prompt_v2(chatbot_state: Dict, user_question: str) -> str:\n",
        "    \"\"\"Create enhanced context prompt matching your V2 methodology\"\"\"\n",
        "\n",
        "    insights = chatbot_state['insights']\n",
        "    rec_analysis = chatbot_state['rec_analysis']\n",
        "    audio_metrics = chatbot_state['audio_metrics']\n",
        "    priority_summary = chatbot_state['priority_summary']\n",
        "\n",
        "    # Build critical issues summary\n",
        "    critical_issues = []\n",
        "    critical_features = insights.get('critical_features', {})\n",
        "    for feature, data in critical_features.items():\n",
        "        if isinstance(data, dict) and data.get('intensity') in ['very_high', 'very_low']:\n",
        "            critical_issues.append({\n",
        "                'feature': feature,\n",
        "                'value': data.get('raw_value', 'N/A'),\n",
        "                'issue': data.get('semantic_level', 'N/A'),\n",
        "                'severity': data.get('intensity', 'N/A')\n",
        "            })\n",
        "\n",
        "    # Enhanced context prompt matching your V2 approach\n",
        "    context_prompt = f\"\"\"You are a professional mixing engineer assistant with deep technical knowledge.\n",
        "\n",
        "TRACK ANALYSIS CONTEXT:\n",
        "Genre: {insights.get('primary_genre', 'Unknown')} (confidence: {insights.get('genre_confidence', 0):.2f})\n",
        "Production Quality: {insights.get('production_quality', 'Unknown')}\n",
        "Musical Complexity: {insights.get('musical_complexity', 'Unknown')}\n",
        "\n",
        "AUDIO METRICS:\n",
        "{json.dumps(audio_metrics, indent=2)}\n",
        "\n",
        "CRITICAL ISSUES DETECTED:\n",
        "{json.dumps(critical_issues, indent=2)}\n",
        "\n",
        "RECOMMENDATION ANALYSIS:\n",
        "- Priority 1 items: {rec_analysis.get('priority_1_count', 0)} ({', '.join(rec_analysis.get('critical_categories', []))})\n",
        "- Priority 2 items: {rec_analysis.get('priority_2_count', 0)}\n",
        "- High confidence recommendations: {len(rec_analysis.get('high_confidence_recs', []))}\n",
        "- Feature conflicts identified: {rec_analysis.get('feature_conflicts', [])}\n",
        "\n",
        "CURRENT ENHANCED MIXING STRATEGY:\n",
        "{chatbot_state['enhanced_plan']}\n",
        "\n",
        "PRIORITY 1 RECOMMENDATIONS:\n",
        "{format_priority_recommendations(priority_summary['priority_1_recs'])}\n",
        "\n",
        "AUDIO FEATURE INTERPRETATION GUIDE:\n",
        "- Spectral Centroid <800Hz = Dark/Muffled, >3000Hz = Bright/Harsh\n",
        "- Dynamic Range <10dB = Over-compressed, >25dB = Good dynamics\n",
        "- RMS Energy <0.05 = Quiet, >0.3 = Loud\n",
        "- Harmonic Ratio >0.8 = Very harmonic, <0.3 = Percussive/Noisy\n",
        "\n",
        "RESPONSE GUIDELINES:\n",
        "- Base all advice on the numerical audio features provided\n",
        "- Reference specific metrics when explaining WHY a process is needed\n",
        "- Use format: [Process Type - Specific Function] for recommendations\n",
        "- Prioritize addressing Priority 1 issues first\n",
        "- Validate suggestions against feature conflicts\n",
        "- Be specific with parameters and technical rationale\n",
        "- Don't reference AI, models, or prior suggestions\n",
        "\n",
        "Answer the user's question with detailed, feature-driven reasoning.\"\"\"\n",
        "\n",
        "    return context_prompt\n",
        "\n",
        "def format_priority_recommendations(priority_recs: List[Dict]) -> str:\n",
        "    \"\"\"Format priority recommendations for chatbot context\"\"\"\n",
        "    if not priority_recs:\n",
        "        return \"No Priority 1 recommendations found\"\n",
        "\n",
        "    formatted = []\n",
        "    for i, rec in enumerate(priority_recs, 1):\n",
        "        formatted.append(\n",
        "            f\"{i}. [{rec.get('category', 'Unknown')}] {rec.get('subcategory', '')}\\n\"\n",
        "            f\"   Confidence: {rec.get('confidence', 0):.2f}\\n\"\n",
        "            f\"   Reasoning: {rec.get('reasoning', 'N/A')}\\n\"\n",
        "            f\"   Parameters: {json.dumps(rec.get('parameters', {}))}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\\n\".join(formatted)\n",
        "\n",
        "def validate_chat_response_v2(response: str, chatbot_state: Dict, user_question: str) -> str:\n",
        "    \"\"\"Enhanced response validation matching your V2 approach\"\"\"\n",
        "\n",
        "    rec_analysis = chatbot_state['rec_analysis']\n",
        "    audio_metrics = chatbot_state['audio_metrics']\n",
        "\n",
        "    validation_notes = []\n",
        "\n",
        "    # Check if response is too short\n",
        "    if len(response.strip()) < 50:\n",
        "        validation_notes.append(\"Response seems brief - consider asking for more specific details\")\n",
        "\n",
        "    # Check if Priority 1 categories are addressed when relevant\n",
        "    priority_1_categories = rec_analysis.get('critical_categories', [])\n",
        "    question_lower = user_question.lower()\n",
        "\n",
        "    # If user asks about EQ, compression, etc., check if Priority 1 items are considered\n",
        "    mixing_keywords = ['eq', 'compression', 'reverb', 'delay', 'processing', 'mix', 'sound']\n",
        "    if any(keyword in question_lower for keyword in mixing_keywords):\n",
        "        missing_priority_1 = []\n",
        "        for category in priority_1_categories:\n",
        "            if category.lower() not in response.lower():\n",
        "                missing_priority_1.append(category)\n",
        "\n",
        "        if missing_priority_1:\n",
        "            validation_notes.append(f\"Consider Priority 1 items: {', '.join(missing_priority_1)}\")\n",
        "\n",
        "    # Check for feature conflicts mentioned in original analysis\n",
        "    feature_conflicts = rec_analysis.get('feature_conflicts', [])\n",
        "    if feature_conflicts and 'conflict' not in response.lower():\n",
        "        if any(conflict_term in question_lower for conflict_term in ['bright', 'eq', 'frequency', 'high']):\n",
        "            validation_notes.append(\"Note: Feature conflicts were detected in analysis\")\n",
        "\n",
        "    # Add validation notes if any\n",
        "    if validation_notes:\n",
        "        validation_section = \"\\n\\n[ASSISTANT NOTES]\\n\" + \"\\n\".join(f\" {note}\" for note in validation_notes)\n",
        "        return response + validation_section\n",
        "\n",
        "    return response\n",
        "\n",
        "def chat_mixing_followup_v2(chatbot_state: Dict, user_question: str, model: str = \"gpt-4\") -> str:\n",
        "    \"\"\"Enhanced follow-up chat matching your V2 methodology\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Create enhanced context prompt\n",
        "        context_prompt = create_context_aware_prompt_v2(chatbot_state, user_question)\n",
        "        '''\n",
        "        # Get LLM response\n",
        "        response = chatbot_state['client'].chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": context_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_question}\n",
        "            ],\n",
        "            temperature=0.4,  # Matching your V2 temperature\n",
        "            max_tokens=600    # Balanced response length\n",
        "        )\n",
        "\n",
        "        raw_answer = response.choices[0].message.content.strip()\n",
        "        '''\n",
        "\n",
        "\n",
        "        raw_response = chatbot_state['client'].chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": context_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_question}\n",
        "                 ],\n",
        "                temperature=0.4,\n",
        "                max_tokens=600\n",
        "        )\n",
        "\n",
        "        # Manejar si es un tuple (posiblemente por decorador de tiempo)\n",
        "        if isinstance(raw_response, tuple):\n",
        "            response = raw_response[0]\n",
        "        else:\n",
        "            response = raw_response\n",
        "\n",
        "        raw_answer = response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "        # Apply V2 validation\n",
        "        validated_answer = validate_chat_response_v2(raw_answer, chatbot_state, user_question)\n",
        "\n",
        "        # Store in conversation history with enhanced metadata\n",
        "        chatbot_state['conversation_history'].append({\n",
        "            'timestamp': time.time(),\n",
        "            'user': user_question,\n",
        "            'assistant': validated_answer,\n",
        "            'context_used': {\n",
        "                'priority_1_count': chatbot_state['rec_analysis'].get('priority_1_count', 0),\n",
        "                'critical_features': list(chatbot_state['insights'].get('critical_features', {}).keys()),\n",
        "                'feature_conflicts': len(chatbot_state['rec_analysis'].get('feature_conflicts', []))\n",
        "            }\n",
        "        })\n",
        "\n",
        "        return validated_answer\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = f\"[ERROR] Chat response failed: {str(e)}\"\n",
        "\n",
        "        # Safe fallback that handles potential tuple issues\n",
        "        try:\n",
        "            priority_1_count = chatbot_state['rec_analysis'].get('priority_1_count', 0)\n",
        "            critical_categories = chatbot_state['rec_analysis'].get('critical_categories', [])\n",
        "        except (TypeError, KeyError):\n",
        "            priority_1_count = 0\n",
        "            critical_categories = []\n",
        "\n",
        "        # Fallback to basic recommendation summary\n",
        "        fallback_response = f\"\"\"\n",
        "{error_response}\n",
        "\n",
        "FALLBACK - KEY RECOMMENDATIONS:\n",
        "Priority 1 Items: {priority_1_count}\n",
        "Critical Categories: {', '.join(critical_categories)}\n",
        "\n",
        "Try rephrasing your question or ask about specific aspects like EQ, compression, or effects.\n",
        "\"\"\"\n",
        "        return fallback_response\n",
        "\n",
        "def get_chatbot_session_summary_v2(chatbot_state: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"Generate enhanced session summary with V2 analytics\"\"\"\n",
        "\n",
        "    session_duration = time.time() - chatbot_state['session_start']\n",
        "    conversation_count = len(chatbot_state['conversation_history'])\n",
        "\n",
        "    # Analyze conversation topics\n",
        "    topics_discussed = []\n",
        "    for conv in chatbot_state['conversation_history']:\n",
        "        question = conv['user'].lower()\n",
        "        if 'eq' in question or 'frequency' in question:\n",
        "            topics_discussed.append('EQ/Frequency')\n",
        "        elif 'compress' in question or 'dynamic' in question:\n",
        "            topics_discussed.append('Compression/Dynamics')\n",
        "        elif 'reverb' in question or 'delay' in question:\n",
        "            topics_discussed.append('Time-based Effects')\n",
        "        elif 'mix' in question or 'balance' in question:\n",
        "            topics_discussed.append('Mix Balance')\n",
        "        elif 'creative' in question or 'effect' in question:\n",
        "            topics_discussed.append('Creative Effects')\n",
        "\n",
        "    return {\n",
        "        'session_duration_minutes': session_duration / 60,\n",
        "        'total_questions': conversation_count,\n",
        "        'topics_discussed': list(set(topics_discussed)),\n",
        "        'priority_1_recommendations': len(chatbot_state['priority_summary']['priority_1_recs']),\n",
        "        'feature_conflicts_identified': len(chatbot_state['rec_analysis'].get('feature_conflicts', [])),\n",
        "        'track_info': {\n",
        "            'genre': chatbot_state['insights'].get('primary_genre', 'Unknown'),\n",
        "            'critical_issues': len(chatbot_state['insights'].get('critical_features', {})),\n",
        "            'production_quality': chatbot_state['insights'].get('production_quality', 'Unknown')\n",
        "        },\n",
        "        'last_interaction': chatbot_state['conversation_history'][-1]['timestamp'] if conversation_count > 0 else None\n",
        "    }\n",
        "\n",
        "# Helper function to work with your existing codebase\n",
        "def timed_section(name):\n",
        "    \"\"\"Decorator to time a function section\"\"\"\n",
        "    def decorator(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.time()\n",
        "            print(f\"\\n[TIMING] Starting {name}...\")\n",
        "            result = func(*args, **kwargs)\n",
        "            duration = time.time() - start\n",
        "            print(f\"[TIMING] {name} completed in {duration:.2f} seconds\")\n",
        "            return result, duration\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Integration function for your pipeline\n",
        "def setup_enhanced_mixing_chatbot(features: Dict, semantic_mapping: Dict, enhanced_plan: str,\n",
        "                                 mixing_recs: List[Dict], api_key: str) -> Dict[str, Any]:\n",
        "    \"\"\"Complete setup function for enhanced mixing chatbot\"\"\"\n",
        "\n",
        "    print(\"\\n[INFO] Initializing enhanced mixing chatbot with V2 logic...\")\n",
        "\n",
        "    chatbot_state = initialize_mixing_chatbot_v2(\n",
        "        api_key=api_key,\n",
        "        features=features,\n",
        "        semantic_mapping=semantic_mapping,\n",
        "        enhanced_plan=enhanced_plan,\n",
        "        mixing_recs=mixing_recs\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Chatbot ready - {len(mixing_recs)} recommendations analyzed\")\n",
        "    print(f\"[INFO] Priority 1 items: {chatbot_state['rec_analysis'].get('priority_1_count', 0)}\")\n",
        "    print(f\"[INFO] Feature conflicts: {len(chatbot_state['rec_analysis'].get('feature_conflicts', []))}\")\n",
        "\n",
        "    return chatbot_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI8gopxLhlu6"
      },
      "source": [
        "## PrompterLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKcELOV_hlE2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def extract_semantic_features(semantic_mapping):\n",
        "    \"\"\"Enhanced extraction aligned with semantic mapping logic\"\"\"\n",
        "\n",
        "    tempo_bpm = int(semantic_mapping['normalized_features']['tempo']['raw_value'])\n",
        "    tempo_feel = semantic_mapping['semantic_interpretations']['energy_characteristics']['level']\n",
        "\n",
        "    # Dynamic key extraction if available\n",
        "    raw_key = semantic_mapping.get('raw_features', {})\n",
        "    raw_mode = semantic_mapping.get('raw_features', {})\n",
        "    key_exact = f\"{raw_key} {raw_mode}\"\n",
        "    tonic_stability = semantic_mapping['normalized_features']['tonic_stability']['semantic_level']\n",
        "\n",
        "    # Timbre\n",
        "    centroid = semantic_mapping['semantic_interpretations']['spectral_centroid']['semantic_level']\n",
        "    complexity = semantic_mapping['semantic_interpretations']['complexity_characteristics']['level']\n",
        "    freq_char = semantic_mapping['semantic_interpretations']['frequency_characteristics']\n",
        "    mfcc_char = semantic_mapping['semantic_interpretations'].get('mfcc_characteristics', {}).get('timbral_character', '')\n",
        "    timbre_descriptors = list(filter(None, [centroid, freq_char['profile'], mfcc_char]))\n",
        "\n",
        "    # Dynamics\n",
        "    dynamic_char = semantic_mapping['semantic_interpretations']['dynamic_characteristics']\n",
        "    dynamics = dynamic_char['dynamic_impression']\n",
        "\n",
        "    # Genre / mood / instrumentation\n",
        "    pre = semantic_mapping['pre_inferred_characteristics']\n",
        "    mood = pre['mood_characteristics'][0].get('mood', semantic_mapping['contextual_analysis']['emotional_impact'])\n",
        "    instrumentation = pre['instrumentation_tags'][0].get('type', 'mixed instruments')\n",
        "\n",
        "\n",
        "    return {\n",
        "        'tempo_bpm': tempo_bpm,\n",
        "        'tempo_feel': tempo_feel,\n",
        "        'key_exact': key_exact,\n",
        "        'key_character': tonic_stability,\n",
        "        'timbre_descriptors': timbre_descriptors,\n",
        "        'instrumentation': instrumentation,\n",
        "        'dynamics': dynamics,\n",
        "        'mood': mood,\n",
        "\n",
        "    }\n",
        "\n",
        "def prompt_gpt_optimized(semantic_mapping, user_request,api_key):\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    features = extract_semantic_features(semantic_mapping)\n",
        "\n",
        "    audio_description = (\n",
        "        f\"{features['tempo_bpm']} BPM ({features['tempo_feel']}), \"\n",
        "        f\"key: {features['key_exact']} ({features['key_character']} stability), \"\n",
        "        f\"timbre: {', '.join(features['timbre_descriptors'])}, \"\n",
        "        f\"instrumentation: {features['instrumentation']} \"\n",
        "        f\"dynamics: {features['dynamics']}, \"\n",
        "        f\"mood: {features['mood']} \"\n",
        "    )\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a  Prompt Generator. You create concise and meaningful prompts to create music with an IA music generator model.\"\n",
        "        \"Use specific musical terms for tempo, key, instrumentation, and mood. \"\n",
        "        \"Focus on the recived audio features and the user request to create the prompt\"\n",
        "        \"Use around 80 word, be concise and create the prompt based on the most important audio featureas plus the user request\"\n",
        "    )\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"Based on the description of the following audio sample: {audio_description}\\n\\n\"\n",
        "        f\"Based on the User request: {user_request}\\n\"\n",
        "        f\"Generate at {features['tempo_bpm']} BPM with {features['key_exact']} key.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        prompt = response.choices[0].message.content.strip()\n",
        "        clean = re.sub(r\"based on.*?reference|inspired by.*?original|similar to.*?analyzed|matching the.*?audio\", \"\", prompt, flags=re.I)\n",
        "\n",
        "        return clean.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"GPT API Error: {e}\")\n",
        "        return (\n",
        "            f\"Create a music piece at {features['tempo_bpm']} BPM. With {features['key_exact']} key \"\n",
        "            f\"{features['mood']} mood, \"\n",
        "            f\"{features['instrumentation']}intrumentation, \"\n",
        "            f\"and with the user request: {user_request}\"\n",
        "        ).strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzgYis6-X1Ae"
      },
      "source": [
        "## Music Generator (MusicGen model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3X_nIxq7p07"
      },
      "outputs": [],
      "source": [
        "## === My version ===\n",
        "from transformers import MusicgenForConditionalGeneration, AutoProcessor, MusicgenMelodyForConditionalGeneration\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "\n",
        "# Opcional: puedes definir un diccionario para mapear nombres a modelos y procesadores\n",
        "MODEL_MAP = {\n",
        "    \"musicgen-small\": {\n",
        "        \"model\": lambda: MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\", attn_implementation=\"eager\"),\n",
        "        \"processor\": lambda: AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
        "    },\n",
        "    \"musicgen-melody\": {\n",
        "        \"model\": lambda: MusicgenMelodyForConditionalGeneration.from_pretrained(\"facebook/musicgen-melody\"),\n",
        "        \"processor\": lambda: AutoProcessor.from_pretrained(\"facebook/musicgen-melody\")\n",
        "    }\n",
        "    # Puedes agregar ms modelos aqu si lo deseas\n",
        "}\n",
        "\n",
        "def generar_audio(audio_np, prompt, sr, model_name, output_path=None):\n",
        "    # Carga el modelo y el processor segn el nombre\n",
        "    if model_name not in MODEL_MAP:\n",
        "        raise ValueError(f\"Modelo '{model_name}' no soportado. Opciones: {list(MODEL_MAP.keys())}\")\n",
        "    model = MODEL_MAP[model_name][\"model\"]()\n",
        "    processor = MODEL_MAP[model_name][\"processor\"]()\n",
        "\n",
        "    waveform = torch.tensor(audio_np, dtype=torch.float32)\n",
        "    if waveform.ndim == 1:\n",
        "        waveform = waveform.unsqueeze(0)\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    if sr != 32000:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, 32000)\n",
        "        sr = 32000\n",
        "\n",
        "    waveform = waveform / (waveform.abs().max() + 1e-9)\n",
        "    assert not torch.isnan(waveform).any()\n",
        "    assert not torch.isinf(waveform).any()\n",
        "\n",
        "    processor.tokenizer.model_input_names\n",
        "    token_ids = processor.tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    print(\" Mximo token ID:\", token_ids.max().item())\n",
        "    assert token_ids.max() < 32000, \" Token fuera del vocabulario\"\n",
        "\n",
        "\n",
        "    if model_name == \"musicgen-melody\":\n",
        "     inputs = processor(\n",
        "        audio=waveform,\n",
        "        sampling_rate=sr,\n",
        "        text=[prompt],\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    else:\n",
        "     inputs = processor(\n",
        "        sampling_rate=sr,\n",
        "        text=[prompt],\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    for k, v in inputs.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            print(f\"\\n Tensor: {k}\")\n",
        "            print(f\"  shape: {v.shape}\")\n",
        "            print(f\"  dtype: {v.dtype}\")\n",
        "            print(f\"  max: {v.max().item()}, min: {v.min().item()}\")\n",
        "            print(f\"  contains nan: {torch.isnan(v).any().item()}, inf: {torch.isinf(v).any().item()}\")\n",
        "            try:\n",
        "                inputs[k] = v.to(model.device)\n",
        "            except Exception as e:\n",
        "                print(f\" Error moviendo {k} a {model.device}: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            print(f\" {k} no es tensor, tipo: {type(v)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        audio_values = model.generate(**inputs, max_new_tokens=1024)[0]\n",
        "\n",
        "    save_path = output_path or \"musicgen_output.wav\"\n",
        "    torchaudio.save(save_path, audio_values.cpu(), 32000)\n",
        "    print(f\" Audio guardado en: {save_path}\")\n",
        "\n",
        "    audio = audio_values.cpu().numpy().astype(\"float32\")\n",
        "    audio /= max(np.abs(audio).max(), 1e-5)\n",
        "\n",
        "    return 32000, audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibWhFW5uJFZn"
      },
      "source": [
        "## Stem_Separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaYQhoxBJKU5"
      },
      "outputs": [],
      "source": [
        "\"\"\"### Stems y Midi\"\"\"\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from demucs.apply import apply_model\n",
        "from demucs.pretrained import get_model\n",
        "\n",
        "def separate_stems3(audio_path, output_dir, model_name='htdemucs'):\n",
        "    \"\"\"\n",
        "    Modelos disponibles:\n",
        "    - 'htdemucs': Mejor calidad general (4 stems)\n",
        "    - 'htdemucs_ft': Fine-tuned, mejor separacin\n",
        "    - 'htdemucs_6s': 6 stems (incluye piano y guitarra)\n",
        "    - 'mdx_extra': Modelo hbrido, muy buena calidad\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    model = get_model(model_name)\n",
        "    model.eval()\n",
        "\n",
        "    # === Load & Preprocessing ===\n",
        "    waveform, sr = torchaudio.load(audio_path)\n",
        "\n",
        "    # Resampleo a 44.1kHz (estndar para Demucs)\n",
        "    if sr != 44100:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=44100)\n",
        "        waveform = resampler(waveform)\n",
        "        sr = 44100\n",
        "\n",
        "    # Normalizar\n",
        "    waveform = waveform / waveform.abs().max()\n",
        "\n",
        "    # Stereo enforcement\n",
        "    if waveform.shape[0] == 1:\n",
        "        waveform = waveform.repeat(2, 1)\n",
        "\n",
        "    # === Separacin con parmetros optimizados ===\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    with torch.no_grad():\n",
        "        sources = apply_model(\n",
        "            model,\n",
        "            waveform.unsqueeze(0),\n",
        "            device=device,\n",
        "            shifts=1,\n",
        "            split=True,\n",
        "            overlap=0.25\n",
        "        )\n",
        "\n",
        "    # === Postprocesamiento y guardado ===\n",
        "    fade_len = int(0.01 * sr)  # 10 ms\n",
        "    stems_info = {}\n",
        "\n",
        "    for i, name in enumerate(model.sources):\n",
        "        stem = sources[0, i].cpu().numpy()\n",
        "\n",
        "        # Fade in/out para evitar clicks\n",
        "        stem[:, :fade_len] *= np.linspace(0, 1, fade_len)\n",
        "        stem[:, -fade_len:] *= np.linspace(1, 0, fade_len)\n",
        "\n",
        "        # RMS\n",
        "        rms = np.sqrt(np.mean(stem**2))\n",
        "        duration = stem.shape[1] / sr\n",
        "        output_path = os.path.join(output_dir, f\"{name}.wav\")\n",
        "\n",
        "        # Guardar solo si tiene contenido relevante\n",
        "        if rms > 0.005:\n",
        "            sf.write(output_path, stem.T, sr, subtype='PCM_24')\n",
        "            print(f\" Guardado: {name}.wav | RMS={rms:.4f}\")\n",
        "        else:\n",
        "            print(f\" {name}: ignorado (muy bajo nivel de seal, RMS={rms:.4f})\")\n",
        "            output_path = None\n",
        "\n",
        "        # Guardar info tcnica\n",
        "        stems_info[name] = {\n",
        "            'rms': float(rms),\n",
        "            'duration_sec': float(duration),\n",
        "            'path': output_path  # Use this value when joining paths elsewhere\n",
        "        }\n",
        "\n",
        "        # Asignar tipo segn nombre\n",
        "    for name, info in stems_info.items():\n",
        "        if name in ['drums', 'bass', 'other', 'vocals']:\n",
        "              info['type'] = 'drum' if name == 'drums' else 'melodic'\n",
        "\n",
        "    return stems_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W37jEKcTJH-a"
      },
      "source": [
        "## Midi_Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SJ0eVuarJLOw"
      },
      "outputs": [],
      "source": [
        "### === MAPEO DE ELEMENTOS MELODICOS === ###\n",
        "from basic_pitch.inference import predict\n",
        "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
        "\n",
        "\n",
        "## Mapeo Midi de Melodias\n",
        "def midi_mapping2(audio_path, output_path):\n",
        "\n",
        "    # Configuracin avanzada\n",
        "    model_output, midi_data, note_events = predict(\n",
        "        audio_path,\n",
        "        model_or_model_path=ICASSP_2022_MODEL_PATH,\n",
        "        onset_threshold=0.5,  # Ajustar sensibilidad\n",
        "        frame_threshold=0.3,  # Threshold para notas sostenidas\n",
        "        minimum_note_length=58,  # Duracin mnima en ms\n",
        "        minimum_frequency=80,   # Hz mnimos\n",
        "        maximum_frequency=2000, # Hz mximos\n",
        "        multiple_pitch_bends=False,\n",
        "        melodia_trick=True  # Mejora monofnico\n",
        "    )\n",
        "\n",
        "        # Guardar archivo MIDI\n",
        "    midi_data.write(output_path)\n",
        "    print(f\" Guardado MIDI en: {output_path}\")\n",
        "\n",
        "    return midi_data\n",
        "\n",
        "\n",
        "\n",
        "### === MAPEO DE DRUMS === ###\n",
        "  # Experimental Feature. DRUM MIDI MAPPING is a difficult task due to the nature of the drums (onsets) different to melodies (harmony)\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from mido import MidiFile, MidiTrack, Message\n",
        "\n",
        "def extract_features(y_segment, sr):\n",
        "    mfcc = librosa.feature.mfcc(y=y_segment, sr=sr, n_mfcc=13)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y_segment, sr=sr)\n",
        "    rms = librosa.feature.rms(y=y_segment)\n",
        "    return np.concatenate([\n",
        "        np.mean(mfcc, axis=1),\n",
        "        np.mean(spectral_centroid, axis=1),\n",
        "        np.mean(rms, axis=1),\n",
        "    ])\n",
        "\n",
        "def convert_drums_to_midi(audio_path, midi_out_path=\"output.mid\", n_clusters=3):\n",
        "    y, sr = librosa.load(audio_path, sr=None) #mismo import que con torch.audio\n",
        "\n",
        "    # Onset detection\n",
        "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, units='frames')\n",
        "    onset_times = librosa.frames_to_time(onset_frames, sr=sr)\n",
        "    onset_samples = librosa.frames_to_samples(onset_frames)\n",
        "\n",
        "    samples_per_onset = int(0.1 * sr)\n",
        "    windows = []\n",
        "    for onset in onset_samples:\n",
        "        start = max(0, onset - samples_per_onset // 2)\n",
        "        end = min(len(y), onset + samples_per_onset // 2)\n",
        "        segment = y[start:end]\n",
        "        windows.append(segment)\n",
        "\n",
        "    # Feature extraction\n",
        "    features = np.array([extract_features(seg, sr) for seg in windows])\n",
        "\n",
        "    # Clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    cluster_labels = kmeans.fit_predict(features)\n",
        "\n",
        "    # Heuristic MIDI note mapping by average energy\n",
        "    energies = [np.mean(f[-1]) for f in features]\n",
        "    cluster_means = [np.mean([energies[i] for i in range(len(energies)) if cluster_labels[i] == c]) for c in range(n_clusters)]\n",
        "    sorted_clusters = np.argsort(cluster_means)[::-1]\n",
        "    midi_map = {\n",
        "        sorted_clusters[0]: 36,  # Kick\n",
        "        sorted_clusters[1]: 38,  # Snare\n",
        "        sorted_clusters[2]: 42   # Hi-hat\n",
        "    }\n",
        "\n",
        "    # MIDI generation\n",
        "    mid = MidiFile()\n",
        "    track = MidiTrack()\n",
        "    mid.tracks.append(track)\n",
        "\n",
        "    ticks_per_beat = mid.ticks_per_beat\n",
        "    for onset_time, cluster in zip(onset_times, cluster_labels):\n",
        "        note = midi_map.get(cluster, 35)  # default note if missing\n",
        "        time_ticks = int(onset_time * ticks_per_beat)\n",
        "        track.append(Message('note_on', note=note, velocity=100, time=time_ticks))\n",
        "        track.append(Message('note_off', note=note, velocity=0, time=10))\n",
        "\n",
        "    mid.save(midi_out_path)\n",
        "    print(f\" Guardado: {midi_out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyzSKUg6JCXC"
      },
      "source": [
        "# APP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4L454hGC_1"
      },
      "source": [
        "- Simple user-oriented app interface using Gradio, targeted to music producer and music enthusiasts that want to learn more about audio features and mixing effect processing chains. The full app output is also showed at the console below the interface, showing the full logic of the app.\n",
        "-Notes:\n",
        "  - If the interface is not working a `main()` module has been also implemented.\n",
        "  - The audio generation module can take some time to produce the audio output, due to the used model nature. Use `GPU` usage for faster production time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gTD1tx8qJS"
      },
      "source": [
        "## Final Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Final Interface\n",
        "\n",
        "import gradio as gr\n",
        "import librosa\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, Any, List, Tuple\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "# Global variables to store analysis results\n",
        "global_features = None\n",
        "global_semantic_mapping = None\n",
        "global_mixing_recs = None\n",
        "global_enhanced_mixing = None\n",
        "global_stems_info = None\n",
        "global_midi_outputs = None\n",
        "global_chatbot_instance = None\n",
        "global_audio_data = None\n",
        "global_sample_rate = None\n",
        "\n",
        "\n",
        "# Folder for storing stems and MIDI outputs\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Detectar entorno (Colab o local)\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    base_dir = \"/content\"\n",
        "else:\n",
        "    base_dir = os.path.abspath(os.path.join(os.getcwd(), \"notebooks\"))\n",
        "\n",
        "# Definir carpetas base para stems, midi y output\n",
        "stems_dir = os.path.join(base_dir, \"stems\")\n",
        "midi_dir = os.path.join(base_dir, \"midi_out\")\n",
        "output_audio_dir = os.path.join(base_dir, \"output_audio\")\n",
        "\n",
        "# Crear carpetas si no existen\n",
        "os.makedirs(stems_dir, exist_ok=True)\n",
        "os.makedirs(midi_dir, exist_ok=True)\n",
        "os.makedirs(output_audio_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "#### MAIN EXTRACTION FUNCTION ####\n",
        "\n",
        "def extract_key_features(audio_file):\n",
        "    \"\"\"Extract features using your existing functions\"\"\"\n",
        "    global global_features, global_semantic_mapping, global_mixing_recs, global_enhanced_mixing\n",
        "    global global_audio_data, global_sample_rate\n",
        "\n",
        "    if audio_file is None:\n",
        "        return \"Please upload an audio file\", None, None\n",
        "\n",
        "    try:\n",
        "        # Load audio (using same parameters as your main)\n",
        "        print(f\"\\n[INFO] Loading audio: {audio_file}\")\n",
        "        audio_data, sample_rate = librosa.load(audio_file, sr=22050, mono=True, duration=30)\n",
        "        duration = len(audio_data)/sample_rate\n",
        "        print(f\"[INFO] Loaded {duration:.1f}s at {sample_rate}Hz\")\n",
        "        print(f\"[DEBUG] Audio shape: {audio_data.shape}, max: {np.max(audio_data):.3f}\")\n",
        "\n",
        "        # Store globally for other modules\n",
        "        global_audio_data = audio_data\n",
        "        global_sample_rate = sample_rate\n",
        "\n",
        "        # Use your existing feature extraction function\n",
        "        print(\"\\n[INFO] Extracting features...\")\n",
        "        features = analyze_audio_features(audio_data, sample_rate)\n",
        "\n",
        "        print(\"\\n[RESULT] All Extracted Features:\")\n",
        "        for k, v in sorted(features.items()):\n",
        "            print(f\"  {k:>25}: {format_value(v)}\")\n",
        "\n",
        "        global_features = features\n",
        "\n",
        "        # Use your existing semantic mapping function\n",
        "        print(\"\\n[INFO] Generating semantic mapping...\")\n",
        "        semantic_mapping = process_audio_features(features)\n",
        "\n",
        "        global_semantic_mapping = semantic_mapping\n",
        "\n",
        "        # ADD THIS: Print the semantic mapping summary\n",
        "        print(\"\\n[RESULT] Formatted Summary:\")\n",
        "        try:\n",
        "            summary = print_semantic_mapping(semantic_mapping, features)\n",
        "            print(summary)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Summary formatting failed: {str(e)}\")\n",
        "            if isinstance(semantic_mapping, dict):\n",
        "                for k, v in semantic_mapping.items():\n",
        "                    print(f\"\\n{k}:\")\n",
        "                    if isinstance(v, dict):\n",
        "                        for sk, sv in v.items():\n",
        "                            print(f\"  {sk:>20}: {format_value(sv)}\")\n",
        "\n",
        "        # Get mixing recommendations\n",
        "        print(\"\\n[INFO] Generating recommendations...\")\n",
        "        mixing_recs = analyze_and_recommend_gpt(features)\n",
        "\n",
        "        global_mixing_recs = mixing_recs\n",
        "\n",
        "        print(\"\\n[RESULT] Complete Mixing Recommendations:\")\n",
        "        for i, rec in enumerate(mixing_recs, 1):\n",
        "            print(f\"\\n{i}. {rec['category']} - {rec['subcategory']}\")\n",
        "            print(f\"   Confidence: {rec['confidence']:.2f}\")\n",
        "            print(f\"   Priority: {rec['priority']}\")\n",
        "            print(f\"   Reasoning: {rec['reasoning']}\")\n",
        "            print(\"   Parameters:\")\n",
        "            for param, val in rec['parameters'].items():\n",
        "                print(f\"     {param:>15}: {format_value(val)}\")\n",
        "            print(f\"   Technical: {rec['technical_rationale']}\")\n",
        "\n",
        "        # Get enhanced mixing recommendations\n",
        "        print(\"\\n[INFO] Generating enhanced mixing recommendations...\")\n",
        "        enhanced_mixing = get_enhanced_mixing_recommendations_v2(\n",
        "            features=features,\n",
        "            semantic_mapping=semantic_mapping,\n",
        "            mixing_recs=mixing_recs,\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        global_enhanced_mixing = enhanced_mixing\n",
        "\n",
        "        print(\"\\n[RESULT] Enhanced Mixing Recommendations:\")\n",
        "        print(enhanced_mixing)\n",
        "\n",
        "        # Combine features and semantic analysis\n",
        "        combined_analysis = create_combined_analysis(features, semantic_mapping)\n",
        "\n",
        "        return (combined_analysis,\n",
        "                create_mixing_recommendations(mixing_recs),\n",
        "                create_enhanced_mixing_display(enhanced_mixing))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERROR] Error processing audio: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"Error processing audio: {str(e)}\", None, None\n",
        "\n",
        "def format_value(value):\n",
        "    \"\"\"Format values for display\"\"\"\n",
        "    if isinstance(value, (int, float)):\n",
        "        if isinstance(value, float):\n",
        "            return f\"{value:.3f}\"\n",
        "        return str(value)\n",
        "    elif isinstance(value, np.ndarray):\n",
        "        return f\"Array({value.shape})\"\n",
        "    elif isinstance(value, list):\n",
        "        return f\"List[{len(value)}]\"\n",
        "    else:\n",
        "        return str(value)\n",
        "\n",
        "def safe_function_call(func, *args, **kwargs):\n",
        "    \"\"\"Safely call a function and handle exceptions\"\"\"\n",
        "    try:\n",
        "        return func(*args, **kwargs)\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling {func.__name__}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "#### NEW FUNCTIONS FOR ADDITIONAL MODULES ####\n",
        "\n",
        "def separate_stems_and_midi(audio_file):\n",
        "    \"\"\"Separate stems and generate MIDI files\"\"\"\n",
        "    global global_stems_info, global_midi_outputs\n",
        "\n",
        "    if audio_file is None:\n",
        "        return \"Please upload an audio file first.\"\n",
        "\n",
        "    try:\n",
        "        # Stem separation \n",
        "        os.makedirs(stems_dir, exist_ok=True)\n",
        "\n",
        "        stems_info = safe_function_call(separate_stems3, audio_path=audio_file, output_dir=stems_dir)\n",
        "        if stems_info is None:\n",
        "            return \" Error in stem separation.\"\n",
        "\n",
        "        global_stems_info = stems_info\n",
        "\n",
        "        # Create summary with accurate counts - only count stems that actually exist\n",
        "        actual_stems = {}\n",
        "        for stem_name, stem_info in stems_info.items():\n",
        "            stem_path = stem_info.get(\"path\")\n",
        "            if stem_path and os.path.exists(stem_path):\n",
        "                # Check if the file actually has content (not just an empty file)\n",
        "                try:\n",
        "                    file_size = os.path.getsize(stem_path)\n",
        "                    if file_size > 1024:  # Only count files larger than 1KB\n",
        "                        actual_stems[stem_name] = stem_info\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        # MIDI mapping - only process actual stems and verify MIDI file creation\n",
        "        midi_outputs = {}\n",
        "\n",
        "        os.makedirs(midi_dir, exist_ok=True)\n",
        "\n",
        "        for stem_name, stem_info in actual_stems.items():\n",
        "            stem_path = stem_info.get(\"path\")\n",
        "            stem_type = stem_info.get(\"type\", \"\").lower()\n",
        "\n",
        "            if not stem_path:\n",
        "                continue\n",
        "\n",
        "            output_path = os.path.join(midi_dir, f\"{stem_name}.mid\")\n",
        "\n",
        "            try:\n",
        "                if stem_type == \"drum\":\n",
        "                    result = safe_function_call(convert_drums_to_midi, stem_path, midi_out_path=output_path)\n",
        "                else:\n",
        "                    result = safe_function_call(midi_mapping2, stem_path, output_path=output_path)\n",
        "\n",
        "                # Only count as successful if the function returned a result AND the file actually exists with content\n",
        "                if result is not None and os.path.exists(output_path):\n",
        "                    try:\n",
        "                        file_size = os.path.getsize(output_path)\n",
        "                        if file_size > 100:  # MIDI files should be at least 100 bytes\n",
        "                            midi_outputs[stem_name] = {\"path\": output_path}\n",
        "                        else:\n",
        "                            print(f\"MIDI file {stem_name} created but is too small ({file_size} bytes)\")\n",
        "                    except:\n",
        "                        print(f\"Error checking MIDI file size for {stem_name}\")\n",
        "                else:\n",
        "                    print(f\"MIDI generation failed for {stem_name} - no file created or function returned None\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {stem_name}: {e}\")\n",
        "\n",
        "        global_midi_outputs = midi_outputs\n",
        "\n",
        "        summary = \"## Stems and MIDI Generation Complete\\n\\n\"\n",
        "        summary += f\"**Stems separated:** {len(actual_stems)}\\n\"\n",
        "        summary += f\"**MIDI files generated:** {len(midi_outputs)}\\n\\n\"\n",
        "\n",
        "        summary += \"### Generated Files:\\n\"\n",
        "\n",
        "        # First list only the stems that actually exist\n",
        "        if actual_stems:\n",
        "            for stem_name in actual_stems.keys():\n",
        "                summary += f\"- **{stem_name}** stem\\n\"\n",
        "        else:\n",
        "            summary += \"- No stems were successfully separated\\n\"\n",
        "\n",
        "        # Then list only the MIDI files that were actually created\n",
        "        if midi_outputs:\n",
        "            summary += \"\\n### MIDI Files Created:\\n\"\n",
        "            for stem_name in midi_outputs.keys():\n",
        "                summary += f\"- **{stem_name}** MIDI file\\n\"\n",
        "        else:\n",
        "            summary += \"\\n### MIDI Files Created:\\n\"\n",
        "            summary += \"- No MIDI files were generated\\n\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in separate_stems_and_midi: {str(e)}\")\n",
        "        return f\" Error in stem separation/MIDI generation: {str(e)}\"\n",
        "    \n",
        "\n",
        "def generate_stem_and_midi_previews():\n",
        "    \"\"\"Genera componentes interactivos para reproducir y descargar stems y MIDIs\"\"\"\n",
        "    global global_stems_info, global_midi_outputs\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    if not global_stems_info and not global_midi_outputs:\n",
        "        return gr.Markdown(\" No stems or MIDI files available. Run the stem separation first.\")\n",
        "\n",
        "    # Previews for Stems\n",
        "    if global_stems_info:\n",
        "        outputs.append(gr.Markdown(\"###  Stems Preview & Download\"))\n",
        "        for stem_name, info in global_stems_info.items():\n",
        "            stem_path = info.get(\"path\")\n",
        "            if stem_path and os.path.exists(stem_path):\n",
        "                outputs.append(\n",
        "                    gr.Audio(value=stem_path, label=f\" {stem_name.capitalize()} Stem\", interactive=True, show_download_button=True)\n",
        "                )\n",
        "\n",
        "    # Downloads for MIDI files\n",
        "    if global_midi_outputs:\n",
        "        outputs.append(gr.Markdown(\"###  MIDI Downloads\"))\n",
        "        for midi_name, info in global_midi_outputs.items():\n",
        "            midi_path = info.get(\"path\")\n",
        "            if midi_path and os.path.exists(midi_path):\n",
        "                outputs.append(\n",
        "                    gr.File(value=midi_path, label=f\" {midi_name.capitalize()} MIDI File\")\n",
        "                )\n",
        "\n",
        "    return gr.update(visible=True, value=outputs)\n",
        "\n",
        "\n",
        "\n",
        "def initialize_chatbot():\n",
        "    \"\"\"Initialize the chatbot with current analysis data\"\"\"\n",
        "    global global_chatbot_instance\n",
        "\n",
        "    if not global_features:\n",
        "        return \"Please analyze an audio file first.\"\n",
        "\n",
        "    try:\n",
        "        global_chatbot_instance = safe_function_call(\n",
        "            initialize_mixing_chatbot_v2,\n",
        "            api_key=api_key,\n",
        "            features=global_features,\n",
        "            semantic_mapping=global_semantic_mapping,\n",
        "            mixing_recs=global_mixing_recs,\n",
        "            enhanced_plan=global_enhanced_mixing\n",
        "        )\n",
        "\n",
        "        if global_chatbot_instance is None:\n",
        "            return \" Error initializing chatbot.\"\n",
        "\n",
        "        return \" Chatbot initialized! You can now ask questions about your mix.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error in initialize_chatbot: {str(e)}\")\n",
        "        return f\" Error initializing chatbot: {str(e)}\"\n",
        "\n",
        "def chat_with_bot(message, history):\n",
        "    \"\"\"Handle chatbot conversations\"\"\"\n",
        "    global global_chatbot_instance\n",
        "\n",
        "    if not global_chatbot_instance:\n",
        "        return history + [[\"Please initialize the chatbot first by clicking 'Initialize Chatbot'.\", \"\"]]\n",
        "\n",
        "    if not message.strip():\n",
        "        return history\n",
        "\n",
        "    try:\n",
        "        response = safe_function_call(chat_mixing_followup_v2, global_chatbot_instance, message)\n",
        "        if response is None:\n",
        "            response = \"Sorry, I encountered an error processing your request.\"\n",
        "\n",
        "        history.append([message, response])\n",
        "        return history\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_with_bot: {str(e)}\")\n",
        "        history.append([message, f\"Error: {str(e)}\"])\n",
        "        return history\n",
        "\n",
        "\n",
        "def generate_music_prompt(user_request, genres=\"\"):\n",
        "    \"\"\"Generate optimized prompt for MusicGen\"\"\"\n",
        "    if not global_semantic_mapping:\n",
        "        return \"Please analyze an audio file first to generate context-aware prompts.\"\n",
        "\n",
        "    try:\n",
        "        prompt = safe_function_call(\n",
        "            prompt_gpt_optimized,\n",
        "            global_semantic_mapping,\n",
        "            user_request,\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        if prompt is None:\n",
        "            return \" Error generating prompt.\"\n",
        "\n",
        "        return f\"## Generated MusicGen Prompt:\\n\\n{prompt}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generate_music_prompt: {str(e)}\")\n",
        "        return f\" Error generating prompt: {str(e)}\"\n",
        "\n",
        "def generate_audio_from_prompt(prompt_text):\n",
        "    \"\"\"Generate audio using MusicGen\"\"\"\n",
        "    if global_audio_data is None or len(global_audio_data) == 0:\n",
        "        return None, \" Please analyze an audio file first.\"\n",
        "\n",
        "    if not prompt_text or not prompt_text.strip():\n",
        "        return None, \" Please provide a prompt first.\"\n",
        "\n",
        "    try:\n",
        "        # Clean the prompt text\n",
        "        clean_prompt = prompt_text.replace(\"## Generated MusicGen Prompt:\\n\\n\", \"\").strip()\n",
        "\n",
        "        if not clean_prompt:\n",
        "            return None, \" Prompt is empty after cleaning.\"\n",
        "\n",
        "        print(f\" Generating audio with prompt: {clean_prompt[:100]}...\")\n",
        "\n",
        "        # Call your existing generar_audio function with correct parameter names\n",
        "        result = safe_function_call(\n",
        "            generar_audio,\n",
        "            audio_np=global_audio_data,\n",
        "            prompt=clean_prompt,\n",
        "            sr=global_sample_rate,\n",
        "            model_name=\"musicgen-small\"   # Change to musicgen-melody if wanted (really time consuming model)\n",
        "        )\n",
        "\n",
        "        if result is None:\n",
        "            return None, \" Error generating audio. Check console for details.\"\n",
        "\n",
        "        sr_gen, generated_audio = result\n",
        "\n",
        "        # Validate output\n",
        "        if generated_audio is None or len(generated_audio) == 0:\n",
        "            return None, \" Generated audio is empty.\"\n",
        "\n",
        "        # Convert to proper format for Gradio\n",
        "        # Ensure audio is numpy array\n",
        "        if not isinstance(generated_audio, np.ndarray):\n",
        "            generated_audio = np.array(generated_audio)\n",
        "\n",
        "        # Ensure audio is in the correct format (float32)\n",
        "        if generated_audio.dtype != np.float32:\n",
        "            if generated_audio.dtype == np.int16:\n",
        "                generated_audio = generated_audio.astype(np.float32) / 32768.0\n",
        "            elif generated_audio.dtype == np.int32:\n",
        "                generated_audio = generated_audio.astype(np.float32) / 2147483648.0\n",
        "            else:\n",
        "                generated_audio = generated_audio.astype(np.float32)\n",
        "\n",
        "        # Ensure audio is in valid range [-1, 1]\n",
        "        max_val = np.max(np.abs(generated_audio))\n",
        "        if max_val > 1.0:\n",
        "            generated_audio = generated_audio / max_val\n",
        "\n",
        "        # Handle multi-dimensional arrays - convert to mono if needed\n",
        "        if generated_audio.ndim > 1:\n",
        "            if generated_audio.shape[0] < generated_audio.shape[1]:\n",
        "                # If first dimension is smaller, it's likely channels x samples\n",
        "                generated_audio = generated_audio[0]  # Take first channel\n",
        "            else:\n",
        "                # If second dimension is smaller, it's likely samples x channels\n",
        "                generated_audio = generated_audio[:, 0]  # Take first channel\n",
        "\n",
        "        # Ensure it's 1D\n",
        "        generated_audio = np.squeeze(generated_audio)\n",
        "\n",
        "        print(f\" Audio generation completed successfully!\")\n",
        "        print(f\"Generated audio shape: {generated_audio.shape}, dtype: {generated_audio.dtype}\")\n",
        "        print(f\"Sample rate: {sr_gen}, Audio range: [{np.min(generated_audio):.3f}, {np.max(generated_audio):.3f}]\")\n",
        "\n",
        "\n",
        "        # Guardar archivo generado\n",
        "        output_dir = os.path.join(\"notebooks\", \"output_audio\") if not os.path.exists(\"/content\") else \"/content/output_audio\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        output_path = os.path.join(output_dir, \"generated_sample.wav\")\n",
        "\n",
        "        torchaudio.save(output_path, torch.tensor(generated_audio).unsqueeze(0), sr_gen)\n",
        "        print(f\"Audio saved to {output_path}\")\n",
        "\n",
        "\n",
        "        # Return as tuple (sample_rate, audio_data) - this is the correct format for Gradio\n",
        "        return (int(sr_gen), generated_audio), \" Audio generated successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\" Error generating audio: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, error_msg\n",
        "\n",
        "\n",
        "#### COMBINED ANALYSIS MODULE ####\n",
        "\n",
        "def create_combined_analysis(features, semantic_mapping):\n",
        "    \"\"\"Combine feature extraction and semantic mapping in one display\"\"\"\n",
        "\n",
        "    # Start with audio features\n",
        "    display_text = \" **AUDIO ANALYSIS RESULTS**\\n\\n\"\n",
        "    display_text += \"###  Key Features:\\n\"\n",
        "\n",
        "    # Most important features for producers\n",
        "    key_features = [\n",
        "        ('tempo', 'Tempo', 'BPM'),\n",
        "        ('key', 'Key', ''),\n",
        "        ('loudness_db', 'Loudness', 'dB'),\n",
        "        ('spectral_centroid', 'Brightness', 'Hz'),\n",
        "        ('dynamic_range', 'Dynamic Range', 'dB'),\n",
        "        ('harmonic_ratio', 'Harmonics', '%'),\n",
        "        ('percussive_ratio', 'Percussion', '%'),\n",
        "        ('rms_energy', 'RMS Energy', ''),\n",
        "        ('peak_level', 'Peak Level', ''),\n",
        "    ]\n",
        "\n",
        "    for feature_key, label, unit in key_features:\n",
        "        if feature_key in features:\n",
        "            value = features[feature_key]\n",
        "            if isinstance(value, (int, float)):\n",
        "                if abs(value) >= 0.01:\n",
        "                    formatted_value = f\"{float(value):.2f}\"\n",
        "                else:\n",
        "                    formatted_value = f\"{float(value):.4f}\"\n",
        "            else:\n",
        "                formatted_value = str(value)\n",
        "\n",
        "            display_text += f\" **{label}**: {formatted_value} {unit}\\n\"\n",
        "\n",
        "    display_text += \"\\n\" + \"\" * 60 + \"\\n\\n\"\n",
        "\n",
        "    # Add semantic interpretations\n",
        "    display_text += \"###  Musical Character:\\n\"\n",
        "\n",
        "    # Core interpretations\n",
        "    if 'semantic_interpretations' in semantic_mapping:\n",
        "        interpretations = semantic_mapping['semantic_interpretations']\n",
        "\n",
        "        key_interpretations = [\n",
        "            ('tempo', ' **Tempo Feel**'),\n",
        "            ('spectral_centroid', ' **Brightness**'),\n",
        "            ('loudness_db', ' **Loudness**'),\n",
        "            ('dynamic_range', ' **Dynamics**'),\n",
        "            ('harmonic_ratio', ' **Harmonics**'),\n",
        "            ('key_confidence', ' **Key Stability**'),\n",
        "        ]\n",
        "\n",
        "        interp_line = \"\"\n",
        "        for feature_key, label in key_interpretations:\n",
        "            if feature_key in interpretations:\n",
        "                interp = interpretations[feature_key]\n",
        "                intensity = interp.get('intensity', 'unknown')\n",
        "                semantic_level = interp.get('semantic_level', 'neutral')\n",
        "                interp_line += f\"{label}: {intensity} ({semantic_level}) \"\n",
        "\n",
        "        display_text += f\"{interp_line}\\n\\n\"\n",
        "\n",
        "    # Production context\n",
        "    if 'contextual_analysis' in semantic_mapping:\n",
        "        context = semantic_mapping['contextual_analysis']\n",
        "        display_text += \"###  Production Context:\\n\"\n",
        "        context_line = f\" **Quality**: {context.get('production_quality', 'unknown')} \"\n",
        "        context_line += f\" **Complexity**: {context.get('musical_complexity', 'unknown')} \"\n",
        "        context_line += f\" **Context**: {context.get('listening_context', 'unknown')} \"\n",
        "        context_line += f\" **Mood**: {context.get('emotional_impact', 'unknown')}\"\n",
        "        display_text += f\"{context_line}\\n\\n\"\n",
        "\n",
        "    # Frequency analysis\n",
        "    if 'frequency_characteristics' in semantic_mapping:\n",
        "        freq_chars = semantic_mapping['frequency_characteristics']\n",
        "        display_text += \"###  Frequency Profile:\\n\"\n",
        "        freq_line = f\" **Balance**: {freq_chars.get('balance', 'unknown')} \"\n",
        "        freq_line += f\" **Profile**: {freq_chars.get('profile', 'unknown')} \"\n",
        "        freq_line += f\" **Dominance**: {freq_chars.get('dominance', 'unknown')}\"\n",
        "        display_text += f\"{freq_line}\\n\\n\"\n",
        "\n",
        "    # Mix coherence\n",
        "    if 'feature_relationships' in semantic_mapping:\n",
        "        relationships = semantic_mapping['feature_relationships']\n",
        "        display_text += \"###  Mix Coherence:\\n\"\n",
        "        coherence_line = f\" **Tempo-Energy**: {relationships.get('tempo_energy_coherence', 'unknown')} \"\n",
        "        coherence_line += f\" **Frequency**: {relationships.get('frequency_coherence', 'unknown')} \"\n",
        "        coherence_line += f\" **Harmonic-Percussive**: {relationships.get('harmonic_percussive_balance', 'unknown')}\"\n",
        "        display_text += f\"{coherence_line}\\n\\n\"\n",
        "\n",
        "    # Production metrics\n",
        "    if 'energy_characteristics' in semantic_mapping and 'complexity_characteristics' in semantic_mapping:\n",
        "        energy = semantic_mapping['energy_characteristics']\n",
        "        complexity = semantic_mapping['complexity_characteristics']\n",
        "        display_text += \"###  Production Metrics:\\n\"\n",
        "        metrics_line = f\" **Energy Score**: {energy.get('energy_score', 0):.2f} \"\n",
        "        metrics_line += f\" **Complexity Score**: {complexity.get('complexity_score', 0):.2f} \"\n",
        "        metrics_line += f\" **Energy Confidence**: {energy.get('confidence', 0):.2f}\"\n",
        "        display_text += f\"{metrics_line}\\n\\n\"\n",
        "\n",
        "    # Stereo imaging\n",
        "    if 'spatial_characteristics' in semantic_mapping:\n",
        "        spatial = semantic_mapping['spatial_characteristics']\n",
        "        display_text += \"###  Stereo Image:\\n\"\n",
        "        spatial_line = f\" **Width**: {spatial.get('width_character', 'unknown')} \"\n",
        "        spatial_line += f\" **Phase**: {spatial.get('phase_character', 'unknown')} \"\n",
        "        spatial_line += f\" **Impression**: {spatial.get('spatial_impression', 'unknown')}\"\n",
        "        display_text += f\"{spatial_line}\\n\\n\"\n",
        "\n",
        "    # Rhythm & timing\n",
        "    if 'normalized_features' in semantic_mapping and isinstance(semantic_mapping['normalized_features'], dict):\n",
        "        norm_features = semantic_mapping['normalized_features']\n",
        "        display_text += \"###  Rhythm & Timing:\\n\"\n",
        "        rhythm_parts = []\n",
        "\n",
        "        if 'rhythmic_regularity' in norm_features:\n",
        "            reg_val = norm_features['rhythmic_regularity'].get('intensity', 'unknown')\n",
        "            rhythm_parts.append(f\"**Regularity**: {reg_val}\")\n",
        "\n",
        "        if 'onset_rate' in norm_features:\n",
        "            onset_val = norm_features['onset_rate'].get('intensity', 'unknown')\n",
        "            rhythm_parts.append(f\"**Onset Rate**: {onset_val}\")\n",
        "\n",
        "        if 'punch_factor' in norm_features:\n",
        "            punch_val = norm_features['punch_factor'].get('intensity', 'unknown')\n",
        "            punch_level = norm_features['punch_factor'].get('semantic_level', 'neutral')\n",
        "            rhythm_parts.append(f\"**Punch**: {punch_val} ({punch_level})\")\n",
        "\n",
        "        if rhythm_parts:\n",
        "            display_text += f\" {'  '.join(rhythm_parts)}\"\n",
        "\n",
        "    return display_text\n",
        "\n",
        "def create_mixing_recommendations(mixing_recs):\n",
        "    \"\"\"Format mixing recommendations for display\"\"\"\n",
        "    if not mixing_recs:\n",
        "        return \"No mixing recommendations available.\"\n",
        "\n",
        "    display_text = \"###  Core Mixing Recommendations\\n\\n\"\n",
        "\n",
        "    # Sort by priority and confidence\n",
        "    priority_recs = sorted(mixing_recs, key=lambda x: (x.get('priority', 999), -x.get('confidence', 0)))\n",
        "\n",
        "    for i, rec in enumerate(priority_recs[:6], 1):  # Show top 6 recommendations\n",
        "        display_text += f\"### {i}. {rec.get('category', 'Unknown')} - {rec.get('subcategory', 'Unknown')}\\n\"\n",
        "        display_text += f\"**Confidence:** {rec.get('confidence', 0):.2f} | **Priority:** {rec.get('priority', 'Unknown')}\\n\\n\"\n",
        "        display_text += f\"**Reasoning:** {rec.get('reasoning', 'Not provided')}\\n\\n\"\n",
        "\n",
        "        if 'parameters' in rec and rec['parameters']:\n",
        "            display_text += \"**Parameters:**\\n\"\n",
        "            for param, val in rec['parameters'].items():\n",
        "                if isinstance(val, dict):\n",
        "                    display_text += f\"- **{param}:**\\n\"\n",
        "                    for k, v in val.items():\n",
        "                        display_text += f\"  - {k}: {v}\\n\"\n",
        "                else:\n",
        "                    display_text += f\"- **{param}:** {val}\\n\"\n",
        "            display_text += \"\\n\"\n",
        "\n",
        "        if rec.get('technical_rationale'):\n",
        "            display_text += f\"**Technical:** {rec.get('technical_rationale')}\\n\\n\"\n",
        "\n",
        "        display_text += \"---\\n\\n\"\n",
        "\n",
        "    return display_text\n",
        "\n",
        "#### ENHANCED MIXING DISPLAY FUNCTION ####\n",
        "\n",
        "def create_enhanced_mixing_display(enhanced_mixing):\n",
        "    \"\"\"Display AI enhanced mixing recommendations in a clean, readable format\"\"\"\n",
        "    if not enhanced_mixing:\n",
        "        return \"No enhanced mixing recommendations available.\"\n",
        "\n",
        "    # Handle different input types - extract the actual text content\n",
        "    if isinstance(enhanced_mixing, tuple):\n",
        "        enhanced_text = str(enhanced_mixing[0]) if enhanced_mixing else \"\"\n",
        "    elif isinstance(enhanced_mixing, dict):\n",
        "        enhanced_text = enhanced_mixing.get('content', str(enhanced_mixing))\n",
        "    else:\n",
        "        enhanced_text = str(enhanced_mixing)\n",
        "\n",
        "    # Remove any leading/trailing quotes or parentheses\n",
        "    enhanced_text = enhanced_text.strip(\"'\\\"()\")\n",
        "\n",
        "    display_text = \"###  AI Enhanced Mixing Strategy\\n\\n\"\n",
        "\n",
        "    # Find and extract each section\n",
        "    lines = enhanced_text.split('\\n')\n",
        "    current_section = None\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        # Skip empty lines, separators, and log messages\n",
        "        if not line or line.startswith('=') or line.startswith('['):\n",
        "            continue\n",
        "\n",
        "        # Check for section headers\n",
        "        if 'EXPANDED PRIORITY 1 RECOMMENDATIONS:' in line:\n",
        "            display_text += \"####  Priority Recommendations\\n\\n\"\n",
        "            current_section = 'priority'\n",
        "            continue\n",
        "        elif 'IDENTIFIED GAPS' in line:\n",
        "            display_text += \"####  Identified Gaps\\n\\n\"\n",
        "            current_section = 'gaps'\n",
        "            continue\n",
        "        elif 'CREATIVE PROCESSING' in line or 'CREATIVE ADDITIONS' in line:\n",
        "            display_text += \"####  Creative Processing\\n\\n\"\n",
        "            current_section = 'creative'\n",
        "            continue\n",
        "        elif 'PROCESSING ORDER:' in line:\n",
        "            display_text += \"####  Processing Order\\n\\n\"\n",
        "            current_section = 'order'\n",
        "            continue\n",
        "\n",
        "        # Process content based on format\n",
        "        if line.startswith('**') and line.endswith('**'):\n",
        "            # Effect headers\n",
        "            effect_name = line.strip('*')\n",
        "            display_text += f\"**{effect_name}**\\n\"\n",
        "\n",
        "        elif current_section == 'order' and line and line[0].isdigit() and '. ' in line:\n",
        "            # Processing order items - we'll collect these first\n",
        "            pass  # Handle separately below\n",
        "\n",
        "        elif current_section in ['priority', 'gaps', 'creative'] and line and not line.startswith('**'):\n",
        "            # Effect descriptions\n",
        "            display_text += f\"{line}\\n\\n\"\n",
        "\n",
        "    # Handle processing order separately with grouping\n",
        "    if 'PROCESSING ORDER:' in enhanced_text:\n",
        "        order_section = enhanced_text.split('PROCESSING ORDER:')[1] if 'PROCESSING ORDER:' in enhanced_text else \"\"\n",
        "        order_lines = [line.strip() for line in order_section.split('\\n') if line.strip() and line.strip()[0].isdigit()]\n",
        "\n",
        "        # Group processing steps\n",
        "        eq_steps = []\n",
        "        dynamics_steps = []\n",
        "        effects_steps = []\n",
        "        spatial_steps = []\n",
        "\n",
        "        for line in order_lines:\n",
        "            if '. ' in line:\n",
        "                step = line.split('. ', 1)[1]\n",
        "                if 'EQ' in step:\n",
        "                    eq_steps.append(step)\n",
        "                elif 'Dynamics' in step or 'Compression' in step:\n",
        "                    dynamics_steps.append(step)\n",
        "                elif 'Reverb' in step or 'Delay' in step or 'Saturation' in step or 'Modulation' in step:\n",
        "                    effects_steps.append(step)\n",
        "                elif 'Stereo' in step or 'Panning' in step or 'Spatial' in step:\n",
        "                    spatial_steps.append(step)\n",
        "\n",
        "        # Add grouped sections\n",
        "        if eq_steps:\n",
        "            display_text += \"**EQ Processing**\\n\"\n",
        "            for i, step in enumerate(eq_steps, 1):\n",
        "                display_text += f\"{i}. {step}\\n\"\n",
        "            display_text += \"\\n\"\n",
        "\n",
        "        if dynamics_steps:\n",
        "            display_text += \"**Dynamics Processing**\\n\"\n",
        "            for i, step in enumerate(dynamics_steps, 1):\n",
        "                display_text += f\"{i}. {step}\\n\"\n",
        "            display_text += \"\\n\"\n",
        "\n",
        "        if effects_steps:\n",
        "            display_text += \"**Effects Processing**\\n\"\n",
        "            for i, step in enumerate(effects_steps, 1):\n",
        "                display_text += f\"{i}. {step}\\n\"\n",
        "            display_text += \"\\n\"\n",
        "\n",
        "        if spatial_steps:\n",
        "            display_text += \"**Spatial Processing**\\n\"\n",
        "            for i, step in enumerate(spatial_steps, 1):\n",
        "                display_text += f\"{i}. {step}\\n\"\n",
        "\n",
        "    return display_text\n",
        "\n",
        "# Create Enhanced Gradio interface with all modules\n",
        "with gr.Blocks(title=\"Audio Analysis & Music Generation Studio\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"#  GROOVE GURU\")\n",
        "    gr.Markdown(\"### *(An Audio Analysis, Music Mixing and Production Assistant Tool)*\")\n",
        "    gr.Markdown(\"Upload an audio file to analyze its features, get mixing recommendations, and generate new music!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            audio_input = gr.Audio(\n",
        "                label=\"Upload Audio File\",\n",
        "                type=\"filepath\",\n",
        "                sources=[\"upload\"]\n",
        "            )\n",
        "            analyze_btn = gr.Button(\" Analyze Audio\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "    # Analysis Results Section\n",
        "    # Analysis Results Section - Separate horizontal accordion windows\n",
        "    # Analysis Results Section - Vertical Tabs\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\" Audio Features & Semantic Analysis\"):\n",
        "            combined_output = gr.Markdown()\n",
        "\n",
        "        with gr.TabItem(\" Basic Mixing Recommendations\"):\n",
        "            mixing_output = gr.Markdown()\n",
        "\n",
        "        with gr.TabItem(\" AI Enhanced Mixing Strategy\"):\n",
        "            enhanced_output = gr.Markdown()\n",
        "\n",
        "\n",
        "    # Chatbot Section\n",
        "    gr.Markdown(\"##  Mixing Assistant Chatbot\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot_interface = gr.Chatbot(\n",
        "                label=\"Chat with Mixing Assistant\",\n",
        "                height=400,\n",
        "                placeholder=\"Initialize the chatbot to start asking questions about your mix...\"\n",
        "            )\n",
        "            with gr.Row():\n",
        "                chat_input = gr.Textbox(\n",
        "                    label=\"Your Question\",\n",
        "                    placeholder=\"Ask about EQ, compression, effects, etc...\",\n",
        "                    scale=4\n",
        "                )\n",
        "                chat_submit = gr.Button(\"Send\", scale=1)\n",
        "        with gr.Column(scale=1):\n",
        "            init_chatbot_btn = gr.Button(\" Initialize Chatbot\", variant=\"secondary\")\n",
        "            chatbot_status = gr.Textbox(\n",
        "                label=\"Chatbot Status\",\n",
        "                value=\"Not initialized\",\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # Additional Modules Section\n",
        "    gr.Markdown(\"##  Additional Features\")\n",
        "\n",
        "    with gr.TabItem(\" Stem Separation & MIDI Generation\"):\n",
        "      with gr.Column():\n",
        "        stems_btn = gr.Button(\" Separate Stems & Generate MIDI\", variant=\"secondary\", size=\"lg\")\n",
        "        stems_status = gr.Markdown(\"Click the button above to separate stems and generate MIDI files.\")\n",
        "        stems_preview_display = gr.Column(visible=True)  \n",
        "\n",
        "\n",
        "        with gr.TabItem(\" Music Generation with MusicGen\"):\n",
        "            with gr.Column():\n",
        "                # Input section\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        music_request = gr.Textbox(\n",
        "                            label=\"Describe the music you want to generate\",\n",
        "                            placeholder=\"e.g., 'Create a chill house track with deep bass'\",\n",
        "                            lines=3\n",
        "                        )\n",
        "                        genre_input = gr.Textbox(\n",
        "                            label=\"Additional Genres/Styles (optional)\",\n",
        "                            placeholder=\"e.g., house, deepsoul, chill, ambient\"\n",
        "                        )\n",
        "                        generate_prompt_btn = gr.Button(\" Generate Prompt\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        generated_prompt = gr.Markdown(\n",
        "                            label=\"Generated Prompt\",\n",
        "                            value=\"Generated prompt will appear here...\"\n",
        "                        )\n",
        "\n",
        "                # Generation section\n",
        "                with gr.Row():\n",
        "                    generate_audio_btn = gr.Button(\" Generate Audio\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            # Audio output section - separate row for bigger display\n",
        "                with gr.Row():\n",
        "                    generated_audio = gr.Audio(\n",
        "                        label=\"Generated Audio\",\n",
        "                        interactive=True,\n",
        "                        show_download_button=True,\n",
        "                        show_share_button=False\n",
        "                    )\n",
        "\n",
        "                # Status section - separate row for better visibility\n",
        "                with gr.Row():\n",
        "                    generation_status = gr.Textbox(\n",
        "                        label=\"Generation Status\",\n",
        "                        interactive=False,\n",
        "                        show_label=True,\n",
        "                        container=True\n",
        "                    )\n",
        "\n",
        "    # Event handlers\n",
        "    analyze_btn.click(\n",
        "        fn=extract_key_features,\n",
        "        inputs=audio_input,\n",
        "        outputs=[combined_output, mixing_output, enhanced_output],\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    stems_btn.click(\n",
        "        separate_stems_and_midi,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[stems_status]\n",
        "    ).then(\n",
        "        generate_stem_and_midi_previews,\n",
        "        inputs=[],\n",
        "        outputs=[stems_preview_display]\n",
        "    )\n",
        "\n",
        "    init_chatbot_btn.click(\n",
        "        initialize_chatbot,\n",
        "        inputs=[],\n",
        "        outputs=[chatbot_status]\n",
        "    )\n",
        "\n",
        "    chat_submit.click(\n",
        "        chat_with_bot,\n",
        "        inputs=[chat_input, chatbot_interface],\n",
        "        outputs=[chatbot_interface]\n",
        "    ).then(\n",
        "        lambda: \"\",\n",
        "        outputs=[chat_input]\n",
        "    )\n",
        "\n",
        "    chat_input.submit(\n",
        "        chat_with_bot,\n",
        "        inputs=[chat_input, chatbot_interface],\n",
        "        outputs=[chatbot_interface]\n",
        "    ).then(\n",
        "        lambda: \"\",\n",
        "        outputs=[chat_input]\n",
        "    )\n",
        "\n",
        "    generate_prompt_btn.click(\n",
        "        generate_music_prompt,\n",
        "        inputs=[music_request, genre_input],\n",
        "        outputs=[generated_prompt]\n",
        "    )\n",
        "\n",
        "    generate_audio_btn.click(\n",
        "        generate_audio_from_prompt,\n",
        "        inputs=[generated_prompt],\n",
        "        outputs=[generated_audio, generation_status]\n",
        "    )\n",
        "\n",
        "''' # Uncomment to launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        show_error=True\n",
        "    )\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8La1FsoW-GVM"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Main\n",
        "import librosa\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Carga el .env\n",
        "\n",
        "#  IMPORTANT: Requires you to set the environment variable OPENAI_API_KEY\n",
        "#               And place an audio file at 'assets/demo_audio.wav'\n",
        "# Note: The output is long, click scrollable output to see the full output (if using Jupyter Notebook)\n",
        "\n",
        "# Decorators and utility functions\n",
        "def timed_section(name):\n",
        "    \"\"\"Decorator to time a function section\"\"\"\n",
        "    def decorator(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.time()\n",
        "            print(f\"\\n[TIMING] Starting {name}...\")\n",
        "            result = func(*args, **kwargs)\n",
        "            duration = time.time() - start\n",
        "            print(f\"[TIMING] {name} completed in {duration:.2f} seconds\")\n",
        "            return result, duration\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "def format_value(value):\n",
        "    \"\"\"Safe formatting for all value types\"\"\"\n",
        "    if isinstance(value, (int, float)):\n",
        "        return f\"{float(value):.2f}\" if abs(value) >= 0.01 else f\"{float(value):.4f}\"\n",
        "    elif isinstance(value, (list, np.ndarray)):\n",
        "        return f\"[{', '.join(format_value(x) for x in value[:3])}{'...' if len(value) > 3 else ''}]\"\n",
        "    return str(value)\n",
        "\n",
        "def print_separator(title):\n",
        "    \"\"\"Print a clear section separator\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  {title}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")  # Set your OpenAI GPT API key\n",
        "\n",
        "    # Track timing for all sections\n",
        "    timings = {}\n",
        "\n",
        "       # Detectar si estamos en Colab o local\n",
        "    try:\n",
        "        IS_COLAB = \"google.colab\" in str(get_ipython())\n",
        "    except NameError:\n",
        "        IS_COLAB = False\n",
        "\n",
        "    # Ajuste de BASE_DIR\n",
        "    if IS_COLAB:\n",
        "        BASE_DIR = \"/content\"\n",
        "    else:\n",
        "        # Subir un nivel desde notebooks/\n",
        "        BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "\n",
        "    STEMS_DIR = os.path.join(BASE_DIR, \"outputs\", \"stems\")\n",
        "    MIDI_DIR = os.path.join(BASE_DIR, \"outputs\", \"midi_out\")\n",
        "    AUDIO_GEN_DIR = os.path.join(BASE_DIR, \"outputs\", \"generated_audio\")\n",
        "\n",
        "    # Example audio file, change to use your desired auido file\n",
        "    audio_path = os.path.join(BASE_DIR, \"assets\", \"demo_audio.wav\")\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"[ERROR]  No API key found. Please set OPENAI_API_KEY in your environment or manually.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"[ERROR]  Audio path not found: {audio_path}\")\n",
        "        return\n",
        "\n",
        "    # === 1. Load Audio ===\n",
        "    @timed_section(\"Audio Loading\")\n",
        "    def load_audio(audio_path):\n",
        "        print(f\"\\n[INFO] Loading audio: {audio_path}\")\n",
        "\n",
        "        audio_data, sample_rate = librosa.load(\n",
        "            audio_path,\n",
        "            sr=22050,\n",
        "            mono=True,\n",
        "            duration=30\n",
        "        )\n",
        "        duration = len(audio_data)/sample_rate\n",
        "        print(f\"[INFO] Loaded {duration:.1f}s at {sample_rate}Hz\")\n",
        "        print(f\"[DEBUG] Audio shape: {audio_data.shape}, max: {np.max(audio_data):.3f}\")\n",
        "        return audio_data, sample_rate\n",
        "\n",
        "    (audio_data, sample_rate), load_time = load_audio(audio_path)\n",
        "    timings['audio_loading'] = load_time\n",
        "\n",
        "    # === 2a. Separar Stems ===\n",
        "    @timed_section(\"Separacin de Stems\")\n",
        "    def run_stem_separation(audio_path):\n",
        "        stems_dir = STEMS_DIR\n",
        "        stems_info = separate_stems3(audio_path=audio_path, output_dir=stems_dir)\n",
        "        return stems_info\n",
        "\n",
        "    stems_info, stem_time = run_stem_separation(audio_path)\n",
        "    timings['stem_separation'] = stem_time\n",
        "\n",
        "    print_separator(\"STEM SEPARATION RESULTS\")\n",
        "    print(f\"[INFO] Guardando stems en: {STEMS_DIR}\")\n",
        "    \n",
        "    if stems_info:\n",
        "        print(\"\\n[RESULT] Stems separados:\")\n",
        "        for stem_name, stem_info in stems_info.items():\n",
        "            stem_path = stem_info.get(\"path\", \"No path\")\n",
        "            stem_type = stem_info.get(\"type\", \"Unknown\")\n",
        "            print(f\"  {stem_name:>15}: {stem_type} -> {stem_path}\")\n",
        "    else:\n",
        "        print(\"[WARNING] No se encontraron stems separados\")\n",
        "\n",
        "    # === 2b. Mapeo MIDI de Todos los Stems ===\n",
        "    @timed_section(\"Mapeo MIDI de Stems\")\n",
        "    def run_midi_mapping():\n",
        "      midi_outputs = {}\n",
        "      midi_dir = MIDI_DIR\n",
        "      os.makedirs(midi_dir, exist_ok=True)\n",
        "\n",
        "      for stem_name, stem_info in stems_info.items():\n",
        "        stem_path = stem_info.get(\"path\")\n",
        "        stem_type = stem_info.get(\"type\", \"\").lower()  #  importante\n",
        "\n",
        "        if not stem_path:\n",
        "            print(f\" {stem_name}: sin archivo de audio, se omite.\")\n",
        "            continue\n",
        "        output_path = os.path.join(midi_dir, f\"{stem_name}.mid\")\n",
        "\n",
        "        try:\n",
        "            if stem_type == \"drum\":\n",
        "                # Usar funcin especfica para drums\n",
        "                convert_drums_to_midi(stem_path, midi_out_path=output_path)\n",
        "                midi_data = None\n",
        "            else:\n",
        "                # Usar modelo melodic\n",
        "                midi_data = midi_mapping2(stem_path, output_path=output_path)\n",
        "\n",
        "            midi_outputs[stem_name] = {\n",
        "                \"path\": output_path,\n",
        "                \"data\": midi_data\n",
        "            }\n",
        "\n",
        "            print(f\" MIDI generado para: {stem_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error al mapear MIDI para {stem_name}: {e}\")\n",
        "\n",
        "      return midi_outputs\n",
        "\n",
        "    midi_outputs, midi_time = run_midi_mapping()\n",
        "    timings['midi_mapping'] = midi_time\n",
        "    \n",
        "    print_separator(\"MIDI MAPPING RESULTS\")\n",
        "    print(f\"[INFO] Guardando MIDIs en: {MIDI_DIR}\")\n",
        "    \n",
        "    if midi_outputs:\n",
        "        print(\"\\n[RESULT] Archivos MIDI generados:\")\n",
        "        for stem_name, midi_info in midi_outputs.items():\n",
        "            midi_path = midi_info.get(\"path\", \"No path\")\n",
        "            has_data = \"Yes\" if midi_info.get(\"data\") else \"No\"\n",
        "            print(f\"  {stem_name:>15}: {midi_path} (Data: {has_data})\")\n",
        "    else:\n",
        "        print(\"[WARNING] No se generaron archivos MIDI\")\n",
        "\n",
        "    # === 3. Feature Extraction ===\n",
        "    @timed_section(\"Feature Extraction\")\n",
        "    def extract_features(audio_data, sample_rate):\n",
        "        print(\"\\n[INFO] Extracting features...\")\n",
        "        features = analyze_audio_features(audio_data, sample_rate)\n",
        "\n",
        "        print(\"\\n[RESULT] All Extracted Features:\")\n",
        "        for k, v in sorted(features.items()):\n",
        "            print(f\"  {k:>25}: {format_value(v)}\")\n",
        "\n",
        "        return features\n",
        "\n",
        "    features, feat_time = extract_features(audio_data, sample_rate)\n",
        "    timings['feature_extraction'] = feat_time\n",
        "\n",
        "    # === 4. Semantic Mapping ===\n",
        "    @timed_section(\"Semantic Mapping\")\n",
        "    def get_semantic_mapping(features):\n",
        "        print(\"\\n[INFO] Generating semantic mapping...\")\n",
        "        mapping = process_audio_features(features)\n",
        "\n",
        "        print_separator(\"SEMANTIC MAPPING RESULTS\")\n",
        "        try:\n",
        "            summary = print_semantic_mapping(mapping, features)\n",
        "            print(summary)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Summary formatting failed: {str(e)}\")\n",
        "            if isinstance(mapping, dict):\n",
        "                for k, v in mapping.items():\n",
        "                    print(f\"\\n{k}:\")\n",
        "                    if isinstance(v, dict):\n",
        "                        for sk, sv in v.items():\n",
        "                            print(f\"  {sk:>20}: {format_value(sv)}\")\n",
        "\n",
        "        return mapping\n",
        "\n",
        "    semantic_mapping, sem_time = get_semantic_mapping(features)\n",
        "    timings['semantic_mapping'] = sem_time\n",
        "\n",
        "     # === 5. Mixing Recommendations ===\n",
        "    @timed_section(\"Mixing Recommendations\")\n",
        "    def get_mixing_recommendations(features):\n",
        "        print(\"\\n[INFO] Generating recommendations...\")\n",
        "        recs = analyze_and_recommend_gpt(features)\n",
        "\n",
        "        print_separator(\"MIXING RECOMMENDATIONS\")\n",
        "        for i, rec in enumerate(recs, 1):\n",
        "            print(f\"\\n{i}. {rec['category']} - {rec['subcategory']}\")\n",
        "            print(f\"   Confidence: {rec['confidence']:.2f}\")\n",
        "            print(f\"   Priority: {rec['priority']}\")\n",
        "            print(f\"   Reasoning: {rec['reasoning']}\")\n",
        "            print(\"   Parameters:\")\n",
        "            for param, val in rec['parameters'].items():\n",
        "                print(f\"     {param:>15}: {format_value(val)}\")\n",
        "            print(f\"   Technical: {rec['technical_rationale']}\")\n",
        "\n",
        "        return recs\n",
        "\n",
        "    mixing_recs, mix_time = get_mixing_recommendations(features)\n",
        "    timings['mixing_recommendations'] = mix_time\n",
        "\n",
        "    # === 6. Enhanced LLM Recommendations ===\n",
        "    @timed_section(\"Enhanced LLM Recommendations\")\n",
        "    def get_enhanced_recommendations():\n",
        "        print(\"\\n[INFO] Generating enhanced LLM recommendations...\")\n",
        "        enhanced_mixing = get_enhanced_mixing_recommendations_v2(\n",
        "            features=features,\n",
        "            semantic_mapping=semantic_mapping,\n",
        "            mixing_recs=mixing_recs,\n",
        "            api_key=api_key,\n",
        "        )\n",
        "        \n",
        "        print_separator(\"ENHANCED MIXING RECOMMENDATIONS\")\n",
        "        if isinstance(enhanced_mixing, dict):\n",
        "            for section, content in enhanced_mixing.items():\n",
        "                print(f\"\\n{section.upper()}:\")\n",
        "                if isinstance(content, dict):\n",
        "                    for key, value in content.items():\n",
        "                        print(f\"  {key}: {format_value(value)}\")\n",
        "                else:\n",
        "                    print(f\"  {content}\")\n",
        "        else:\n",
        "            print(f\"[RESULT] Enhanced recommendations:\\n{enhanced_mixing}\")\n",
        "        \n",
        "        return enhanced_mixing\n",
        "\n",
        "    enhanced_mixing, enh_time = get_enhanced_recommendations()\n",
        "    timings['enhanced_recommendations'] = enh_time\n",
        "\n",
        "    # === 7. Chatbot Setup ===\n",
        "    @timed_section(\"Chatbot Setup\")\n",
        "    def setup_chatbot():\n",
        "        print(\"\\n[INFO] Setting up enhanced mixing chatbot...\")\n",
        "        chatbot_state = setup_enhanced_mixing_chatbot(\n",
        "           features=features,\n",
        "           semantic_mapping=semantic_mapping,\n",
        "           enhanced_plan=enhanced_mixing,\n",
        "           mixing_recs=mixing_recs,\n",
        "           api_key=api_key\n",
        "        )\n",
        "        \n",
        "        print_separator(\"CHATBOT READY\")\n",
        "        print(\"[INFO] Chatbot configurado con el contexto completo del anlisis\")\n",
        "        print(\"[INFO] Puedes hacer preguntas sobre el mix, recomendaciones, etc.\")\n",
        "        \n",
        "        return chatbot_state\n",
        "\n",
        "    chatbot_state, chat_time = setup_chatbot()\n",
        "    timings['chatbot_setup'] = chat_time\n",
        "\n",
        "    # Chat with enhanced context\n",
        "    print(\"\\n[INTERACTIVE] Iniciando sesin de chat...\")\n",
        "    while True:\n",
        "        user_input = input(\"\\nAsk about the mix (or 'q' to quit): \")\n",
        "        if user_input.lower() in (\"q\", \"quit\", \"exit\"):\n",
        "            print(\"Exiting chatbot session.\")\n",
        "            break\n",
        "        \n",
        "        try:\n",
        "            answer = chat_mixing_followup_v2(chatbot_state, user_input)\n",
        "            print(f\"\\n[RESPONSE]\\n{answer}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Error en el chatbot: {e}\")\n",
        "\n",
        "    # === 8. Prompt Generation ===\n",
        "    @timed_section(\"Prompt Generation\")\n",
        "    def generate_prompt(semantic_mapping):\n",
        "        print(\"\\n[INFO] Generating MusicGen prompt...\")\n",
        "\n",
        "        user_request = input(\"\\nDescribe the music follow-up: \")\n",
        "        prompt = prompt_gpt_optimized(semantic_mapping, user_request, api_key)\n",
        "        \n",
        "        print_separator(\"GENERATED PROMPT\")\n",
        "        print(f\"[INPUT] User request: {user_request}\")\n",
        "        print(f\"[RESULT] Generated Prompt:\\n{prompt}\")\n",
        "        \n",
        "        return prompt\n",
        "\n",
        "    prompt, prompt_time = generate_prompt(semantic_mapping)\n",
        "    timings['prompt_generation'] = prompt_time\n",
        "\n",
        "    # === 9. Audio Generation ===\n",
        "    AUDIO_GEN_DIR = os.path.join(BASE_DIR, \"outputs\", \"generated_audio\")\n",
        "    os.makedirs(AUDIO_GEN_DIR, exist_ok=True)\n",
        "\n",
        "    output_gen_path = os.path.join(AUDIO_GEN_DIR, \"musicgen_output.wav\")\n",
        "\n",
        "    model_name = \"musicgen-small\"\n",
        "    @timed_section(\"Audio Generation\")\n",
        "    def generate_audio(prompt, audio_data, sample_rate):\n",
        "        print(\"\\n[INFO] Generating audio from prompt...\")\n",
        "        sr_gen, generated_audio = generar_audio(audio_data, prompt, sample_rate, model_name=model_name, output_path=output_gen_path)\n",
        "        \n",
        "        print_separator(\"AUDIO GENERATION RESULTS\")\n",
        "        print(f\"[INFO] Audio generado con sample rate: {sr_gen} Hz\")\n",
        "        print(f\"[INFO] Archivo guardado en: {output_gen_path}\")\n",
        "        print(f\"[INFO] Duracin del audio generado: {len(generated_audio)/sr_gen:.2f} segundos\")\n",
        "        \n",
        "        return sr_gen, generated_audio\n",
        "\n",
        "    (sr_gen, generated_audio), gen_time = generate_audio(prompt, audio_data, sample_rate)\n",
        "    timings['audio_generation'] = gen_time\n",
        "\n",
        "    # === Final Report ===\n",
        "    print_separator(\"PROCESSING COMPLETE\")\n",
        "    print(\"Timing Summary:\")\n",
        "    for section, duration in timings.items():\n",
        "        print(f\"- {section.replace('_', ' ').title()}: {duration:.2f}s\")\n",
        "\n",
        "    total = sum(timings.values())\n",
        "    print(f\"\\nTotal time: {total:.2f}s ({total/60:.1f} minutes)\")\n",
        "    print(\"\\nPercentage breakdown:\")\n",
        "    for section, duration in timings.items():\n",
        "        print(f\"- {section.replace('_', ' '):<25}: {duration/total*100:.1f}%\")\n",
        "\n",
        "    print_separator(\"OUTPUT FILES SUMMARY\")\n",
        "    print(f\"Stems directory: {STEMS_DIR}\")\n",
        "    print(f\"MIDI directory: {MIDI_DIR}\")\n",
        "    print(f\"Generated audio: {output_gen_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configure for best performance\n",
        "    total_start = time.time()\n",
        "    main()\n",
        "    print(f\"\\n[SYSTEM] Total wall time: {time.time()-total_start:.2f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JXm_rVHUbTCY",
        "pDYrWf_BbQLZ",
        "-eNxMzfgH3ei",
        "fgJRA0VB9zjG",
        "ssIFrM7h-OVU",
        "SYuJdNVSUP5Z",
        "hq0KpH4G1l4T",
        "nI8gopxLhlu6",
        "ZzgYis6-X1Ae",
        "ibWhFW5uJFZn",
        "W37jEKcTJH-a",
        "vyzSKUg6JCXC",
        "D3gTD1tx8qJS",
        "8La1FsoW-GVM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0037636e80b046dabed6082a9cd6c267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b2ec5d461a42d28f99ff5c11990ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f83c6878de46e7a95886c3de4a3d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06d7e0c27904e6ba2a5a1ef87d779ed",
            "placeholder": "",
            "style": "IPY_MODEL_dee62f34e27c4859bfe5950a0a95e3b5",
            "value": "generation_config.json:100%"
          }
        },
        "0791a249c94c46c8b0206a6749d4c572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "08440f83615343e99ff7c93f1d13f05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8098e97cee324c6abe41e47355903e12",
            "placeholder": "",
            "style": "IPY_MODEL_da5739f23eac4b14aa228409f4af013b",
            "value": "792k/792k[00:00&lt;00:00,332kB/s]"
          }
        },
        "09d2e61977f04520875854c715c9c9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d92ec37a50448be9e0fe8975ec48c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e9c81af1cf143ef8809401f44d234bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ca3c2dd48945b7988866bcc4b97a38",
            "max": 224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdfa66b3e71f41679025c296419bbf39",
            "value": 224
          }
        },
        "102b15ca6592475a8bde98b8bf40e9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64907f1ee7884475b914d79515f298ff",
            "placeholder": "",
            "style": "IPY_MODEL_340d0ac3cc9541a7b2f7d4eaa121fa3f",
            "value": "preprocessor_config.json:100%"
          }
        },
        "13e6863b9f154ddd97063d492abebfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1543e84b18df4af687a442234e336572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155abab0c4fb4c41942f87188edbc4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e48e61bf994073bdf5692e1c22e013",
            "placeholder": "",
            "style": "IPY_MODEL_13e6863b9f154ddd97063d492abebfde",
            "value": "275/275[00:00&lt;00:00,28.9kB/s]"
          }
        },
        "156f7a9bb51f43c0b2a2045c4951d274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a637e4e38a42f69c0924aba9c23e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a09b0486694cbcac1ba23c0e5650aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c0a3463a83a43eba81a5bddb948ccab",
              "IPY_MODEL_987b9567a3a34e498ebbbe4f738d1170",
              "IPY_MODEL_3ebf62edf0f0456dbc187168f2f53fed"
            ],
            "layout": "IPY_MODEL_c9c75e0a272c489e851fce03ed962016"
          }
        },
        "273022bf587346428617a72f406a76e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d2e61977f04520875854c715c9c9a1",
            "placeholder": "",
            "style": "IPY_MODEL_e4774ffe61e343bcad2626e1ac5c1116",
            "value": "tokenizer.json:"
          }
        },
        "28d493d8024d4689b022e8a9e1c21172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_273022bf587346428617a72f406a76e7",
              "IPY_MODEL_6d5864c9879d429d8a81c4f60dd28c93",
              "IPY_MODEL_39c05fa47f604b3db2414a97f74b640b"
            ],
            "layout": "IPY_MODEL_01b2ec5d461a42d28f99ff5c11990ee2"
          }
        },
        "3351784a68554e5fb51323699b324da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36a0e68f76464a34b9f8860c1e3a4fe0",
              "IPY_MODEL_9d1b8f7c69624a31a6f574a2ab0f6a84",
              "IPY_MODEL_08440f83615343e99ff7c93f1d13f05d"
            ],
            "layout": "IPY_MODEL_9e6f2e6de6b847fda89f0f563bedc80d"
          }
        },
        "340d0ac3cc9541a7b2f7d4eaa121fa3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3619e667de324a5095e3d05c19d428c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a0e68f76464a34b9f8860c1e3a4fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6942b083a904a34aa14b74658282e6e",
            "placeholder": "",
            "style": "IPY_MODEL_d5207c92583243d4b9dc41232d9e3747",
            "value": "spiece.model:100%"
          }
        },
        "39c05fa47f604b3db2414a97f74b640b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc18d8db6e2142778ac5d6b3efe78011",
            "placeholder": "",
            "style": "IPY_MODEL_6ac71d71244540d8a5c8064f27d9c49a",
            "value": "2.42M/?[00:00&lt;00:00,39.1MB/s]"
          }
        },
        "3ce97a8ee09244ada7e25580a31da155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5aa640def14ff7aeb4065df708d389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561e011d4ec44381a9a000438ec21093",
            "placeholder": "",
            "style": "IPY_MODEL_0d92ec37a50448be9e0fe8975ec48c4a",
            "value": "224/224[00:00&lt;00:00,23.3kB/s]"
          }
        },
        "3ebf62edf0f0456dbc187168f2f53fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd993a6c884642918c6372d293e0ee7c",
            "placeholder": "",
            "style": "IPY_MODEL_156f7a9bb51f43c0b2a2045c4951d274",
            "value": "7.87k/?[00:00&lt;00:00,652kB/s]"
          }
        },
        "4a21d06ca66c48b5884d6ab18dd05d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_102b15ca6592475a8bde98b8bf40e9e0",
              "IPY_MODEL_8b3647061dc444ecafdc8fdc116d7d55",
              "IPY_MODEL_155abab0c4fb4c41942f87188edbc4e6"
            ],
            "layout": "IPY_MODEL_c924938163ba43c2a9ea68d0e77ba596"
          }
        },
        "517d04a29e184986bac84c82a9ea9d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521bf051fafc4fdcb9a13d6d0b02ab9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53cb4c3f30034594b028c9b49c85b60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b4772235a24ec1a44c597a8b797b81",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85be157bb9ba42be867a07c1696d410a",
            "value": 1
          }
        },
        "561e011d4ec44381a9a000438ec21093": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5745171739a149af891cfa5ec7dcf656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece794815cec475987b3d183a6fed5d0",
            "max": 2364427288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdd7c6c2209247a9bd17b53c76ef4a2c",
            "value": 2364427288
          }
        },
        "5af19adf867c47599a27009afa17a16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c0a3463a83a43eba81a5bddb948ccab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1543e84b18df4af687a442234e336572",
            "placeholder": "",
            "style": "IPY_MODEL_5af19adf867c47599a27009afa17a16f",
            "value": "config.json:"
          }
        },
        "5da33549be924de3b96963a9323794bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e7846f331e49a59f5c8569ebb3e0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64907f1ee7884475b914d79515f298ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67010486fcca43f0ba1dc1eac3ac2516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c050bbf642d4e879d9f673d5868ef6a",
            "placeholder": "",
            "style": "IPY_MODEL_ec0896d6d767431cb2b3c21f73d94ec8",
            "value": "2.36G/2.36G[02:40&lt;00:00,61.6MB/s]"
          }
        },
        "67e2edd967a542818753b78fce069c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecde802519ea4224b5250a826a3c66df",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8efc695a606445afaa742062cd8558ae",
            "value": 1
          }
        },
        "6a5350cc20354ae092d55f8bd18e6f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01f83c6878de46e7a95886c3de4a3d26",
              "IPY_MODEL_0e9c81af1cf143ef8809401f44d234bb",
              "IPY_MODEL_3e5aa640def14ff7aeb4065df708d389"
            ],
            "layout": "IPY_MODEL_a85310eef0984dde9ebd9f3b72b5643f"
          }
        },
        "6ac71d71244540d8a5c8064f27d9c49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d5864c9879d429d8a81c4f60dd28c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94aac872ff704be19b95416b11b192e6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d2624d4cd314d02830569b66b22d18a",
            "value": 1
          }
        },
        "6e8fcfd0f1654beba1d67dca290be5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70273e0beba442b5b2a5adf5601bdb50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780076916f0b4b2498acc7ece7f52d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b0b1bd53af248d594e4930ad2a155ad",
              "IPY_MODEL_5745171739a149af891cfa5ec7dcf656",
              "IPY_MODEL_67010486fcca43f0ba1dc1eac3ac2516"
            ],
            "layout": "IPY_MODEL_b62a7ea19a79496d81ee9dfa58c9388f"
          }
        },
        "7b0b1bd53af248d594e4930ad2a155ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d027ec637140c8bae3cfab6d0bb8d9",
            "placeholder": "",
            "style": "IPY_MODEL_521bf051fafc4fdcb9a13d6d0b02ab9f",
            "value": "model.safetensors:100%"
          }
        },
        "8098e97cee324c6abe41e47355903e12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85be157bb9ba42be867a07c1696d410a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8af97c3e6330473d86ad80f2b0a84dce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3647061dc444ecafdc8fdc116d7d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a637e4e38a42f69c0924aba9c23e4d",
            "max": 275,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad7ee65a90854df0ae72db524e7e4c45",
            "value": 275
          }
        },
        "8c050bbf642d4e879d9f673d5868ef6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efc695a606445afaa742062cd8558ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "945ba439284346e383dca3264e27fb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce97a8ee09244ada7e25580a31da155",
            "placeholder": "",
            "style": "IPY_MODEL_6e8fcfd0f1654beba1d67dca290be5fe",
            "value": "tokenizer_config.json:"
          }
        },
        "94aac872ff704be19b95416b11b192e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "987b9567a3a34e498ebbbe4f738d1170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0791a249c94c46c8b0206a6749d4c572",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70273e0beba442b5b2a5adf5601bdb50",
            "value": 1
          }
        },
        "9985821481da49d3929b7571cedf3980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d29f894259134d919c4788353540804f",
              "IPY_MODEL_53cb4c3f30034594b028c9b49c85b60f",
              "IPY_MODEL_cd390adc0bc14eef8f99e3c97d740168"
            ],
            "layout": "IPY_MODEL_3619e667de324a5095e3d05c19d428c4"
          }
        },
        "9d1b8f7c69624a31a6f574a2ab0f6a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76b52c4a1994bd3b5ce7fd3b39cfbfa",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61e7846f331e49a59f5c8569ebb3e0e8",
            "value": 791656
          }
        },
        "9d2624d4cd314d02830569b66b22d18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e6f2e6de6b847fda89f0f563bedc80d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06d7e0c27904e6ba2a5a1ef87d779ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b4772235a24ec1a44c597a8b797b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a85310eef0984dde9ebd9f3b72b5643f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7ee65a90854df0ae72db524e7e4c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b62a7ea19a79496d81ee9dfa58c9388f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76b52c4a1994bd3b5ce7fd3b39cfbfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a378dd68cc45e4925cc546933538c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc18d8db6e2142778ac5d6b3efe78011": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd993a6c884642918c6372d293e0ee7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd7c6c2209247a9bd17b53c76ef4a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c924938163ba43c2a9ea68d0e77ba596": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c75e0a272c489e851fce03ed962016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd390adc0bc14eef8f99e3c97d740168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af97c3e6330473d86ad80f2b0a84dce",
            "placeholder": "",
            "style": "IPY_MODEL_517d04a29e184986bac84c82a9ea9d7e",
            "value": "2.20k/?[00:00&lt;00:00,216kB/s]"
          }
        },
        "d0e48e61bf994073bdf5692e1c22e013": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29f894259134d919c4788353540804f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a378dd68cc45e4925cc546933538c6",
            "placeholder": "",
            "style": "IPY_MODEL_5da33549be924de3b96963a9323794bc",
            "value": "special_tokens_map.json:"
          }
        },
        "d5207c92583243d4b9dc41232d9e3747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5d027ec637140c8bae3cfab6d0bb8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5739f23eac4b14aa228409f4af013b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee62f34e27c4859bfe5950a0a95e3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4774ffe61e343bcad2626e1ac5c1116": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6942b083a904a34aa14b74658282e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0896d6d767431cb2b3c21f73d94ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecde802519ea4224b5250a826a3c66df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ece794815cec475987b3d183a6fed5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61b718dc18d47ea9e5d40735c803c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d58776cb9a49c0afeb7d3e051e4c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f61b718dc18d47ea9e5d40735c803c89",
            "placeholder": "",
            "style": "IPY_MODEL_f71b8adc2ca54fd9934dc6838d37dc4e",
            "value": "2.37k/?[00:00&lt;00:00,224kB/s]"
          }
        },
        "f71b8adc2ca54fd9934dc6838d37dc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9ca3c2dd48945b7988866bcc4b97a38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdfa66b3e71f41679025c296419bbf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fefd5edd87dd4b83ad698a269e3d6f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_945ba439284346e383dca3264e27fb90",
              "IPY_MODEL_67e2edd967a542818753b78fce069c16",
              "IPY_MODEL_f6d58776cb9a49c0afeb7d3e051e4c95"
            ],
            "layout": "IPY_MODEL_0037636e80b046dabed6082a9cd6c267"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
